# 线程

## 参考文献

* [面试官：说说多线程并发问题](https://juejin.cn/post/6844903941830869006)

## 1、进程,线程,协程

**说说进程,线程,协程之间的区别**

简而言之,**最本质的区别在于进程拥有自己的一整套变量，线程则共享数据**

* 进程是程序运行和资源分配的基本单位,一个程序至少有一个进程,一个进程至少有一个线程.
* 共享变量使线程之间的通信比进程更有效、更容易
* 进程在执行过程中拥有独立的内存单元,而多个线程共享内存资源,减少切换次数,从而效率更高.
* 线程是进程的一个实体,是cpu调度和分派的基本单位,是比程序更小的能独立运行的基本单位.
* 同一进程中的多个线程之间可以并发执行.

### 协程

一个线程可以有多个协程，协程是完全由用户进程进行管理，与操作系统无关，因此其完全在用户态运行，不存在上下文切换的开销，且可以在线程中乱序（异步）执行，没有同步开销，协程还可以保留每一次运行后的状态，重入时即从上一次状态开始运行

## 创建线程方式

4、创建两种线程的方式?他们有什么区别?

通过实现java.lang.Runnable或者通过继承java.lang.Thread类.相比扩展Thread,实现Runnable接口可能更优.原因有二:

- Java不支持多继承.因此扩展Thread类就代表这个子类不能扩展其他类.而实现Runnable接口的类还可以扩展另一个类.
- 类可能只要求可执行即可,因此继承整个Thread类的开销过大.
- 为每个任务常见一个独立的线程开销太大，可以使用线程池解决这个问题

方法一：实现runable

```java
public class MyThread implements Runnable {
    @Override
    public void run() {
        for (int i=0;i<10;i++)
            System.out.println(i);
    }

    public static void main(String[] args) {
        Runnable r = new MyThread();
        Thread t = new Thread(r);
        t.start();
    }
}

```

方法二:继承Thead

```java
static class NewThread extends Thread{
        public void run(){
            for (int i=0;i<10;i++){
                System.out.println(NewThread.class.toString()+": "+i);
            }
        }
    }
```

## 线程状态

* New 新生
* Runnable 可运行
* Blocked 被阻塞
* waiting 等待
* Timed Waiting  计时等待
* Terminated  被终止

|                             |                                                    |
| --------------------------- | -------------------------------------------------- |
| New 新生                    | 创建后、运行前                                     |
| Runnable 可运行             | 可能在运行、也可能不在运行                         |
| Blocked 被阻塞 waiting 等待 | 线程试图获得一个对象的内部锁，而该锁被其他线程占用 |
|                             |                                                    |
|                             |                                                    |

* 线程试图获得一个对象的内部锁，而该锁被其他线程占用，线程进入阻塞状态；当所有其他线程释放该锁，且线程调度器允许该线程持有它的时候，线程变成非阻塞状态
* 等待另一个线程通知调度器的一个条件时，线程进入等待状态。比如调用Object.wait方法或Thread.join方法。或是等待java.util.concurrent库中的Lock或Condition
* 有几个方法拥有超时参数，调用它们导致线程进入计数等待；这一状态持续带计时期满或者接收到适当的通知。带有超时参数的方法有Thread.sleep和Object.wait、Thread.join、Lock.tryLock以及Condition.await的计时版

### 线程终止的原因

1. 因为run方法正常退出而死亡
2. 因为一个没有捕获的异常终止了run方法，意外死亡

## 线程属性

### 线程优先级

- 线程继承父线程的优先级

- setPriority可以设置线程优先级，可以设置为1-10之间的值

### 守护线程

- 使用t.setDaemon(true)调用，必须在线程启动之前调用

守护线程的唯一用途就是为其他线程提供服务。当只剩下守护线程时，虚拟机就退出了。

## 概念

* 守护线程：程序运行完毕,jvm会等待非守护线程完成后关闭,但是jvm不会等待守护线程.守护线程最典型的例子就是GC线程
* 上下文切换：多线程的上下文切换是指CPU控制权由一个已经正在运行的线程切换到另外一个就绪并等待获取CPU执行权的线程的过程。

# 并发

## Java 内存模型（JMM）

Java 内存模型(JMM) 作用于工作内存（本地内存）和主存之间数据同步过程，它规定了如何做数据同步以及什么时候做数据同步，如下图。

![JMM](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/9/15/16d32c69d2b91f19~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)



## 并发问题

为什么多线程同时访问（读写）同个变量，会有并发问题？

> 1. Java 内存模型规定了所有的变量都存储在主内存中，每条线程有自己的工作内存。
> 2. 线程的工作内存中保存了该线程中用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。
> 3. 线程访问一个变量，首先将变量从主内存拷贝到工作内存，对变量的写操作，不会马上同步到主内存。
> 4. 不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。

## 并发三要素

**原子性**：在一个操作中，CPU 不可以在中途暂停然后再调度，即不被中断操作，要么执行完成，要么就不执行。

**可见性**：多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

**有序性**：程序执行的顺序按照代码的先后顺序执行。

# 线程安全

### 竞争条件

两个或以上线程存取相同的数据

假设两个线程都要执行以下语句

- 取出accounts

- accounts += 500

- 放回accounts

如果线程一执行完前两步就被剥夺了运行权，线程二执行结束后线程一又执行了第三步，那么线程二所做的修改将被抹去

**假如有一个转移资产的方法**

```java
    public void transfer(int from,int to,double amount){
        accounts[from] -= amount;
        System.out.println(Thread.currentThread());
        accounts[to]+=amount;
        System.out.println("从"+from+"到"+to);
        System.out.printf("Total: %10.2f%n",getTotalBalance());
    }
```

这一段代码可能会因为种种原因没执行完就被剥夺了运行权（可能是由于打印，但不一定），那么accounts就会出现错误数据

## 同步&加锁

### 概述

* 乐观锁
* 悲观锁
* 公平锁：线程获取锁的顺序是按照请求锁的时间早晚来决定的
* 非公平锁
* 独占锁：任何时候都只有 个线程能得到锁，
* 共享锁
* 可重入锁：线程再次获取自己已经获取的锁不会被阻塞
* 自旋锁：当前线程在获取锁时，如果发现锁已经被其他线程占有， 它不马上阻塞自己，在不放弃 CPU 使用权的情况下，多次尝试获取

如何解决？对这段代码加锁，在它执行完之前另一个线程不能执行这段代码

- 锁用来保护代码片段，任何时刻只能有一个线程执行被保护的代码
- 锁可以管理试图进入被保护代码的线程
- 锁可以拥有一个或多个相关的条件对象
- 每个条件对象管理那些已经进入被保护的代码段但还不能运行的线程
- 

|        | synchronized   | Reentrantlock  | volatile | 并发包         |
| ------ | -------------- | -------------- | -------- | -------------- |
| 定义   | 关键字         | 类             | 关键字   | 一系列数据类型 |
| 释放锁 | 不能           | 通过代码，条件 |          |                |
| 性质   | 原子性、可见性 |                | 可见性   |                |

### synchronized

#### 使用场景

多个线程同时写一个变量。

写变量大多涉及三个步骤，

1. 取出变量
2. 修改变量
3. 写回内存

一般在修改变量之后不会立刻写回内存，这样三个步骤如果不能保证原子性，就会导致线程安全问题。

**Synchronized 可以保证同一时刻，只有一个线程可执行某个方法或某个代码块。**

#### 原理

每个对象拥有一个计数器，当线程获取该对象锁后，计数器就会加一，释放锁后就会将计数器减一，所以只要这个锁的计数器大于0，其它线程访问就只能等待。

* 使用Synchronized进行同步，其关键就是必须要对对象的监视器monitor进行获取，
* 当线程获取monitor后才能继续往下执行，否则就进入同步队列，线程状态变成BLOCK，
* 同一时刻只有一个线程能够获取到monitor，当监听到monitorexit被调用，队列里就有一个线程出队，获取monitor。

**释放锁**：正常退出、抛出异常、调用wait方法

#### 内存视角

1. 代码段会把线程内的变量副本清除
2. 这样只能到主存获取
3. 退出代码段时再把变量写回主存

由此保证可见性

#### 锁的升级

大家对Synchronized的理解可能就是重量级锁，但是Java1.6对 Synchronized 进行了各种优化之后，有些情况下它就并不那么重，Java1.6 中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁。

**偏向锁：** 大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。

> 当一个线程A访问加了同步锁的代码块时，会在对象头中存 储当前线程的id，后续这个线程进入和退出这段加了同步锁的代码块时，不需要再次加锁和释放锁。

**轻量级锁：** 在偏向锁情况下，如果线程B也访问了同步代码块，比较对象头的线程id不一样，会升级为轻量级锁，并且通过自旋的方式来获取轻量级锁。

**重量级锁：** 如果线程A和线程B同时访问同步代码块，则轻量级锁会升级为重量级锁，线程A获取到重量级锁的情况下，线程B只能入队等待，进入BLOCK状态。

#### 2.4  Synchronized 缺点

1. 不能设置锁超时时间
2. 不能通过代码释放锁
3. 容易造成死锁
4. 阻塞其他线程需要从用户态切换到内核态，进行上下文切换，开销很大

### ReentrantLock

上面说到`Synchronized`的缺点，不能设置锁超时时间和不能通过代码释放锁，`ReentranLock`就可以解决这个问题。

**在多个条件变量和高度竞争锁的地方，用ReentrantLock更合适**，ReentrantLock还提供了`Condition`，对线程的等待和唤醒等操作更加灵活，一个ReentrantLock可以有多个Condition实例，所以更有扩展性。

#### 使用

#### 3.3 公平锁与非公平锁

ReentrantLock 构造函数传true表示公平锁。

公平锁表示线程获取锁的顺序是按照线程加锁的顺序来分配的，即先来先得的顺序。而非公平锁就是一种锁的抢占机制，是随机获得锁的，可能会导致某些线程一致拿不到锁，所以是不公平的。

#### 3.4 ReentrantLock  注意点

1. ReentrantLock使用lock和unlock来获得锁和释放锁
2. unlock要放在finally中，这样正常运行或者异常都会释放锁
3. 使用condition的await和signal方法之前，必须调用lock方法获得对象监视器

### volatile域

有时，仅仅需要读写一两个实例域就使用同步，显得开销太大了。

**volatile关键字为实例域的同步访问提供了一种免锁机制**，如果声明一个域为volatile，那么编译器和虚拟机就知道该域是可能被另一个进程并发更新的

总之，在以下三种情况下域的并发访问是安全的

1. 域是final,并且在构造完成后被访问

2. 对域的访问由共有的锁进行保护

3. 域是valatile的

#### 特性

**保证可见性，不保证原子性**

> 1. 当写一个volatile变量时，JVM会把本地内存的变量强制刷新到主内存中
> 2. 这个写操作导致其他线程中的缓存无效，其他线程读，会从主内存读。volatile的写操作对其它线程实时可见。

**禁止指令重排序** 指令重排序是指编译器和处理器为了优化程序性能对指令进行排序的一种手段，需要遵守一定规则：

> 1. 不会对存在依赖关系的指令重排序，例如 a = 1;b = a;  a 和b存在依赖关系，不会被重排序
> 2. 不能影响单线程下的执行结果。比如：a=1;b=2;c=a+b这三个操作,前两个操作可以重排序，但是c=a+b不会被重排序，因为要保证结果是3

#### 1.2 使用场景

对于一个变量，只有一个线程执行写操作，其它线程都是读操作，这时候可以用 volatile 修饰这个变量。

#### 1.3 单例双重锁为什么要用到volatile？

```java
public class TestInstance {

private static volatile TestInstance mInstance;

public static TestInstance getInstance(){       //1
    if (mInstance == null){                     //2
        synchronized (TestInstance.class){      //3
            if (mInstance == null){             //4
                mInstance = new TestInstance(); //5
            }
        }
    }
    return mInstance;
	}
}
```



假如没有用volatile，并发情况下会出现问题，线程A执行到注释5 `new TestInstance()` 的时候，分为如下几个几步操作：

1. 分配内存
2. 初始化对象
3. mInstance 指向内存

这时候如果发生指令重排，执行顺序是132，执行到第3的时候，线程B刚好进来了，并且执行到注释2，这时候判断mInstance 不为空，直接使用一个未初始化的对象。所以使用volatile关键字来禁止指令重排序。

#### 1.4 volatile 原理

在JVM底层volatile是采用**内存屏障**来实现的，内存屏障会提供3个功能：

> 1. 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
> 2. 它会强制将缓存的修改操作立即写到主内存
> 3. 写操作会导致其它CPU中的缓存行失效，写之后，其它线程的读操作会从主内存读。

#### 1.5 volatile 的局限性

**volatile 只能保证可见性，不能保证原子性**写操作对其它线程可见，但是不能解决多个线程同时写的问题。

> 1、可以创建Volatile数组吗?

Java 中可以创建 volatile类型数组，不过只是一个指向数组的引用，而不是整个数组。如果改变引用指向的数组，将会受到volatile 的保护，但是如果多个线程同时改变数组的元素，volatile标示符就不能起到之前的保护作用了

> 2、volatile能使得一个非原子操作变成原子操作吗?

一个典型的例子是在类中有一个 long 类型的成员变量。如果你知道该成员变量会被多个线程访问，如计数器、价格等，你最好是将其设置为 volatile。为什么？因为 Java 中读取 long 类型变量不是原子的，需要分成两步，如果一个线程正在修改该 long 变量的值，另一个线程可能只能看到该值的一半（前 32 位）。但是对一个 volatile 型的 long 或 double 变量的读写是原子。

一种实践是用 volatile 修饰 long 和 double 变量，使其能按原子类型来读写。double 和 long 都是64位宽，因此对这两种类型的读是分为两部分的，第一次读取第一个 32 位，然后再读剩下的 32 位，这个过程不是原子的，但 Java 中 volatile 型的 long 或 double 变量的读写是原子的。volatile 修复符的另一个作用是提供内存屏障（memory barrier），例如在分布式框架中的应用。简单的说，就是当你写一个 volatile 变量之前，Java 内存模型会插入一个写屏障（write barrier），读一个 volatile 变量之前，会插入一个读屏障（read barrier）。意思就是说，在你写一个 volatile 域时，能保证任何线程都能看到你写的值，同时，在写之前，也能保证任何数值的更新对所有线程是可见的，因为内存屏障会将其他所有写的值更新到缓存。

> 3、volatile类型变量提供什么保证?

volatile 主要有两方面的作用:1.避免指令重排2.可见性保证.例如，JVM 或者 JIT为了获得更好的性能会对语句重排序，但是 volatile 类型变量即使在没有同步块的情况下赋值也不会与其他语句重排序。 volatile 提供 happens-before 的保证，确保一个线程的修改能对其他线程是可见的。某些情况下，volatile 还能提供原子性，如读 64 位数据类型，像 long 和 double 都不是原子的(低32位和高32位)，但 volatile 类型的 double 和 long 就是原子的.

## ThreadLocal

**背景**：多个线程并发访问共享变量时，为了保证线程安全，一般使用同步的方法，即加锁进行控制，这种方法既考验对锁的理解，也有可能降低代码效率

**使用场景**：ThreadLocal为每个线程提供专属的本地变量副本，线程操作时实际操作的是自己内存里的变量

### 存储方式

每个线程拥有一个名为**threadLocals**的成员变量，类型是特殊的HashMap,键是该线程对应的ThreadLocal变量的引用，值是变量值

### ThreadLocalMAp

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ed5978a54046419897b1f5a039889931~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)



* 实际上是一个数据冗余操作，给变量设置多个副本，变量与线程一对一，每个线程只操作自己的变量
* 由于threadLocals存放的键是threadlocal而不是线程id，所以一个线程可以对应多个threadlocal变量



### 内存泄漏

* `ThreadLocalMap `中使用的 key 为` ThreadLocal `的弱引用，而 value 是强引用。
* 所以，如果 `ThreadLocal `没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清 理掉。 这样一来， `ThreadLocalMap `中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永 远无法被 GC 回收，这个时候就可能会产生**内存泄露**
* ThreadLocalMap 实现中已经考虑了这种情况， 在调用 set() 、 get() 、 remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal 方法后 最好手动调用 remove() 方法

### 应用场景

可以使用ThreadLocal存放User

1.并发编程中重要的问题就是数据共享，当你在一个线程中改变任意属性时，所有的线程都会因此受到影响，同时会看到第一个线程修改后的值<br>
有时我们希望如此，比如：多个线程增大或减小同一个计数器变量<br>
但是，有时我们希望确保每个线程，只能工作在它自己 的线程实例的拷贝上，同时不会影响其他线程的数据<br>

举例： 举个例子，想象你在开发一个电子商务应用，你需要为每一个控制器处理的顾客请求，生成一个唯一的事务ID，同时将其传到管理器或DAO的业务方法中，
以便记录日志。一种方案是将事务ID作为一个参数，传到所有的业务方法中。但这并不是一个好的方案，它会使代码变得冗余。   
你可以使用ThreadLocal类型的变量解决这个问题。首先在控制器或者任意一个预处理器拦截器中生成一个事务ID
然后在ThreadLocal中 设置事务ID，最后，不论这个控制器调用什么方法，都能从threadlocal中获取事务ID
而且这个应用的控制器可以同时处理多个请求，
同时在框架 层面，因为每一个请求都是在一个单独的线程中处理的，所以事务ID对于每一个线程都是唯一的，而且可以从所有线程的执行路径获取
运行结果可以看出每个线程都在维护自己的变量：
 Starting Thread: 0 : Fri Sep 21 23:05:34 CST 2018<br>
 Starting Thread: 2 : Fri Sep 21 23:05:34 CST 2018<br>
 Starting Thread: 1 : Fri Jan 02 05:36:17 CST 1970<br>
 Thread Finished: 1 : Fri Jan 02 05:36:17 CST 1970<br>
 Thread Finished: 0 : Fri Sep 21 23:05:34 CST 2018<br>
 Thread Finished: 2 : Fri Sep 21 23:05:34 CST 2018<br>

 局部线程通常使用在这样的情况下，当你有一些对象并不满足线程安全，但是你想避免在使用synchronized关键字<br>
 块时产生的同步访问，那么，让每个线程拥有它自己的对象实例<br>
 注意：局部变量是同步或局部线程的一个好的替代，它总是能够保证线程安全。唯一可能限制你这样做的是你的应用设计约束<br>
 所以设计threadlocal存储user不会对对象产生影响，每次进来一个请求都会产生自身的线程变量来存储

# 并发包

除了手动加锁实现线程安全，java还提供了一些线程安全的数据结构，称为并发包

## AQS

![concurrent包实现整体示意图.png](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2018/5/3/163260cff7cb847c~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

**AbstractQueuedSynchronizer** 抽象队列同步器

**AQS就是一个并发包的基础组件，用来实现各种锁，各种同步组件的。它包含了state变量、加锁线程、等待队列等并发中的核心组件。**

* 是一个FIFO的双向队列
* 通过head、tail记录头尾结点
* 元素类型为Node
* 有一个int类型的状态信息变量state
* 有个内部类ConditionObject,用来结合锁实现线程同步
* 



### 并发包

通过上面分析，并发严重的情况下，使用锁显然效率低下，因为同一时刻只能有一个线程可以获得锁，其它线程只能乖乖等待。

Java提供了并发包解决这个问题，接下来介绍并发包里一些常用的数据结构。

#### 4.1 ConcurrentHashMap

**我们都知道HashMap是线程不安全的数据结构，HashTable则在HashMap基础上，get方法和put方法加上Synchronized修饰变成线程安全，不过在高并发情况下效率底下，最终被`ConcurrentHashMap`替代。**

ConcurrentHashMap 采用分段锁，内部默认有16个桶，get和put操作，首先将key计算hashcode，然后跟16取余，落到16个桶中的一个，然后每个桶中都加了锁（ReentrantLock），桶中是HashMap结构（数组加链表，链表过长转红黑树）。

所以理论上最多支持16个线程同时访问。

## ConcurrentHashMap

### ConcurrentHashMap的并发度是什么?

ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势，任何情况下，Hashtable能同时有两条线程获取Hashtable中的数据吗？

### ConcurrentHashMap的工作原理

ConcurrentHashMap在jdk 1.6和jdk 1.8实现原理是不同的.

####  **jdk 1.6**

ConcurrentHashMap是线程安全的，但是与Hashtable相比，实现线程安全的方式不同。Hashtable是通过对hash表结构进行锁定，是阻塞式的，当一个线程占有这个锁时，其他线程必须阻塞等待其释放锁。ConcurrentHashMap是采用分离锁的方式，它并没有对整个hash表进行锁定，而是局部锁定，也就是说当一个线程占有这个局部锁时，不影响其他线程对hash表其他地方的访问。 具体实现:ConcurrentHashMap内部有一个Segment 

#### **jdk 1.8**

在jdk 8中，ConcurrentHashMap不再使用Segment分离锁，而是采用一种乐观锁CAS算法来实现同步问题，但其底层还是“数组+链表->红黑树”的实现。

#### 4.2 LinkBlockingQueue

链表结构的阻塞队列，内部使用多个ReentrantLock

```java
    /** Lock held by take, poll, etc */
    private final ReentrantLock takeLock = new ReentrantLock();

    /** Wait queue for waiting takes */
    private final Condition notEmpty = takeLock.newCondition();

    /** Lock held by put, offer, etc */
    private final ReentrantLock putLock = new ReentrantLock();

    /** Wait queue for waiting puts */
    private final Condition notFull = putLock.newCondition();

private void signalNotEmpty() {
        final ReentrantLock takeLock = this.takeLock;
        takeLock.lock();
        try {
            notEmpty.signal();
        } finally {
            takeLock.unlock();
        }
    }

    /**
     * Signals a waiting put. Called only from take/poll.
     */
    private void signalNotFull() {
        final ReentrantLock putLock = this.putLock;
        putLock.lock();
        try {
            notFull.signal();
        } finally {
            putLock.unlock();
        }
    }
```

源码不贴太多，简单说一下`LinkBlockingQueue` 的逻辑：

> 1. 从队列获取数据，如果队列中没有数据，会调用`notEmpty.await();`进入等待。
> 2. 在放数据进去队列的时候会调用`notEmpty.signal();`，通知消费者，1中的等待结束，唤醒继续执行。
> 3. 从队列里取到数据的时候会调用`notFull.signal();`，通知生产者继续生产。
> 4. 在put数据进入队列的时候，如果判断队列中的数据达到最大值，那么会调用`notFull.await();`，等待消费者消费掉，也就是等待3去取数据并且发出`notFull.signal();`，这时候生产者才能继续生产。

`LinkBlockingQueue` 是典型的生产者消费者模式，源码细节就不多说。

#### 4.3  原子操作类：AtomicInteger

内部采用CAS（compare and swap）保证原子性

举一个int自增的例子

```
        AtomicInteger atomicInteger = new AtomicInteger(0);
        atomicInteger.incrementAndGet();//自增
```

源码看一下

```
   /**
     * Atomically increments by one the current value.
     *
     * @return the updated value
     */
    public final int incrementAndGet() {
        return U.getAndAddInt(this, VALUE, 1) + 1;
    }
```

U 是 Unsafe，看下 `Unsafe#getAndAddInt`

```
    public final int getAndAddInt(Object var1, long var2, int var4) {
        int var5;
        do {
            var5 = this.getIntVolatile(var1, var2);
        } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));

        return var5;
    }
```

通过`compareAndSwapInt`保证原子性。

## 五、总结

面试中问到多线程并发问题，可以这么答：

> 1. 当只有一个线程写，其它线程都是读的时候，可以用`volatile`修饰变量
> 2. 当多个线程写，那么一般情况下并发不严重的话可以用`Synchronized`，Synchronized并不是一开始就是重量级锁，在并发不严重的时候，比如只有一个线程访问的时候，是偏向锁；当多个线程访问，但不是同时访问，这时候锁升级为轻量级锁；当多个线程同时访问，这时候升级为重量级锁。所以在并发不是很严重的情况下，使用Synchronized是可以的。不过Synchronized有局限性，比如不能设置锁超时，不能通过代码释放锁。
> 3. `ReentranLock` 可以通过代码释放锁，可以设置锁超时。
> 4. 高并发下，Synchronized、ReentranLock 效率低，因为同一时刻只有一个线程能进入同步代码块，如果同时有很多线程访问，那么其它线程就都在等待锁。这个时候可以使用并发包下的数据结构，例如`ConcurrentHashMap`，`LinkBlockingQueue`，以及原子性的数据结构如：`AtomicInteger`。。



# 线程池

* [拒绝策略](https://mp.weixin.qq.com/s?__biz=MzkyMjI1OTgxNA==&mid=2247496664&idx=1&sn=eca3c9774333d77fa8afdb50c61070e9&source=41#wechat_redirect)
* [java高级应用：线程池全面解析](http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247483824&idx=1&sn=7e34a3944a93d649d78d618cf04e0619&chksm=eb538486dc240d903d6f3ae80b7cd00455b2125c5ff01d118ce6f17a7a75b81661800f9be760&scene=21#wechat_redirect)
* 

### 背景

频繁的创建和销毁线程会产生巨大的CPU开销，因此设计线程池来复用线程，以此避免耗费CPU、内存资源，GC频繁收集和停顿。

构建一个新的线程是有一定的代价的，因为设计与操作系统的交互。如果程序中创建了大量的生命期很短的线程，**应该使用线程池。**一个线程池包含了很多准备运行的空闲线程。将Runnable对象交给线程池，就会有一个线程调用run方法，当run方法结束时线程不会死亡，而是准备为下一个请求提供服务。

### 线程核心类ThreadPoolExecutor

另一个使用线程池的理由是减少并发线程的数目。

执行器类（Executor）有很多静态工厂方法创建线程池。

​	基本组成

- corePoolSize：线程池的核心大小，也可以理解为最小的线程池大小。 int
- maximumPoolSize：最大线程池大小。int 
- keepAliveTime：空余线程存活时间，指的是超过corePoolSize的空余线程达到多长时间才进行销毁。long
- unit：销毁时间单位。 TimeUnit
- workQueue：存储等待执行线程的工作队列。 BlockingQueue
- threadFactory：创建线程的工厂，一般用默认即可。 ThreadFactory
- handler：拒绝策略，当工作队列、线程池全已满时如何拒绝新任务，默认抛出异常。

### 核心线程池数量

IO密集型=2Ncpu（可以测试后自己控制大小，2Ncpu一般没问题）（常出现于线程中：数据库数据交互、文件上传下载、网络数据传输等等）

计算密集型=Ncpu（常出现于线程中：复杂算法）

**java中：Ncpu=`Runtime.getRuntime().availableProcessors()`**


著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。****

###   创建时机 

* 核心线程数以内的线程是常驻线程，占用固定数量的CPU资源
* 大小设定取决于系统需求
* 任务来了直接开启违背了线程复用的初衷，线程的创建于销毁是一件开销不小的任务



### 线程池工作流程

1、如果线程池中的线程**小于**corePoolSize时就会创建新线程直接执行任务。

2、如果线程池中的线程**大于**corePoolSize时就会暂时把任务存储到工作队列workQueue中等待执行。

3、如果工作队列workQueue也满时：当线程数小于最大线程池数maximumPoolSize时就会创建新线程来处理，而线程数大于等于最大线程池数maximumPoolSize时就会执行拒绝策略。

### 线程池分类

Executors是jdk里面提供的创建线程池的工厂类，它默认提供了4种常用的线程池应用，而不必我们去重复构造。

#### newFixedThreadPool

固定线程池，核心线程数和最大线程数固定相等，而空闲存活时间为0毫秒，说明此参数也无意义，工作队列为最大为Integer.MAX_VALUE大小的阻塞队列。当执行任务时，如果线程都很忙，就会丢到工作队列等有空闲线程时再执行，队列满就执行默认的拒绝策略。

#### newCachedThreadPool

​    带缓冲线程池，从构造看核心线程数为0，最大线程数为Integer最大值大小，超过0个的空闲线程在60秒后销毁，SynchronousQueue这是一个直接提交的队列，意味着每个新任务都会有线程来执行，如果线程池有可用线程则执行任务，没有的话就创建一个来执行，线程池中的线程数不确定，一般建议执行速度较快较小的线程，不然这个最大线程池边界过大容易造成内存溢出。

#### newSingleThreadExecutor

​        单线程线程池，核心线程数和最大线程数均为1，空闲线程存活0毫秒同样无意思，意味着每次只执行一个线程，多余的先存储到工作队列，一个一个执行，保证了线程的顺序执行。

#### newScheduledThreadPool

调度线程池，即按一定的周期执行任务，即定时任务，对ThreadPoolExecutor进行了包装而已。

### 提交线程池

```java
如可以先随便定义一个固定大小的线程池

ExecutorService es = Executors.newFixedThreadPool(3);



提交一个线程

es.submit(xxRunnble);

es.execute(xxRunnble);
```

#### submit和execute

execute没有返回值，如果不需要知道线程的结果就使用execute方法，性能会好很多。

submit返回一个Future对象，如果想知道线程结果就使用submit提交，而且它能在主线程中通过Future的get方法捕获线程中的异常

### 拒绝策略

当线程池满了之后，新来的线程需要被拒绝。

#### AbortPolicy

 简单粗暴，直接抛出拒绝异常，这也是默认的拒绝策略。

#### CallerRunsPolicy

 如果线程池未关闭，则会在调用者线程中直接执行新任务，这会导致主线程提交线程性能变慢。

**使用场景**：一般在不允许失败的、对性能要求不高、并发量较小的场景下使用，因为线程池一般情况下不会关闭，也就是提交的任务一定会被运行，但是由于是调用者线程自己执行的，当多次提交任务时，就会阻塞后续任务执行，性能和效率自然就慢了。

#### DiscardPolicy

   从方法看没做任务操作，即表示不处理新任务，即丢弃。

#### DiscardOldestPolicy

抛弃最老的任务，就是从队列取出最老的任务然后放入新的任务进行执行。 

### 关闭线程池

**es.shutdown();** 

不再接受新的任务，之前提交的任务等执行结束再关闭线程池。

**es.shutdownNow();**

不再接受新的任务，试图停止池中的任务再关闭线程池，返回所有未处理的线程list列表。

|      |      |      |
| ---- | ---- | ---- |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |
|      |      |      |





## Runnable和Callable

|        | Runnable | Callable                                                   |
| ------ | -------- | ---------------------------------------------------------- |
| 返回值 | 有       | 无                                                         |
|        |          | 而Callable+Future/FutureTask却可以方便获取多线程运行的结果 |
|        |          |                                                            |



## 线程阻塞

阻塞指的是暂停一个线程的执行以等待某个条件发生（如某资源就绪），学过操作系统的同学对它一定已经很熟悉了。Java 提供了大量方法来支持阻塞，下面让我们逐一分析。

| 方法                  | 说明                                                         |
| --------------------- | ------------------------------------------------------------ |
| sleep()               | sleep() 允许 指定以毫秒为单位的一段时间作为参数，它使得线程在指定的时间内进入阻塞状态，不能得到CPU 时间，指定的时间一过，线程重新进入可执行状态。 典型地，sleep() 被用在等待某个资源就绪的情形：测试发现条件不满足后，让线程阻塞一段时间后重新测试，直到条件满足为止 |
| suspend() 和 resume() | 两个方法配套使用，suspend()使得线程进入阻塞状态，并且不会自动恢复，必须其对应的resume() 被调用，才能使得线程重新进入可执行状态。典型地，suspend() 和 resume() 被用在等待另一个线程产生的结果的情形：测试发现结果还没有产生后，让线程阻塞，另一个线程产生了结果后，调用 resume() 使其恢复。 |
| yield()               | yield() 使当前线程放弃当前已经分得的CPU 时间，但不使当前线程阻塞，即线程仍处于可执行状态，随时可能再次分得 CPU 时间。调用 yield() 的效果等价于调度程序认为该线程已执行了足够的时间从而转到另一个线程 |
| wait() 和 notify()    | 两个方法配套使用，wait() 使得线程进入阻塞状态，它有两种形式，一种允许 指定以毫秒为单位的一段时间作为参数，另一种没有参数，前者当对应的 notify() 被调用或者超出指定时间时线程重新进入可执行状态，后者则必须对应的 notify() 被调用. |

> 12、为什么wait()方法和notify()/notifyAll()方法要在同步块中被调用

这是JDK强制的，wait()方法和notify()/notifyAll()方法在调用前都必须先获得对象的锁 wait()方法和notify()/notifyAll()方法在放弃对象监视器时有什么区别

wait()方法和notify()/notifyAll()方法在放弃对象监视器的时候的区别在于：wait()方法立即释放对象监视器，notify()/notifyAll()方法则会等待线程剩余代码执行完毕才会放弃对象监视器。

> 14、为什么wait,nofity和nofityAll这些方法不放在Thread类当中

一个很明显的原因是JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。如果线程需要等待某些锁那么调用对象中的wait()方法就有意义了。如果wait()方法定义在Thread类中，线程正在等待的是哪个锁就不明显了。简单的说，由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象。

> 15、怎么唤醒一个阻塞的线程

如果线程是因为调用了wait()、sleep()或者join()方法而导致的阻塞，可以中断线程，并且通过抛出InterruptedException来唤醒它；如果线程遇到了IO阻塞，无能为力，因为IO是操作系统实现的，Java代码并没有办法直接接触到操作系统。

> 18、FutureTask是什么

这个其实前面有提到过，FutureTask表示一个异步运算的任务。FutureTask里面可以传入一个Callable的具体实现类，可以对这个异步运算的任务的结果进行等待获取、判断是否已经完成、取消任务等操作。当然，由于FutureTask也是Runnable接口的实现类，所以FutureTask也可以放入线程池中。

> 19、一个线程如果出现了运行时异常怎么办?

如果这个异常没有被捕获的话，这个线程就停止执行了。另外重要的一点是：如果这个线程持有某个某个对象的监视器，那么这个对象监视器会被立即释放

> 20、Java当中有哪几种锁

- 自旋锁: 自旋锁在JDK1.6之后就默认开启了。基于之前的观察，共享数据的锁定状态只会持续很短的时间，为了这一小段时间而去挂起和恢复线程有点浪费，所以这里就做了一个处理，让后面请求锁的那个线程在稍等一会，但是不放弃处理器的执行时间，看看持有锁的线程能否快速释放。为了让线程等待，所以需要让线程执行一个忙循环也就是自旋操作。在jdk6之后，引入了自适应的自旋锁，也就是等待的时间不再固定了，而是由上一次在同一个锁上的自旋时间及锁的拥有者状态来决定
- 偏向锁: 在JDK1.之后引入的一项锁优化，目的是消除数据在无竞争情况下的同步原语。进一步提升程序的运行性能。 偏向锁就是偏心的偏，意思是这个锁会偏向第一个获得他的线程，如果接下来的执行过程中，改锁没有被其他线程获取，则持有偏向锁的线程将永远不需要再进行同步。偏向锁可以提高带有同步但无竞争的程序性能，也就是说他并不一定总是对程序运行有利，如果程序中大多数的锁都是被多个不同的线程访问，那偏向模式就是多余的，在具体问题具体分析的前提下，可以考虑是否使用偏向锁。
- 轻量级锁: 为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁

> 21、如何在两个线程间共享数据

通过在线程之间共享对象就可以了，然后通过wait/notify/notifyAll、await/signal/signalAll进行唤起和等待，比方说阻塞队列BlockingQueue就是为线程之间共享数据而设计的

> 22、如何正确的使用wait()?使用if还是while?

wait() 方法应该在循环调用，因为当线程获取到 CPU 开始执行的时候，其他条件可能还没有满足，所以在处理前，循环检测条件是否满足会更好。下面是一段标准的使用 wait 和 notify 方法的代码：



> 23、什么是线程局部变量ThreadLocal

线程局部变量是局限于线程内部的变量，属于线程自身所有，不在多个线程间共享。Java提供ThreadLocal类来支持线程局部变量，是一种实现线程安全的方式。但是在管理环境下（如 web 服务器）使用线程局部变量的时候要特别小心，在这种情况下，工作线程的生命周期比任何应用变量的生命周期都要长。任何线程局部变量一旦在工作完成后没有释放，Java 应用就存在内存泄露的风险。 

> 29、java中用到的线程调度算法是什么

抢占式。一个线程用完CPU之后，操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。

> 30、Thread.sleep(0)的作用是什么

由于Java采用抢占式的线程调度算法，因此可能会出现某条线程常常获取到CPU控制权的情况，为了让某些优先级比较低的线程也能获取到CPU控制权，可以使用Thread.sleep(0)手动触发一次操作系统分配时间片的操作，这也是平衡CPU控制权的一种操作。





## CAS

CAS，全称为Compare and Swap，即比较-替换。假设有三个操作数：内存值V、旧的预期值A、要修改的值B，当且仅当预期值A和内存值V相同时，才会将内存值修改为B并返回true，否则什么都不做并返回false。当然CAS一定要volatile变量配合，这样才能保证每次拿到的变量是主内存中最新的那个值，否则旧的预期值A对某条线程来说，永远是一个不会变的值A，只要某次CAS操作失败，永远都不可能成功

## 乐观锁和悲观锁

* 乐观锁：乐观锁认为竞争不总是会发生，因此它不需要持有锁，将比较-替换这两个动作作为一个原子操作尝试去修改内存中的变量，如果失败则表示发生冲突，那么就应该有相应的重试逻辑。
* 悲观锁：悲观锁认为竞争总是会发生，因此每次对某资源进行操作时，都会持有一个独占的锁，就像synchronized，不管三七二十一，直接上了锁就操作资源了。

得分点 乐观锁、悲观锁定义及使用场景 标准回答 

|      | 乐观锁                                                       | 悲观锁                                                       |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 概述 | 乐观锁总是假设最好的情况,每次去拿数据的时候都认为别人不会修改,所以不会上锁,但是在更新的时候会判断一下在此期间别人有没有去更新这个数据, | 悲观锁总是假设最坏的情况,每次去拿数据的时候都认为别人会修改,所以每次在拿数据的时候都会上锁,这样别人想拿这个数据就会阻塞直到它拿到锁 |
| 实现 | 可以使用版本号机制和CAS算法实现。像数据库提供的类似于write_condition机制,其实都是提供的乐观锁。 | 传统的关系型数据库里边就用到了很多这种锁机制,比如行锁,表锁等,读锁,写锁等,都是在做操作之前先上锁。 |
| 场景 | 乐观锁适用于多读的应用类型,这样可以提高吞吐量                | 悲观锁的好处在于可以减少并发,但是当并发量非常大的时候,由于锁消耗资源、锁定时间过长等原因,很容易导致系统性能下降,资源消耗严重。 |
| 举例 | GIT,SVN,CVS等代码版本控制管理器,就是一个乐观锁使用很好的场景,例如：A、B程序员,同时从SVN服务器上下载了code.html文件,当A完成提交后,此时B再提交,那么会报版本冲突,此时需要B进行版本处理合并后,再提交到服务器。这其实就是乐观锁的实现全过程。如果此时使用的是悲观锁,那么意味者所有程序员都必须一个一个等待操作提交完,才能访问文件,这是难以接受的。 | 因此一般我们可以在并发量不是很大,并且出现并发情况导致的异常用户和系统都很难以接受的情况下,会选择悲观锁进行。 |





> 37、CyclicBarrier和CountDownLatch区别

这两个类非常类似，都在java.util.concurrent下，都可以用来表示代码运行到某个点上，二者的区别在于：

- CyclicBarrier的某个线程运行到某个点上之后，该线程即停止运行，直到所有的线程都到达了这个点，所有线程才重新运行；CountDownLatch则不是，某线程运行到某个点上之后，只是给某个数值-1而已，该线程继续运行
- CyclicBarrier只能唤起一个任务，CountDownLatch可以唤起多个任务
- CyclicBarrier可重用，CountDownLatch不可重用，计数值为0该CountDownLatch就不可再用了



# 面试题

## start、run方法区别

* 当程序调用start()方法，一个新的线程会被创建，此时新线程处于就绪状态，等待cpu时间片，得到时间片后run()方法中的代码将会被执行。（要注意的是run方法是自动被调用的，并不需要手工调用）

* 当直接调用run方法时，并不会生成新线程，而是在当前线程执行run方法中的代码

##  sleep() 和 wait() 

|      | sleep                  | wait             |
| ---- | ---------------------- | ---------------- |
|      | 没有释放锁             | 释放锁           |
| 来源 | Thread类               | Object类         |
| 唤醒 | 指定睡眠时间，自动唤醒 | 配合notify()唤醒 |
| 用途 | 暂停执行               | 进程间交互       |
|      |                        | 搭配while使用    |

## ++操作符

不是线程安全的操作。它涉及到多个指令，如读取变量值，增加，然后存储回内存，这个过程可能会出现多个线程交叉访问标量

