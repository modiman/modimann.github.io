# 多线程并发

## 参考文献

* [面试官：说说多线程并发问题](https://juejin.cn/post/6844903941830869006)

## 1、进程,线程,协程

**说说进程,线程,协程之间的区别**

简而言之,**最本质的区别在于进程拥有自己的一整套变量，线程则共享数据**

* 进程是程序运行和资源分配的基本单位,一个程序至少有一个进程,一个进程至少有一个线程.
* 共享变量使线程之间的通信比进程更有效、更容易
* 进程在执行过程中拥有独立的内存单元,而多个线程共享内存资源,减少切换次数,从而效率更高.
* 线程是进程的一个实体,是cpu调度和分派的基本单位,是比程序更小的能独立运行的基本单位.
* 同一进程中的多个线程之间可以并发执行.

### 协程

一个线程可以有多个协程，协程是完全由用户进程进行管理，与操作系统无关，因此其完全在用户态运行，不存在上下文切换的开销，且可以在线程中乱序（异步）执行，没有同步开销，协程还可以保留每一次运行后的状态，重入时即从上一次状态开始运行

## 创建线程方式

4、创建两种线程的方式?他们有什么区别?

通过实现java.lang.Runnable或者通过扩展java.lang.Thread类.相比扩展Thread,实现Runnable接口可能更优.原因有二:

- Java不支持多继承.因此扩展Thread类就代表这个子类不能扩展其他类.而实现Runnable接口的类还可以扩展另一个类.
- 类可能只要求可执行即可,因此继承整个Thread类的开销过大.
- 为每个任务常见一个独立的线程开销太大，可以使用线程池解决这个问题

方法一：实现runable

```java
public class MyThread implements Runnable {
    @Override
    public void run() {
        for (int i=0;i<10;i++)
            System.out.println(i);
    }

    public static void main(String[] args) {
        Runnable r = new MyThread();
        Thread t = new Thread(r);
        t.start();
    }
}

```

方法二:继承Thead

```java
static class NewThread extends Thread{
        public void run(){
            for (int i=0;i<10;i++){
                System.out.println(NewThread.class.toString()+": "+i);
            }
        }
    }
```

## 中断线程

## 线程状态

* New 新生
* Runnable 可运行
* Blocked 被阻塞
* waiting 等待
* Timed Waiting  计时等待
* Terminated  被终止

|                             |                                                    |
| --------------------------- | -------------------------------------------------- |
| New 新生                    | 创建后、运行前                                     |
| Runnable 可运行             | 可能在运行、也可能不在运行                         |
| Blocked 被阻塞 waiting 等待 | 线程试图获得一个对象的内部锁，而该锁被其他线程占用 |
|                             |                                                    |
|                             |                                                    |

* 线程试图获得一个对象的内部锁，而该锁被其他线程占用，线程进入阻塞状态；当所有其他线程释放该锁，且线程调度器允许该线程持有它的时候，线程变成非阻塞状态
* 等待另一个线程通知调度器的一个条件时，线程进入等待状态。比如调用Object.wait方法或Thread.join方法。或是等待java.util.concurrent库中的Lock或Condition
* 有几个方法拥有超时参数，调用它们导致线程进入计数等待；这一状态持续带计时期满或者接收到适当的通知。带有超时参数的方法有Thread.sleep和Object.wait、Thread.join、Lock.tryLock以及Condition.await的计时版

### 线程终止的原因

1. 因为run方法正常退出而死亡
2. 因为一个没有捕获的异常终止了run方法，意外死亡

## 线程属性

### 线程优先级

- 线程继承父线程的优先级

- setPriority可以设置线程优先级，可以设置为1-10之间的值

### 守护线程

- 使用t.setDaemon(true)调用，必须在线程启动之前调用

守护线程的唯一用途就是为其他线程提供服务。当只剩下守护线程时，虚拟机就退出了。

### 未捕获异常处理器

## 同步

### 竞争条件

两个或以上线程存取相同的数据

### 详解竞争条件

假设两个线程都要执行以下语句

- 取出accounts

- accounts += 500

- 放回accounts

如果线程一执行完前两步就被剥夺了运行权，线程二执行结束后线程一又执行了第三步，那么线程二所做的修改将被抹去

**假如有一个转移资产的方法**

```java
    public void transfer(int from,int to,double amount){
        accounts[from] -= amount;
        System.out.println(Thread.currentThread());
        accounts[to]+=amount;
        System.out.println("从"+from+"到"+to);
        System.out.printf("Total: %10.2f%n",getTotalBalance());
    }
```

这一段代码可能会因为种种原因没执行完就被剥夺了运行权（可能是由于打印，但不一定），那么accounts就会出现错误数据

如何解决？对这段代码加锁，在它执行完之前另一个线程不能执行这段代码

两种锁

### synchronized

```java
    public synchronized void transfer(int from,int to,double amount){
        accounts[from] -= amount;
        System.out.println(Thread.currentThread());
        accounts[to]+=amount;
        System.out.println("从"+from+"到"+to);
        System.out.printf("Total: %10.2f%n",getTotalBalance());
    }
```

### ReentrantLock

```java
ReentrantLock rt = new ReentrantLock();
public  void transfer(int from,int to,double amount){
        rt.lock();
        try {
            accounts[from] -= amount;
            System.out.println(Thread.currentThread());
            accounts[to]+=amount;
            System.out.println("从"+from+"到"+to);
            System.out.printf("Total: %10.2f%n",getTotalBalance());
        }
        finally {
            rt.unlock();
        }

    }
```

### 锁对象

下文详解

从java se 5以后，有两种机制防止代码块受并发控制的干扰。

- synchronized关键字

- volatile能保证数据的可见性，但不能完全保证数据的原子性，

- synchronized即保证了数据的可见性也保证了原子性

### 



（645页）

- 锁用来保护代码片段，任何时刻只能有一个线程执行被保护的代码

- 所可以管理试图进入被保护代码的线程

- 锁可以拥有一个或多个相关的条件对象

- 每个条件对象管理那些已经进入被保护的代码段但还不能运行的线程

如果一个方法使用synchronized声明，那么对象的锁将保护整个方法，也就是说，要调用该方法，线程必须获得对象的内部锁





### 条件对象



## **14.5.8** volatile域

有时，仅仅需要读写一两个实例域就使用同步，显得开销太大了。

***\*volatile关键字为实例域的同步访问提供了一种免锁机制\**，如果声明一个域为volatile，那么编译器和虚拟机就知道该域是可能被另一个进程并发更新的**

volatile变量不能提供原子性，

总之，在以下三种情况下域的并发访问是安全的

1. 域是final,并且在构造完成后被访问

2. 对域的访问由共有的锁进行保护

3. 域是valatile的



## 执行器

构建一个新的线程是有一定的代价的，因为设计与操作系统的交互。如果程序中创建了大量的生命期很短的线程，**应该使用线程池。**一个线程池包含了很多准备运行的空闲线程。将Runnable对象交给线程池，就会有一个线程调用run方法，当run方法结束时线程不会死亡，而是准备为下一个请求提供服务。

另一个使用线程池的理由是减少并发线程的数目。

执行器类（Executor）有很多静态工厂方法创建线程池。

## 14.10 同步器



同步器



类

它能做什么

何时使用

CyclicBarrier

允许线程集等待直至其中预定数目的线程到达一个公共障栏，然后可以选择执行一个处理障栏的动作

当大量的线程需要在他们的结果可用之前完成时

## 一、多线程为什么会有并发问题

为什么多线程同时访问（读写）同个变量，会有并发问题？

> 1. Java 内存模型规定了所有的变量都存储在主内存中，每条线程有自己的工作内存。
> 2. 线程的工作内存中保存了该线程中用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。
> 3. 线程访问一个变量，首先将变量从主内存拷贝到工作内存，对变量的写操作，不会马上同步到主内存。
> 4. 不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。

## 二、Java 内存模型（JMM）

Java 内存模型(JMM) 作用于工作内存（本地内存）和主存之间数据同步过程，它规定了如何做数据同步以及什么时候做数据同步，如下图。



![JMM](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/9/15/16d32c69d2b91f19~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)



## 三、并发三要素

**原子性**：在一个操作中，CPU 不可以在中途暂停然后再调度，即不被中断操作，要么执行完成，要么就不执行。

**可见性**：多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

**有序性**：程序执行的顺序按照代码的先后顺序执行。

## 四、怎么做，才能解决并发问题？（重点）

下面结合不同场景分析解决并发问题的处理方式。

### 一、volatile

#### 1.1 volatile 特性

**保证可见性，不保证原子性**

> 1. 当写一个volatile变量时，JVM会把本地内存的变量强制刷新到主内存中
> 2. 这个写操作导致其他线程中的缓存无效，其他线程读，会从主内存读。volatile的写操作对其它线程实时可见。

**禁止指令重排序** 指令重排序是指编译器和处理器为了优化程序性能对指令进行排序的一种手段，需要遵守一定规则：

> 1. 不会对存在依赖关系的指令重排序，例如 a = 1;b = a;  a 和b存在依赖关系，不会被重排序
> 2. 不能影响单线程下的执行结果。比如：a=1;b=2;c=a+b这三个操作,前两个操作可以重排序，但是c=a+b不会被重排序，因为要保证结果是3

#### 1.2 使用场景

对于一个变量，只有一个线程执行写操作，其它线程都是读操作，这时候可以用 volatile 修饰这个变量。

#### 1.3 单例双重锁为什么要用到volatile？

```java
public class TestInstance {

private static volatile TestInstance mInstance;

public static TestInstance getInstance(){       //1
    if (mInstance == null){                     //2
        synchronized (TestInstance.class){      //3
            if (mInstance == null){             //4
                mInstance = new TestInstance(); //5
            }
        }
    }
    return mInstance;
	}
}
```



假如没有用volatile，并发情况下会出现问题，线程A执行到注释5 `new TestInstance()` 的时候，分为如下几个几步操作：

1. 分配内存
2. 初始化对象
3. mInstance 指向内存

这时候如果发生指令重排，执行顺序是132，执行到第3的时候，线程B刚好进来了，并且执行到注释2，这时候判断mInstance 不为空，直接使用一个未初始化的对象。所以使用volatile关键字来禁止指令重排序。

#### 1.4 volatile 原理

在JVM底层volatile是采用**内存屏障**来实现的，内存屏障会提供3个功能：

> 1. 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
> 2. 它会强制将缓存的修改操作立即写到主内存
> 3. 写操作会导致其它CPU中的缓存行失效，写之后，其它线程的读操作会从主内存读。

#### 1.5 volatile 的局限性

**volatile 只能保证可见性，不能保证原子性**写操作对其它线程可见，但是不能解决多个线程同时写的问题。

> 1、可以创建Volatile数组吗?

Java 中可以创建 volatile类型数组，不过只是一个指向数组的引用，而不是整个数组。如果改变引用指向的数组，将会受到volatile 的保护，但是如果多个线程同时改变数组的元素，volatile标示符就不能起到之前的保护作用了

> 2、volatile能使得一个非原子操作变成原子操作吗?

一个典型的例子是在类中有一个 long 类型的成员变量。如果你知道该成员变量会被多个线程访问，如计数器、价格等，你最好是将其设置为 volatile。为什么？因为 Java 中读取 long 类型变量不是原子的，需要分成两步，如果一个线程正在修改该 long 变量的值，另一个线程可能只能看到该值的一半（前 32 位）。但是对一个 volatile 型的 long 或 double 变量的读写是原子。

一种实践是用 volatile 修饰 long 和 double 变量，使其能按原子类型来读写。double 和 long 都是64位宽，因此对这两种类型的读是分为两部分的，第一次读取第一个 32 位，然后再读剩下的 32 位，这个过程不是原子的，但 Java 中 volatile 型的 long 或 double 变量的读写是原子的。volatile 修复符的另一个作用是提供内存屏障（memory barrier），例如在分布式框架中的应用。简单的说，就是当你写一个 volatile 变量之前，Java 内存模型会插入一个写屏障（write barrier），读一个 volatile 变量之前，会插入一个读屏障（read barrier）。意思就是说，在你写一个 volatile 域时，能保证任何线程都能看到你写的值，同时，在写之前，也能保证任何数值的更新对所有线程是可见的，因为内存屏障会将其他所有写的值更新到缓存。

> 3、volatile类型变量提供什么保证?

volatile 主要有两方面的作用:1.避免指令重排2.可见性保证.例如，JVM 或者 JIT为了获得更好的性能会对语句重排序，但是 volatile 类型变量即使在没有同步块的情况下赋值也不会与其他语句重排序。 volatile 提供 happens-before 的保证，确保一个线程的修改能对其他线程是可见的。某些情况下，volatile 还能提供原子性，如读 64 位数据类型，像 long 和 double 都不是原子的(低32位和高32位)，但 volatile 类型的 double 和 long 就是原子的.

### 二、Synchronized

#### 2.1 Synchronized 使用场景

多个线程同时写一个变量。

例如售票，余票是100张，窗口A和窗口B同时各卖出一张票， 假如余票变量用 volatile 修饰，是有问题的。
 A窗口获取余票是100，B窗口获取余票也是100，A卖出一张变成99，刷新回主内存，同时B卖出一张变成99，也刷新回主内存，会导致最终主内存余票是99而不是98。

前面说到 volatile 的局限性，就是多个线程同时写的情况，这种情况一般可以使用**Synchronized**。

**Synchronized 可以保证同一时刻，只有一个线程可执行某个方法或某个代码块。**

#### 2.2 Synchronized 原理

```java
public class SynchronizedTest {

public static void main(String[] args) {
    synchronized (SynchronizedTest.class) {
        System.out.println("123");
    }
    method();
}

private static void method() {
}
}
```

将这段代码先用`javac`命令编译，再`java p -v SynchronizedTest.class`命令查看字节码，部分字节码如下

```java
public static void main(java.lang.String[]);
descriptor: ([Ljava/lang/String;)V
flags: ACC_PUBLIC, ACC_STATIC
Code:
  stack=2, locals=3, args_size=1
     0: ldc           #2                  // class com/lanshifu/opengldemo/test/SynchronizedTest
     2: dup
     3: astore_1
     4: monitorenter
     5: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;
     8: ldc           #4                  // String 123
    10: invokevirtual #5                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
    13: aload_1
    14: monitorexit
    15: goto          23
    18: astore_2
    19: aload_1
    20: monitorexit
    21: aload_2
    22: athrow
    23: invokestatic  #6                  // Method method:()V
    26: return
```

可以看到 `4: monitorenter` 和 `14: monitorexit`，中间是打印的语句。

执行同步代码块，首先会执行`monitorenter`指令，然后执行同步代码块中的代码，退出同步代码块的时候会执行`monitorexit`指令 。

> 使用Synchronized进行同步，其关键就是必须要对对象的监视器monitor进行获取，当线程获取monitor后才能继续往下执行，否则就进入同步队列，线程状态变成BLOCK，同一时刻只有一个线程能够获取到monitor，当监听到monitorexit被调用，队列里就有一个线程出队，获取monitor。详情参考：[www.jianshu.com/p/d53bf830f…](https://link.juejin.cn?target=https%3A%2F%2Fwww.jianshu.com%2Fp%2Fd53bf830fa09)

每个对象拥有一个计数器，当线程获取该对象锁后，计数器就会加一，释放锁后就会将计数器减一，所以只要这个锁的计数器大于0，其它线程访问就只能等待。

#### 2.3 Synchronized 锁的升级

大家对Synchronized的理解可能就是重量级锁，但是Java1.6对 Synchronized 进行了各种优化之后，有些情况下它就并不那么重，Java1.6 中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁。

**偏向锁：** 大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。

> 当一个线程A访问加了同步锁的代码块时，会在对象头中存 储当前线程的id，后续这个线程进入和退出这段加了同步锁的代码块时，不需要再次加锁和释放锁。

**轻量级锁：** 在偏向锁情况下，如果线程B也访问了同步代码块，比较对象头的线程id不一样，会升级为轻量级锁，并且通过自旋的方式来获取轻量级锁。

**重量级锁：** 如果线程A和线程B同时访问同步代码块，则轻量级锁会升级为重量级锁，线程A获取到重量级锁的情况下，线程B只能入队等待，进入BLOCK状态。

#### 2.4  Synchronized 缺点

1. 不能设置锁超时时间
2. 不能通过代码释放锁
3. 容易造成死锁

### 三、ReentrantLock

上面说到`Synchronized`的缺点，不能设置锁超时时间和不能通过代码释放锁，`ReentranLock`就可以解决这个问题。

**在多个条件变量和高度竞争锁的地方，用ReentrantLock更合适**，ReentrantLock还提供了`Condition`，对线程的等待和唤醒等操作更加灵活，一个ReentrantLock可以有多个Condition实例，所以更有扩展性。

#### 3.1 ReentrantLock 的使用

**lock 和 unlock**

```java
        ReentrantLock reentrantLock = new ReentrantLock();
        System.out.println("reentrantLock->lock");
        reentrantLock.lock();
        try {
            
            System.out.println("睡眠2秒...");
            Thread.sleep(2000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }finally {
            reentrantLock.unlock();
            System.out.println("reentrantLock->unlock");
        }
```

**实现可定时的锁请求：tryLock**

```java
    public static void main(String[] args) {
        ReentrantLock reentrantLock = new ReentrantLock();
        Thread thread1 = new Thread_tryLock(reentrantLock);
        thread1.setName("thread1");
        thread1.start();
        Thread thread2 = new Thread_tryLock(reentrantLock);
        thread2.setName("thread2");
        thread2.start();
}


    static class Thread_tryLock extends Thread {
        ReentrantLock reentrantLock;

        public Thread_tryLock(ReentrantLock reentrantLock) {
            this.reentrantLock = reentrantLock;
        }

        @Override
        public void run() {
            try {
                System.out.println("try lock:" + Thread.currentThread().getName());
                boolean tryLock = reentrantLock.tryLock(3, TimeUnit.SECONDS);
                if (tryLock) {
                    System.out.println("try lock success :" + Thread.currentThread().getName());
                    System.out.println("睡眠一下：" + Thread.currentThread().getName());
                    Thread.sleep(5000);
                    System.out.println("醒了：" + Thread.currentThread().getName());
                } else {
                    System.out.println("try lock 超时 :" + Thread.currentThread().getName());
                }

            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                System.out.println("unlock:" + Thread.currentThread().getName());
                reentrantLock.unlock();
            }
        }
    }
```

打印的日志：

```
try lock:thread1
try lock:thread2
try lock success :thread2
睡眠一下：thread2
try lock 超时 :thread1
unlock:thread1
Exception in thread "thread1" java.lang.IllegalMonitorStateException
	at java.util.concurrent.locks.ReentrantLock$Sync.tryRelease(ReentrantLock.java:151)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.release(AbstractQueuedSynchronizer.java:1261)
	at java.util.concurrent.locks.ReentrantLock.unlock(ReentrantLock.java:457)
	at com.lanshifu.demo_module.test.lock.ReentranLockTest$Thread_tryLock.run(ReentranLockTest.java:60)
醒了：thread2
unlock:thread2
```

上面演示了`trtLock`的使用，`trtLock`设置获取锁的等待时间，超过3秒直接返回失败，可以从日志中看到结果。 有异常是因为thread1获取锁失败，不应该调用unlock。

#### 3.2 Condition 条件

```java
public static void main(String[] args) {

        Thread_Condition thread_condition = new Thread_Condition();
        thread_condition.setName("测试Condition的线程");
        thread_condition.start();
        try {
            Thread.sleep(2000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        thread_condition.singal();

    }


static class Thread_Condition extends Thread {

        @Override
        public void run() {
            await();
        }

        private ReentrantLock lock = new ReentrantLock();
        public Condition condition = lock.newCondition();

        public void await() {
            try {
                System.out.println("lock");
                lock.lock();
                System.out.println(Thread.currentThread().getName() + ":我在等待通知的到来...");
                condition.await();//await 和 signal 对应
                //condition.await(2, TimeUnit.SECONDS); //设置等待超时时间
                System.out.println(Thread.currentThread().getName() + ":等到通知了，我继续执行>>>");
            } catch (Exception e) {
                e.printStackTrace();
            } finally {
                System.out.println("unlock");
                lock.unlock();
            }
        }

        public void singal() {
            try {
                System.out.println("lock");
                lock.lock();
                System.out.println("我要通知在等待的线程，condition.signal()");
                condition.signal();//await 和 signal 对应
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                System.out.println("unlock");
                lock.unlock();
            }
        }
    }
```

运行打印日志

```
lock
测试Condition的线程:我在等待通知的到来...
lock
我要通知在等待的线程，condition.signal()
unlock
测试Condition的线程:等到通知了，我继续执行>>>
unlock
```

上面演示了`Condition的 await 和 signal` 使用，前提要先lock。

#### 3.3 公平锁与非公平锁

ReentrantLock 构造函数传true表示公平锁。

公平锁表示线程获取锁的顺序是按照线程加锁的顺序来分配的，即先来先得的顺序。而非公平锁就是一种锁的抢占机制，是随机获得锁的，可能会导致某些线程一致拿不到锁，所以是不公平的。

#### 3.4 ReentrantLock  注意点

1. ReentrantLock使用lock和unlock来获得锁和释放锁
2. unlock要放在finally中，这样正常运行或者异常都会释放锁
3. 使用condition的await和signal方法之前，必须调用lock方法获得对象监视器

### 四、并发包

通过上面分析，并发严重的情况下，使用锁显然效率低下，因为同一时刻只能有一个线程可以获得锁，其它线程只能乖乖等待。

Java提供了并发包解决这个问题，接下来介绍并发包里一些常用的数据结构。

#### 4.1 ConcurrentHashMap

**我们都知道HashMap是线程不安全的数据结构，HashTable则在HashMap基础上，get方法和put方法加上Synchronized修饰变成线程安全，不过在高并发情况下效率底下，最终被`ConcurrentHashMap`替代。**

ConcurrentHashMap 采用分段锁，内部默认有16个桶，get和put操作，首先将key计算hashcode，然后跟16取余，落到16个桶中的一个，然后每个桶中都加了锁（ReentrantLock），桶中是HashMap结构（数组加链表，链表过长转红黑树）。

所以理论上最多支持16个线程同时访问。

#### 4.2 LinkBlockingQueue

链表结构的阻塞队列，内部使用多个ReentrantLock

```java
    /** Lock held by take, poll, etc */
    private final ReentrantLock takeLock = new ReentrantLock();

    /** Wait queue for waiting takes */
    private final Condition notEmpty = takeLock.newCondition();

    /** Lock held by put, offer, etc */
    private final ReentrantLock putLock = new ReentrantLock();

    /** Wait queue for waiting puts */
    private final Condition notFull = putLock.newCondition();

private void signalNotEmpty() {
        final ReentrantLock takeLock = this.takeLock;
        takeLock.lock();
        try {
            notEmpty.signal();
        } finally {
            takeLock.unlock();
        }
    }

    /**
     * Signals a waiting put. Called only from take/poll.
     */
    private void signalNotFull() {
        final ReentrantLock putLock = this.putLock;
        putLock.lock();
        try {
            notFull.signal();
        } finally {
            putLock.unlock();
        }
    }
```

源码不贴太多，简单说一下`LinkBlockingQueue` 的逻辑：

> 1. 从队列获取数据，如果队列中没有数据，会调用`notEmpty.await();`进入等待。
> 2. 在放数据进去队列的时候会调用`notEmpty.signal();`，通知消费者，1中的等待结束，唤醒继续执行。
> 3. 从队列里取到数据的时候会调用`notFull.signal();`，通知生产者继续生产。
> 4. 在put数据进入队列的时候，如果判断队列中的数据达到最大值，那么会调用`notFull.await();`，等待消费者消费掉，也就是等待3去取数据并且发出`notFull.signal();`，这时候生产者才能继续生产。

`LinkBlockingQueue` 是典型的生产者消费者模式，源码细节就不多说。

#### 4.3  原子操作类：AtomicInteger

内部采用CAS（compare and swap）保证原子性

举一个int自增的例子

```
        AtomicInteger atomicInteger = new AtomicInteger(0);
        atomicInteger.incrementAndGet();//自增
```

源码看一下

```
   /**
     * Atomically increments by one the current value.
     *
     * @return the updated value
     */
    public final int incrementAndGet() {
        return U.getAndAddInt(this, VALUE, 1) + 1;
    }
```

U 是 Unsafe，看下 `Unsafe#getAndAddInt`

```
    public final int getAndAddInt(Object var1, long var2, int var4) {
        int var5;
        do {
            var5 = this.getIntVolatile(var1, var2);
        } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));

        return var5;
    }
```

通过`compareAndSwapInt`保证原子性。

## 五、总结

面试中问到多线程并发问题，可以这么答：

> 1. 当只有一个线程写，其它线程都是读的时候，可以用`volatile`修饰变量
> 2. 当多个线程写，那么一般情况下并发不严重的话可以用`Synchronized`，Synchronized并不是一开始就是重量级锁，在并发不严重的时候，比如只有一个线程访问的时候，是偏向锁；当多个线程访问，但不是同时访问，这时候锁升级为轻量级锁；当多个线程同时访问，这时候升级为重量级锁。所以在并发不是很严重的情况下，使用Synchronized是可以的。不过Synchronized有局限性，比如不能设置锁超时，不能通过代码释放锁。
> 3. `ReentranLock` 可以通过代码释放锁，可以设置锁超时。
> 4. 高并发下，Synchronized、ReentranLock 效率低，因为同一时刻只有一个线程能进入同步代码块，如果同时有很多线程访问，那么其它线程就都在等待锁。这个时候可以使用并发包下的数据结构，例如`ConcurrentHashMap`，`LinkBlockingQueue`，以及原子性的数据结构如：`AtomicInteger`。

面试的时候按照上面总结的这个思路回答基本就ok了。既然说到并发包，那么除了`ConcurrentHashMap`，其它一些常用的数据结构的原理也需要去了解下，例如`HashMap、HashTable、TreeMap`原理，`ArrayList、LinkedList`对比，这些都是老生常谈的，自己去看源码或者一些博客。

关于多线程并发就先总结到这里，如果是应付面试的话按照这篇文章的思路来准备应该是没太大问题的。


作者：蓝师傅
链接：https://juejin.cn/post/6844903941830869006
来源：稀土掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

## 线程池

* [拒绝策略](https://mp.weixin.qq.com/s?__biz=MzkyMjI1OTgxNA==&mid=2247496664&idx=1&sn=eca3c9774333d77fa8afdb50c61070e9&source=41#wechat_redirect)
* [java高级应用：线程池全面解析](http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247483824&idx=1&sn=7e34a3944a93d649d78d618cf04e0619&chksm=eb538486dc240d903d6f3ae80b7cd00455b2125c5ff01d118ce6f17a7a75b81661800f9be760&scene=21#wechat_redirect)
* 

### 背景

频繁的创建和销毁线程会产生巨大的CPU开销，因此设计线程池来复用线程，以此避免耗费CPU、内存资源，GC频繁收集和停顿。

### 线程核心类ThreadPoolExecutor

​	基本组成

- corePoolSize：线程池的核心大小，也可以理解为最小的线程池大小。 int
- maximumPoolSize：最大线程池大小。int 
- keepAliveTime：空余线程存活时间，指的是超过corePoolSize的空余线程达到多长时间才进行销毁。long
- unit：销毁时间单位。 TimeUnit
- workQueue：存储等待执行线程的工作队列。 BlockingQueue
- threadFactory：创建线程的工厂，一般用默认即可。 ThreadFactory
- handler：拒绝策略，当工作队列、线程池全已满时如何拒绝新任务，默认抛出异常。

### 核心线程池数量

IO密集型=2Ncpu（可以测试后自己控制大小，2Ncpu一般没问题）（常出现于线程中：数据库数据交互、文件上传下载、网络数据传输等等）

计算密集型=Ncpu（常出现于线程中：复杂算法）

**java中：Ncpu=`Runtime.getRuntime().availableProcessors()`**


作者：二十六画生的博客
链接：https://juejin.cn/post/6985042008297455629
来源：稀土掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。****

###   为什么是要等核心线程数满了之后再去开创非核心线程数，而不是来了任务直接开启非核心线程数。 

* 核心线程数以内的线程是常驻线程，占用固定数量的CPU资源
* 大小设定取决于系统需求
* 任务来了直接开启违背了线程复用的初衷，线程的创建于销毁是一件开销不小的任务



### 线程池工作流程

1、如果线程池中的线程**小于**corePoolSize时就会创建新线程直接执行任务。

2、如果线程池中的线程**大于**corePoolSize时就会暂时把任务存储到工作队列workQueue中等待执行。

3、如果工作队列workQueue也满时：当线程数小于最大线程池数maximumPoolSize时就会创建新线程来处理，而线程数大于等于最大线程池数maximumPoolSize时就会执行拒绝策略。

### 线程池分类

Executors是jdk里面提供的创建线程池的工厂类，它默认提供了4种常用的线程池应用，而不必我们去重复构造。

#### newFixedThreadPool

固定线程池，核心线程数和最大线程数固定相等，而空闲存活时间为0毫秒，说明此参数也无意义，工作队列为最大为Integer.MAX_VALUE大小的阻塞队列。当执行任务时，如果线程都很忙，就会丢到工作队列等有空闲线程时再执行，队列满就执行默认的拒绝策略。

#### newCachedThreadPool

​    带缓冲线程池，从构造看核心线程数为0，最大线程数为Integer最大值大小，超过0个的空闲线程在60秒后销毁，SynchronousQueue这是一个直接提交的队列，意味着每个新任务都会有线程来执行，如果线程池有可用线程则执行任务，没有的话就创建一个来执行，线程池中的线程数不确定，一般建议执行速度较快较小的线程，不然这个最大线程池边界过大容易造成内存溢出。

#### newSingleThreadExecutor

​        单线程线程池，核心线程数和最大线程数均为1，空闲线程存活0毫秒同样无意思，意味着每次只执行一个线程，多余的先存储到工作队列，一个一个执行，保证了线程的顺序执行。

#### newScheduledThreadPool

调度线程池，即按一定的周期执行任务，即定时任务，对ThreadPoolExecutor进行了包装而已。

### 提交线程池

```java
如可以先随便定义一个固定大小的线程池

ExecutorService es = Executors.newFixedThreadPool(3);



提交一个线程

es.submit(xxRunnble);

es.execute(xxRunnble);
```

#### submit和execute

execute没有返回值，如果不需要知道线程的结果就使用execute方法，性能会好很多。

submit返回一个Future对象，如果想知道线程结果就使用submit提交，而且它能在主线程中通过Future的get方法捕获线程中的异常

### 拒绝策略

当线程池满了之后，新来的线程需要被拒绝。

#### AbortPolicy

 简单粗暴，直接抛出拒绝异常，这也是默认的拒绝策略。

#### CallerRunsPolicy

 如果线程池未关闭，则会在调用者线程中直接执行新任务，这会导致主线程提交线程性能变慢。

**使用场景**：一般在不允许失败的、对性能要求不高、并发量较小的场景下使用，因为线程池一般情况下不会关闭，也就是提交的任务一定会被运行，但是由于是调用者线程自己执行的，当多次提交任务时，就会阻塞后续任务执行，性能和效率自然就慢了。

#### DiscardPolicy

   从方法看没做任务操作，即表示不处理新任务，即丢弃。

#### DiscardOldestPolicy

抛弃最老的任务，就是从队列取出最老的任务然后放入新的任务进行执行。 

### 关闭线程池

**es.shutdown();** 

不再接受新的任务，之前提交的任务等执行结束再关闭线程池。

**es.shutdownNow();**

不再接受新的任务，试图停止池中的任务再关闭线程池，返回所有未处理的线程list列表。

## [六大*进程通信*机制原理](https://zhuanlan.zhihu.com/p/465574868)



目录

初学操作系统的时候，我就一直懵逼，为啥进程同步与互斥机制里有信号量机制，进程通信里又有信号量机制，然后你再看网络上的各种面试题汇总或者博客，你会发现很多都是千篇一律的进程通信机制有哪些？进程同步与互斥机制鲜有人问津。看多了我都想把 CSDN 屏了.....，最后知道真相的我只想说为啥不能一篇博客把东西写清楚，没头没尾真的浪费时间。希望这篇文章能够拯救某段时间和我一样被绕晕的小伙伴。上篇文章我已经讲过进程间的同步与互斥机制，各位小伙伴看完这个再来看进程通信比较好。**全文脉络思维导图如下：**![img](https://pic2.zhimg.com/v2-05357079c73568813ec18658a5e803c1_b.jpg)一. 什么是进程通信顾名思义，进程通信（ InterProcess Communication，IPC）就是指**进程之间的信息交换**。实际上，**进程的同步与互斥本质上也是一种进程通信**（这也就是待会我们会在进程通信机制中看见信号量和 PV 操作的原因了），只不过它传输的仅仅是[信号量](https://www.zhihu.com/search?q=信号量&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})，通过修改信号量，使得进程之间建立联系，相互协调和协同工作，但是它**缺乏传递数据的能力**。虽然存在某些情况，进程之间交换的信息量很少，比如仅仅交换某个状态信息，这样进程的同步与互斥机制完全可以胜任这项工作。但是大多数情况下，**进程之间需要交换大批数据**，比如传送一批信息或整个文件，这就需要通过一种新的通信机制来完成，也就是所谓的进程通信。再来从操作系统层面直观的看一些进程通信：我们知道，为了保证安全，每个进程的用户地址空间都是独立的，一般而言一个进程不能直接访问另一个进程的地址空间，不过内核空间是每个进程都共享的，所以**进程之间想要进行信息交换就必须通过内核**。![img](https://pic2.zhimg.com/v2-1c0a8bc38f13325491ab6a8b0f781be1_b.jpg)
下面就来我们来列举一下 Linux 内核提供的常见的进程通信机制：管道（也称作共享文件）消息队列（也称作消息传递）共享内存（也称作共享存储）信号量和 PV 操作信号套接字（Socket）![img](https://pic1.zhimg.com/v2-b8374d9d3ede89608ee38a95136b6c1c_b.jpghttps://link.zhihu.com/?target=https%3A//docs.qq.com/doc/DTkZRWXRFcWx1bWVx)

二. 管道**匿名管道**各位如果学过 Linux 命令，那对管道肯定不陌生，Linux 管道使用竖线 | 连接多个命令，这被称为管道符。`$ command1 | command2`以上这行代码就组成了一个管道，它的功能是将前一个命令（command1）的输出，作为后一个命令（command2）的输入，从这个功能描述中，我们可以看出**管道中的数据只能单向流动**，也就是半双工通信，如果想实现相互通信（全双工通信），我们需要创建两个管道才行。另外，通过管道符 | 创建的管道是匿名管道，用完了就会被自动销毁。并且，匿名管道只能在具有亲缘关系（父子进程）的进程间使用，。也就是说，**匿名管道只能用于父子进程之间的通信**。在 Linux 的实际编码中，是通过 pipe 函数来创建匿名管道的，若创建成功则返回 0，创建失败就返回 -1：`int pipe (int fd[2]);`**该函数拥有一个存储空间为 2 的[文件描述符](https://www.zhihu.com/search?q=文件描述符&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})数组：**fd[0] 指向管道的读端，fd[1] 指向管道的写端fd[1] 的输出是 fd[0] 的输入**粗略的解释一下通过匿名管道实现进程间通信的步骤：**1）父进程创建两个匿名管道，管道 1（fd1[0]和 fd1[1]）和管道 2（fd2[0] 和 fd2[1]）；因为管道的数据是单向流动的，所以要想实现数据双向通信，就需要两个管道，每个方向一个。2）[父进程](https://www.zhihu.com/search?q=父进程&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"}) fork 出子进程，于是对于这两个匿名管道，子进程也分别有两个文件描述符指向匿名管道的读写两端；3）父进程关闭管道 1 的读端 fd1[0] 和 管道 2 的写端 fd2[1]，子进程关闭管道 1 的写端 fd1[1] 和 管道 2 的读端 fd2[0]，这样，管道 1 只能用于父进程写、子进程读；管道 2 只能用于父进程读、子进程写。管道是用**[环形队列](https://www.zhihu.com/search?q=环形队列&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})**实现的，数据从写端流入从读端流出，这就实现了父子进程之间的双向通信。![img](https://pic3.zhimg.com/v2-9a3131e0e838332fecaab3476eda26fa_b.jpg)看完上面这些讲述，我们来理解下管道的本质是什么：对于管道两端的进程而言，管道就是一个文件（这也就是为啥管道也被称为共享文件机制的原因了），但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在于内存中。简单来说，**管道的本质就是内核在内存中开辟了一个缓冲区，这个缓冲区与管道文件相关联，对管道文件的操作，被内核转换成对这块缓冲区的操作**。**有名管道**匿名管道由于没有名字，只能用于父子进程间的通信。为了克服这个缺点，提出了有名管道，也称做 FIFO，因为数据是先进先出的传输方式。所谓有名管道也就是提供一个路径名与之关联，这样，即使与创建有名管道的进程不存在亲缘关系的进程，只要可以访问该路径，就能够通过这个有名管道进行相互通信。**使用 Linux 命令 mkfifo 来创建有名管道：**`$ mkfifo myPipe`**myPipe 就是这个管道的名称，接下来，我们往 myPipe 这个有名管道中写入数据：**`$ echo "hello" > myPipe`执行这行命令后，你会发现它就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。于是，我们执行另外一个命令来读取这个有名管道里的数据：`$ cat < myPipe hello`三. 消息队列可以看出，**管道这种进程通信方式虽然使用简单，但是效率比较低，不适合进程间频繁地交换数据，并且管道只能传输无格式的[字节流](https://www.zhihu.com/search?q=字节流&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})**。为此，消息传递机制（Linux 中称消息队列）应用而生。比如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程在需要的时候自行去消息队列中读取数据就可以了。同样的，B 进程要给 A 进程发送消息也是如此。![img](https://pic1.zhimg.com/v2-a2caf6e76f9407a1752a220080b10134_b.jpg)**消息队列的本质就是存放在内存中的消息的链表，而消息本质上是用户自定义的[数据结构](https://www.zhihu.com/search?q=数据结构&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})**。如果进程从消息队列中读取了某个消息，这个消息就会被从消息队列中删除。对比一下管道机制：消息队列允许一个或多个进程向它写入或读取消息。消息队列可以实现消息的**随机查询**，不一定非要以先进先出的次序读取消息，也可以按消息的类型读取。比有名管道的先进先出原则更有优势。对于消息队列来说，在某个进程往一个队列写入消息之前，并不需要另一个进程在该消息队列上等待消息的到达。而对于管道来说，除非读进程已存在，否则先有写进程进行写入操作是没有意义的。消息队列的生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列就会一直存在。而匿名管道随进程的创建而建立，随进程的结束而销毁。需要注意的是，消息队列对于交换较少数量的数据很有用，因为无需避免冲突。但是，由于用户进程写入数据到内存中的消息队列时，会发生从用户态**拷贝**数据到内核态的过程；同样的，另一个用户进程读取内存中的消息数据时，会发生从内核态拷贝数据到[用户态](https://www.zhihu.com/search?q=用户态&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})的过程。因此，**如果数据量较大，使用消息队列就会造成频繁的系统调用，也就是需要消耗更多的时间以便内核介入**。四. 共享内存为了避免像消息队列那样频繁的拷贝消息、进行系统调用，共享内存机制出现了。顾名思义，共享内存就是允许不相干的进程将同一段物理内存连接到它们各自的地址空间中，使得这些进程可以访问同一个物理内存，这个物理内存就成为共享内存。如果某个进程向共享内存写入数据，所做的改动将**立即**影响到可以访问同一段共享内存的任何其他进程。集合内存管理的内容，我们来深入理解下共享内存的原理。首先，每个进程都有属于自己的进程控制块（PCB）和逻辑地址空间（Addr Space），并且都有一个与之对应的页表，负责将进程的逻辑地址（虚拟地址）与物理地址进行映射，通过内存管理单元（MMU）进行管理。**两个不同进程的逻辑地址通过页表映射到物理空间的同一区域，它们所共同指向的这块区域就是共享内存**。![img](https://pic4.zhimg.com/v2-30fd4ee32afadbc97fc602a8461ac74b_b.jpg)不同于消息队列频繁的系统调用，对于共享内存机制来说，仅在建立共享内存区域时需要系统调用，一旦建立共享内存，所有的访问都可作为常规内存访问，无需借助内核。这样，数据就不需要在进程之间来回拷贝，所以这是最快的一种进程通信方式。![img](https://pic2.zhimg.com/v2-b2f88341dfb4ed26e5e11a7408e8766d_b.jpg)五. 信号量和 PV 操作实际上，对具有多 CPU 系统的最新研究表明，在这类系统上，消息传递的性能其实是要优于共享内存的，因为**消息队列无需避免冲突，而共享内存机制可能会发生冲突**。也就是说如果多个进程同时修改同一个共享内存，先来的那个进程写的内容就会被后来的覆盖。并且，在多道批处理系统中，多个进程是可以并发执行的，但由于系统的资源有限，进程的执行不是一贯到底的， 而是走走停停，以不可预知的速度向前推进（异步性）。但有时候我们又希望多个进程能密切合作，按照某个特定的顺序依次执行，以实现一个共同的任务。举个例子，如果有 A、B 两个进程分别负责读和写数据的操作，这两个线程是相互合作、相互依赖的。那么写数据应该发生在读数据之前。而实际上，由于异步性的存在，可能会发生先读后写的情况，而此时由于缓冲区还没有被写入数据，读进程 A 没有数据可读，因此读进程 A 被阻塞。![img](https://pic2.zhimg.com/v2-44d3a2d42d9c6c0be7e636d192cdd749_b.jpg)因此，为了解决上述这两个问题，保证共享内存在任何时刻只有一个进程在访问（互斥），并且使得进程们能够按照某个特定顺序访问共享内存（同步），我们就可以使用进程的同步与互斥机制，常见的比如信号量与 PV 操作。**进程的同步与互斥其实是一种对进程通信的保护机制，并不是用来传输进程之间真正通信的内容的，但是由于它们会传输信号量，所以也被纳入进程通信的范畴，称为低级通信**。下面的内容和上篇文章【看完了进程同步与互斥机制，我终于彻底理解了 PV 操作】中所讲的差不多，看过的小伙伴可直接跳到下一标题。信号量其实就是一个变量 ，我们可以用一个信号量来表示系统中某种资源的数量，比如：系统中只有一台打印机，就可以设置一个初值为 1 的信号量。用户进程可以通过使用操作系统提供的一对原语来对信号量进行操作，从而很方便的实现进程互斥或同步。这一对原语就是 PV 操作：1）**P 操作**：将信号量值减 1，表示**申请占用一个资源**。如果结果小于 0，表示已经没有可用资源，则执行 P 操作的进程被阻塞。如果结果大于等于 0，表示现有的资源足够你使用，则执行 P 操作的进程继续执行。可以这么理解，当信号量的值为 2 的时候，表示有 2 个资源可以使用，当信号量的值为 -2 的时候，表示有两个进程正在等待使用这个资源。不看这句话真的无法理解 V 操作，看完顿时如梦初醒。2）**V 操作**：将信号量值加 1，表示**释放一个资源**，即使用完资源后归还资源。若加完后信号量的值小于等于 0，表示有某些进程正在等待该资源，由于我们已经释放出一个资源了，因此需要唤醒一个等待使用该资源（[就绪态](https://www.zhihu.com/search?q=就绪态&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})）的进程，使之运行下去。我觉得已经讲的足够通俗了，不过对于 V 操作大家可能仍然有困惑，下面再来看两个关于 V 操作的问答：问：**信号量的值 大于 0 表示有共享资源可供使用，这个时候为什么不需要唤醒进程**？答：所谓唤醒进程是从就绪队列（[阻塞队列](https://www.zhihu.com/search?q=阻塞队列&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})）中唤醒进程，而信号量的值大于 0 表示有共享资源可供使用，也就是说这个时候没有进程被阻塞在这个资源上，所以不需要唤醒，正常运行即可。问：**信号量的值 等于 0 的时候表示没有共享资源可供使用，为什么还要唤醒进程**？答：V 操作是先执行信号量值加 1 的，也就是说，把信号量的值加 1 后才变成了 0，在此之前，信号量的值是 -1，即有一个进程正在等待这个共享资源，我们需要唤醒它。**信号量和 PV 操作具体的定义如下：**![img](https://pic4.zhimg.com/v2-7b74c0f4c727c73429e033d31686d257_b.jpg)**互斥访问共享内存****两步走即可实现不同进程对共享内存的互斥访问：**定义一个互斥信号量，并初始化为 1把对共享内存的访问置于 P 操作和 V 操作之间![img](https://pic1.zhimg.com/v2-b9985c3b39adfc1318846b92b06f4a84_b.jpg)**P 操作和 V 操作必须成对出现**。缺少 P 操作就不能保证对共享内存的互斥访问，缺少 V 操作就会导致共享内存永远得不到释放、处于等待态的进程永远得不到唤醒。![img](https://pic2.zhimg.com/v2-bacaff7e77dc273c7bd9b7c206b7edf9_b.jpg)**实现进程同步**回顾一下进程同步，就是要各并发进程按要求有序地运行。举个例子，以下两个进程 P1、P2 并发执行，由于存在异步性，因此二者交替推进的次序是不确定的。假设 P2 的 “代码4” 要基于 P1 的 “代码1” 和 “代码2” 的运行结果才能执行，那么我们就必须保证 “代码4” 一定是在 “代码2” 之后才会执行。![img](https://pic3.zhimg.com/v2-d235165c06aa584e182af579baeefa06_b.jpg)如果 P2 的 “代码4” 要基于 P1 的 “代码1” 和 “代码2” 的运行结果才能执行，那么我们就必须保证 “代码4” 一定是在 “代码2” 之后才会执行。**使用信号量和 PV 操作实现进程的同步也非常方便，三步走：**定义一个同步信号量，并初始化为当前可用资源的数量在优先级较**高**的操作的**后**面执行 V 操作，释放资源在优先级较**低**的操作的**前**面执行 P 操作，申请占用资源![img](https://pic1.zhimg.com/v2-b96f4d81a066a07c78881580ed5d6a10_b.jpg)**配合下面这张图直观理解下：**![img](https://pic1.zhimg.com/v2-5298a00e4d5f74ec0e6e7667761e695c_b.jpg)六. 信号注意！**信号和信号量是完全不同的两个概念**！信号是进程通信机制中唯一的**异步**通信机制，它可以在任何时候发送信号给某个进程。**通过发送指定信号来通知进程某个[异步事件](https://www.zhihu.com/search?q=异步事件&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})的发送，以迫使进程执行信号处理程序。信号处理完毕后，被中断进程将恢复执行**。用户、内核和进程都能生成和发送信号。信号事件的来源主要有硬件来源和软件来源。所谓硬件来源就是说我们可以通过键盘输入某些[组合键](https://www.zhihu.com/search?q=组合键&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})给进程发送信号，比如常见的组合键 Ctrl+C 产生 SIGINT 信号，表示终止该进程；而软件来源就是通过 [kill](https://www.zhihu.com/search?q=kill&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"}) 系列的命令给进程发送信号，比如 kill -9 1111 ，表示给 PID 为 1111 的进程发送 SIGKILL 信号，让其立即结束。**我们来查看一下 Linux 中有哪些信号：**![img](https://pic3.zhimg.com/v2-09f8b9dcfea6a49418793954047a8f62_b.jpg)**

**

**七. Socket至此，上面介绍的 5 种方法都是用于同一台主机上的进程之间进行通信的，如果想要**跨网络与不同主机上的进程进行通信**，那该怎么做呢？这就是 Socket 通信做的事情了（**当然，Socket 也能完成同主机上的进程通信**）。![img](https://pic1.zhimg.com/v2-053f491fd42d5e7ba86295393e275310_b.jpg)
Socket 起源于 Unix，原意是**插座**，在计算机通信领域，Socket 被翻译为**套接字**，它是计算机之间进行通信的一种约定或一种方式。通过 Socket 这种约定，一台计算机可以接收其他计算机的数据，也可以向其他计算机发送数据。从计算机网络层面来说，**Socket 套接字是网络通信的基石**，是支持 TCP/IP 协议的网络通信的基本操作单元。它是网络通信过程中端点的抽象表示，包含进行网络通信必须的五种信息：连接使用的协议，本地主机的 IP 地址，本地进程的协议端口，远地主机的 IP 地址，远地进程的协议端口。Socket 的本质其实是一个编程接口（API），是应用层与 TCP/IP 协议族通信的中间软件抽象层，它对 TCP/IP 进行了封装。它**把复杂的 TCP/IP [协议族](https://www.zhihu.com/search?q=协议族&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})隐藏在 Socket 接口后面**。对用户来说，只要通过一组简单的 API 就可以实现网络的连接。**

### **八. 总结

1. 首先，最简单的方式就是**管道**，管道的本质是存放在内存中的特殊的文件。也就是说，内核在内存中开辟了一个缓冲区，这个缓冲区与管道文件相关联，对管道文件的操作，被内核转换成对这块缓冲区的操作。管道分为匿名管道和有名管道，匿名管道只能在父子进程之间进行通信，而有名管道没有限制。
2. 虽然管道使用简单，但是效率比较低，不适合进程间频繁地交换数据，并且管道只能传输无格式的字节流。为此**消息队列**应用而生。消息队列的本质就是存放在内存中的消息的链表，而消息本质上是用户自定义的数据结构。如果进程从消息队列中读取了某个消息，这个消息就会被从消息队列中删除。
3. 消息队列的速度比较慢，因为每次数据的写入和读取都需要经过用户态与内核态之间数据的拷贝过程，**共享内存**可以解决这个问题。所谓共享内存就是：两个不同进程的逻辑地址通过页表映射到物理空间的同一区域，它们所共同指向的这块区域就是共享内存。如果某个进程向共享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程。对于共享内存机制来说，仅在建立共享内存区域时需要系统调用，一旦建立共享内存，所有的访问都可作为常规内存访问，无需借助内核。这样，数据就不需要在进程之间来回拷贝，所以这是最快的一种进程通信方式。
4. 共享内存速度虽然非常快，但是存在冲突问题，为此，我们可以使用信号量和 PV 操作来实现对共享内存的互斥访问，并且还可以实现进程同步。
5. **信号**和信号量是完全不同的两个概念！信号是进程通信机制中唯一的异步通信机制，它可以在任何时候发送信号给某个进程。通过发送指定信号来通知进程某个异步事件的发送，以迫使进程执行信号处理程序。信号处理完毕后，被中断进程将恢复执行。用户、内核和进程都能生成和发送信号。
6. 上面介绍的 5 种方法都是用于同一台主机上的进程之间进行通信的，如果想要跨网络与不同主机上的进程进行通信，就需要使用 **Socket** 通信。另外，Socket 也能完成同主机上的进程通信。

## 3.反射是什么



## 2、守护线程

**你了解守护线程吗?它和非守护线程有什么区别**

程序运行完毕,jvm会等待非守护线程完成后关闭,但是jvm不会等待守护线程.守护线程最典型的例子就是GC线程

## 多线程上下文切换

> 3、什么是多线程上下文切换

多线程的上下文切换是指CPU控制权由一个已经正在运行的线程切换到另外一个就绪并等待获取CPU执行权的线程的过程。

- 

## start、run方法区别

当程序调用start()方法，一个新的线程会被创建，此时新线程处于就绪状态，等待cpu时间片，得到时间片后run()方法中的代码将会被执行。（要注意的是run方法是自动被调用的，并不需要手工调用）

```java
public class MyThread2 implements Runnable {

    @Override
    public void run() {
        for (int i = 0; i < 5; i++) {
            System.out.println(Thread.currentThread().getName() + " " + i);
        }
    }

    public static void main(String[] args) {
        MyThread2 myThread2 = new MyThread2();
        Thread thread = new Thread(myThread2);
        thread.start();
    }

}

```

程序输出新创建的Thread1

```
>>>
Thread-0 0
Thread-0 1
Thread-0 2
Thread-0 3
Thread-0 4

Process finished with exit code 0
```

当直接调用run方法时，并不会生成新线程，而是在当前线程执行run方法中的代码

```java
public class MyThread2 implements Runnable {

    @Override
    public void run() {
        for (int i = 0; i < 5; i++) {
            System.out.println(Thread.currentThread().getName() + " " + i);
        }
    }

    public static void main(String[] args) {
        MyThread2 myThread2 = new MyThread2();
        Thread thread = new Thread(myThread2);
    
        thread.run();
    }

}

```

程序输出当前线程main

```
main 0
main 1
main 2
main 3
main 4
Process finished with exit code 0
```

> 5、Thread类中的start()和run()方法有什么区别?

start()方法被用来启动新创建的线程，而且start()内部调用了run()方法，这和直接调用run()方法的效果不一样。当你调用run()方法的时候，只会是在原来的线程中调用，没有新的线程启动，start()方法才会启动新线程。



## 说说 sleep() 方法和 wait() 方法区别和共同点?

- 两者最主要的区别在于：**`sleep()` 方法没有释放锁，而 `wait()` 方法释放了锁** 。
- 两者都可以暂停线程的执行。
- `wait()` 通常被用于线程间交互/通信，`sleep() `通常被用于暂停执行。
- `wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify() `或者 `notifyAll()` 方法。`sleep() `方法执行完成后，线程会自动苏醒。或者可以使用 `wait(long timeout)` 超时后线程会自动苏醒。

## 对象监视器

> 6、怎么检测一个线程是否持有对象监视器

Thread类提供了一个holdsLock(Object obj)方法，当且仅当对象obj的监视器被某条线程持有的时候才会返回true，注意这是一个static方法，这意味着”某条线程”指的是当前线程。

## Runnable和Callable

> 7、Runnable和Callable的区别

Runnable接口中的run()方法的返回值是void，它做的事情只是纯粹地去执行run()方法中的代码而已；Callable接口中的call()方法是有返回值的，是一个泛型，和Future、FutureTask配合可以用来获取异步执行的结果。 这其实是很有用的一个特性，因为多线程相比单线程更难、更复杂的一个重要原因就是因为多线程充满着未知性，某条线程是否执行了？某条线程执行了多久？某条线程执行的时候我们期望的数据是否已经赋值完毕？无法得知，我们能做的只是等待这条多线程的任务执行完毕而已。而Callable+Future/FutureTask却可以方便获取多线程运行的结果，可以在等待时间太长没获取到需要的数据的情况下取消该线程的任务

## 线程阻塞

> 8、什么导致线程阻塞

阻塞指的是暂停一个线程的执行以等待某个条件发生（如某资源就绪），学过操作系统的同学对它一定已经很熟悉了。Java 提供了大量方法来支持阻塞，下面让我们逐一分析。

| 方法                  | 说明                                                         |
| --------------------- | ------------------------------------------------------------ |
| sleep()               | sleep() 允许 指定以毫秒为单位的一段时间作为参数，它使得线程在指定的时间内进入阻塞状态，不能得到CPU 时间，指定的时间一过，线程重新进入可执行状态。 典型地，sleep() 被用在等待某个资源就绪的情形：测试发现条件不满足后，让线程阻塞一段时间后重新测试，直到条件满足为止 |
| suspend() 和 resume() | 两个方法配套使用，suspend()使得线程进入阻塞状态，并且不会自动恢复，必须其对应的resume() 被调用，才能使得线程重新进入可执行状态。典型地，suspend() 和 resume() 被用在等待另一个线程产生的结果的情形：测试发现结果还没有产生后，让线程阻塞，另一个线程产生了结果后，调用 resume() 使其恢复。 |
| yield()               | yield() 使当前线程放弃当前已经分得的CPU 时间，但不使当前线程阻塞，即线程仍处于可执行状态，随时可能再次分得 CPU 时间。调用 yield() 的效果等价于调度程序认为该线程已执行了足够的时间从而转到另一个线程 |
| wait() 和 notify()    | 两个方法配套使用，wait() 使得线程进入阻塞状态，它有两种形式，一种允许 指定以毫秒为单位的一段时间作为参数，另一种没有参数，前者当对应的 notify() 被调用或者超出指定时间时线程重新进入可执行状态，后者则必须对应的 notify() 被调用. |

## wait(),notify()和suspend(),resume()

> 9、wait(),notify()和suspend(),resume()之间的区别

初看起来它们与 suspend() 和 resume() 方法对没有什么分别，但是事实上它们是截然不同的。区别的核心在于，前面叙述的所有方法，阻塞时都不会释放占用的锁（如果占用了的话），而这一对方法则相反。上述的核心区别导致了一系列的细节上的区别。

首先，前面叙述的所有方法都隶属于 Thread 类，但是这一对却直接隶属于 Object 类，也就是说，所有对象都拥有这一对方法。初看起来这十分不可思议，但是实际上却是很自然的，因为这一对方法阻塞时要释放占用的锁，而锁是任何对象都具有的，调用任意对象的 wait() 方法导致线程阻塞，并且该对象上的锁被释放。而调用 任意对象的notify()方法则导致从调用该对象的 wait() 方法而阻塞的线程中随机选择的一个解除阻塞（但要等到获得锁后才真正可执行）。

其次，前面叙述的所有方法都可在任何位置调用，但是这一对方法却必须在 synchronized 方法或块中调用，理由也很简单，只有在synchronized 方法或块中当前线程才占有锁，才有锁可以释放。同样的道理，调用这一对方法的对象上的锁必须为当前线程所拥有，这样才有锁可以释放。因此，这一对方法调用必须放置在这样的 synchronized 方法或块中，该方法或块的上锁对象就是调用这一对方法的对象。若不满足这一条件，则程序虽然仍能编译，但在运行时会出现IllegalMonitorStateException 异常。

wait() 和 notify() 方法的上述特性决定了它们经常和synchronized关键字一起使用，将它们和操作系统进程间通信机制作一个比较就会发现它们的相似性：synchronized方法或块提供了类似于操作系统原语的功能，它们的执行不会受到多线程机制的干扰，而这一对方法则相当于 block 和wakeup 原语（这一对方法均声明为 synchronized）。它们的结合使得我们可以实现操作系统上一系列精妙的进程间通信的算法（如信号量算法），并用于解决各种复杂的线程间通信问题。

关于 wait() 和 notify() 方法最后再说明两点：

第一：调用 notify() 方法导致解除阻塞的线程是从因调用该对象的 wait() 方法而阻塞的线程中随机选取的，我们无法预料哪一个线程将会被选择，所以编程时要特别小心，避免因这种不确定性而产生问题。

第二：除了 notify()，还有一个方法 notifyAll() 也可起到类似作用，唯一的区别在于，调用 notifyAll() 方法将把因调用该对象的 wait() 方法而阻塞的所有线程一次性全部解除阻塞。当然，只有获得锁的那一个线程才能进入可执行状态。

谈到阻塞，就不能不谈一谈死锁，略一分析就能发现，suspend() 方法和不指定超时期限的 wait() 方法的调用都可能产生死锁。遗憾的是，Java 并不在语言级别上支持死锁的避免，我们在编程中必须小心地避免死锁。

以上我们对 Java 中实现线程阻塞的各种方法作了一番分析，我们重点分析了 wait() 和 notify() 方法，因为它们的功能最强大，使用也最灵活，但是这也导致了它们的效率较低，较容易出错。实际使用中我们应该灵活使用各种方法，以便更好地达到我们的目的。

## 死锁必要条件

（1） 互斥条件：一个资源每次只能被一个进程使用。

（2） 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。

（3） 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。

（4） 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。



> 12、为什么wait()方法和notify()/notifyAll()方法要在同步块中被调用

这是JDK强制的，wait()方法和notify()/notifyAll()方法在调用前都必须先获得对象的锁 wait()方法和notify()/notifyAll()方法在放弃对象监视器时有什么区别

wait()方法和notify()/notifyAll()方法在放弃对象监视器的时候的区别在于：wait()方法立即释放对象监视器，notify()/notifyAll()方法则会等待线程剩余代码执行完毕才会放弃对象监视器。

> 13、wait()与sleep()的区别

关于这两者已经在上面进行详细的说明,这里就做个概括好了:

- sleep()来自Thread类，和wait()来自Object类.调用sleep()方法的过程中，线程不会释放对象锁。而 调用 wait 方法线程会释放对象锁
- sleep()睡眠后不出让系统资源，wait让其他线程可以占用CPU
- sleep(milliseconds)需要指定一个睡眠时间，时间一到会自动唤醒.而wait()需要配合notify()或者notifyAll()使用

> 14、为什么wait,nofity和nofityAll这些方法不放在Thread类当中

一个很明显的原因是JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。如果线程需要等待某些锁那么调用对象中的wait()方法就有意义了。如果wait()方法定义在Thread类中，线程正在等待的是哪个锁就不明显了。简单的说，由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象。

> 15、怎么唤醒一个阻塞的线程

如果线程是因为调用了wait()、sleep()或者join()方法而导致的阻塞，可以中断线程，并且通过抛出InterruptedException来唤醒它；如果线程遇到了IO阻塞，无能为力，因为IO是操作系统实现的，Java代码并没有办法直接接触到操作系统。

> 17、synchronized和ReentrantLock的区别

synchronized是和if、else、for、while一样的关键字，ReentrantLock是类，这是二者的本质区别。既然ReentrantLock是类，那么它就提供了比synchronized更多更灵活的特性，可以被继承、可以有方法、可以有各种各样的类变量，ReentrantLock比synchronized的扩展性体现在几点上： （1）ReentrantLock可以对获取锁的等待时间进行设置，这样就避免了死锁 （2）ReentrantLock可以获取各种锁的信息 （3）ReentrantLock可以灵活地实现多路通知 另外，二者的锁机制其实也是不一样的:ReentrantLock底层调用的是Unsafe的park方法加锁，synchronized操作的应该是对象头中mark word.

> 18、FutureTask是什么

这个其实前面有提到过，FutureTask表示一个异步运算的任务。FutureTask里面可以传入一个Callable的具体实现类，可以对这个异步运算的任务的结果进行等待获取、判断是否已经完成、取消任务等操作。当然，由于FutureTask也是Runnable接口的实现类，所以FutureTask也可以放入线程池中。

> 19、一个线程如果出现了运行时异常怎么办?

如果这个异常没有被捕获的话，这个线程就停止执行了。另外重要的一点是：如果这个线程持有某个某个对象的监视器，那么这个对象监视器会被立即释放

> 20、Java当中有哪几种锁

- 自旋锁: 自旋锁在JDK1.6之后就默认开启了。基于之前的观察，共享数据的锁定状态只会持续很短的时间，为了这一小段时间而去挂起和恢复线程有点浪费，所以这里就做了一个处理，让后面请求锁的那个线程在稍等一会，但是不放弃处理器的执行时间，看看持有锁的线程能否快速释放。为了让线程等待，所以需要让线程执行一个忙循环也就是自旋操作。在jdk6之后，引入了自适应的自旋锁，也就是等待的时间不再固定了，而是由上一次在同一个锁上的自旋时间及锁的拥有者状态来决定
- 偏向锁: 在JDK1.之后引入的一项锁优化，目的是消除数据在无竞争情况下的同步原语。进一步提升程序的运行性能。 偏向锁就是偏心的偏，意思是这个锁会偏向第一个获得他的线程，如果接下来的执行过程中，改锁没有被其他线程获取，则持有偏向锁的线程将永远不需要再进行同步。偏向锁可以提高带有同步但无竞争的程序性能，也就是说他并不一定总是对程序运行有利，如果程序中大多数的锁都是被多个不同的线程访问，那偏向模式就是多余的，在具体问题具体分析的前提下，可以考虑是否使用偏向锁。
- 轻量级锁: 为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁

> 21、如何在两个线程间共享数据

通过在线程之间共享对象就可以了，然后通过wait/notify/notifyAll、await/signal/signalAll进行唤起和等待，比方说阻塞队列BlockingQueue就是为线程之间共享数据而设计的

> 22、如何正确的使用wait()?使用if还是while?

wait() 方法应该在循环调用，因为当线程获取到 CPU 开始执行的时候，其他条件可能还没有满足，所以在处理前，循环检测条件是否满足会更好。下面是一段标准的使用 wait 和 notify 方法的代码：

```
synchronized (obj) {
   while (condition does not hold)
     obj.wait(); // (Releases lock, and reacquires on wakeup)
     ... // Perform action appropriate to condition
}
复制代码
```

> 23、什么是线程局部变量ThreadLocal

线程局部变量是局限于线程内部的变量，属于线程自身所有，不在多个线程间共享。Java提供ThreadLocal类来支持线程局部变量，是一种实现线程安全的方式。但是在管理环境下（如 web 服务器）使用线程局部变量的时候要特别小心，在这种情况下，工作线程的生命周期比任何应用变量的生命周期都要长。任何线程局部变量一旦在工作完成后没有释放，Java 应用就存在内存泄露的风险。

> 24、ThreadLoal的作用是什么?

简单说ThreadLocal就是一种以空间换时间的做法在每个Thread里面维护了一个ThreadLocal.ThreadLocalMap把数据进行隔离，数据不共享，自然就没有线程安全方面的问题了.

> 25、生产者消费者模型的作用是什么?

（1）通过平衡生产者的生产能力和消费者的消费能力来提升整个系统的运行效率，这是生产者消费者模型最重要的作用 （2）解耦，这是生产者消费者模型附带的作用，解耦意味着生产者和消费者之间的联系少，联系越少越可以独自发展而不需要收到相互的制约

> 26.写一个生产者-消费者队列

可以通过阻塞队列实现,也可以通过wait-notify来实现. **使用阻塞队列来实现**

```java
//消费者
public class Producer implements Runnable{
   private final BlockingQueue<Integer> queue;

   public Producer(BlockingQueue q){
       this.queue=q;
   }

   @Override
   public void run() {
       try {
           while (true){
               Thread.sleep(1000);//模拟耗时
               queue.put(produce());
           }
       }catch (InterruptedException e){

       }
   }

   private int produce() {
       int n=new Random().nextInt(10000);
       System.out.println("Thread:" + Thread.currentThread().getId() + " produce:" + n);
       return n;
   }
}
//消费者
public class Consumer implements Runnable {
   private final BlockingQueue<Integer> queue;

   public Consumer(BlockingQueue q){
       this.queue=q;
   }

   @Override
   public void run() {
       while (true){
           try {
               Thread.sleep(2000);//模拟耗时
               consume(queue.take());
           }catch (InterruptedException e){

           }

       }
   }

   private void consume(Integer n) {
       System.out.println("Thread:" + Thread.currentThread().getId() + " consume:" + n);

   }
}
//测试
public class Main {

   public static void main(String[] args) {
       BlockingQueue<Integer> queue=new ArrayBlockingQueue<Integer>(100);
       Producer p=new Producer(queue);
       Consumer c1=new Consumer(queue);
       Consumer c2=new Consumer(queue);

       new Thread(p).start();
       new Thread(c1).start();
       new Thread(c2).start();
   }
}
复制代码
```

\**使用wait-notify来实现**

该种方式应该最经典,这里就不做说明了

> 27、如果你提交任务时，线程池队列已满，这时会发生什么

如果你使用的LinkedBlockingQueue，也就是无界队列的话，没关系，继续添加任务到阻塞队列中等待执行，因为LinkedBlockingQueue可以近乎认为是一个无穷大的队列，可以无限存放任务；如果你使用的是有界队列比方说ArrayBlockingQueue的话，任务首先会被添加到ArrayBlockingQueue中，ArrayBlockingQueue满了，则会使用拒绝策略RejectedExecutionHandler处理满了的任务，默认是AbortPolicy。

> 28、为什么要使用线程池

避免频繁地创建和销毁线程，达到线程对象的重用。另外，使用线程池还可以根据项目灵活地控制并发的数目。

> 29、java中用到的线程调度算法是什么

抢占式。一个线程用完CPU之后，操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。

> 30、Thread.sleep(0)的作用是什么

由于Java采用抢占式的线程调度算法，因此可能会出现某条线程常常获取到CPU控制权的情况，为了让某些优先级比较低的线程也能获取到CPU控制权，可以使用Thread.sleep(0)手动触发一次操作系统分配时间片的操作，这也是平衡CPU控制权的一种操作。



## AQS

![concurrent包实现整体示意图.png](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2018/5/3/163260cff7cb847c~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

**AbstractQueuedSynchronizer** 抽象队列同步器

**AQS就是一个并发包的基础组件，用来实现各种锁，各种同步组件的。它包含了state变量、加锁线程、等待队列等并发中的核心组件。**

## CAS

> 31、什么是CAS

CAS，全称为Compare and Swap，即比较-替换。假设有三个操作数：内存值V、旧的预期值A、要修改的值B，当且仅当预期值A和内存值V相同时，才会将内存值修改为B并返回true，否则什么都不做并返回false。当然CAS一定要volatile变量配合，这样才能保证每次拿到的变量是主内存中最新的那个值，否则旧的预期值A对某条线程来说，永远是一个不会变的值A，只要某次CAS操作失败，永远都不可能成功

## 乐观锁和悲观锁

> 32、什么是乐观锁和悲观锁

* 乐观锁：乐观锁认为竞争不总是会发生，因此它不需要持有锁，将比较-替换这两个动作作为一个原子操作尝试去修改内存中的变量，如果失败则表示发生冲突，那么就应该有相应的重试逻辑。
* 悲观锁：悲观锁认为竞争总是会发生，因此每次对某资源进行操作时，都会持有一个独占的锁，就像synchronized，不管三七二十一，直接上了锁就操作资源了。

## ConcurrentHashMap

### ConcurrentHashMap的并发度是什么?

ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势，任何情况下，Hashtable能同时有两条线程获取Hashtable中的数据吗？

### ConcurrentHashMap的工作原理

ConcurrentHashMap在jdk 1.6和jdk 1.8实现原理是不同的.

####  **jdk 1.6**

ConcurrentHashMap是线程安全的，但是与Hashtable相比，实现线程安全的方式不同。Hashtable是通过对hash表结构进行锁定，是阻塞式的，当一个线程占有这个锁时，其他线程必须阻塞等待其释放锁。ConcurrentHashMap是采用分离锁的方式，它并没有对整个hash表进行锁定，而是局部锁定，也就是说当一个线程占有这个局部锁时，不影响其他线程对hash表其他地方的访问。 具体实现:ConcurrentHashMap内部有一个Segment 

#### **jdk 1.8**

在jdk 8中，ConcurrentHashMap不再使用Segment分离锁，而是采用一种乐观锁CAS算法来实现同步问题，但其底层还是“数组+链表->红黑树”的实现。

> 37、CyclicBarrier和CountDownLatch区别

这两个类非常类似，都在java.util.concurrent下，都可以用来表示代码运行到某个点上，二者的区别在于：

- CyclicBarrier的某个线程运行到某个点上之后，该线程即停止运行，直到所有的线程都到达了这个点，所有线程才重新运行；CountDownLatch则不是，某线程运行到某个点上之后，只是给某个数值-1而已，该线程继续运行
- CyclicBarrier只能唤起一个任务，CountDownLatch可以唤起多个任务
- CyclicBarrier可重用，CountDownLatch不可重用，计数值为0该CountDownLatch就不可再用了

> 39、java中的++操作符线程安全么?

不是线程安全的操作。它涉及到多个指令，如读取变量值，增加，然后存储回内存，这个过程可能会出现多个线程交差

## 多线程实践

> 40、你有哪些多线程开发良好的实践?

- 给线程命名
- 最小化同步范围
- 优先使用volatile
- 尽可能使用更高层次的并发工具而非wait和notify()来实现线程通信,如BlockingQueue,Semeaphore
- 优先使用并发容器而非同步容器.
- 考虑使用线程池

# 垃圾回收

* [回收](https://juejin.cn/post/6911668514096955406)

回收之前判断对象是否存活

## 引用计数法

给对象添加一个引用计数器，引用+1，失效-1，为0表示不被使用。

**缺点**：无法解决循环依赖

## 可达性分析算法

以GC Roots作为起点向下搜索，如果不能搜索到某个对象，证明它可回收	

![image-20220815204217068](E:\gitfile\modiman.github.io\docs\_posts\imgs\image-20220815204217068.png)

 **可作为GC Roots的对象**

* 虚拟机栈中引用的对象
* 方法区中类静态属性引用的对象
* 方法区中常量引用的对象
* 本地方法栈中JNI引用的对象

## 分代结构

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/45a74a5765b74ad4857511271c922ecf~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

* 对象优先分配在 Eden 区
* 大对象直接进入老年代
* 长期存活的对象将进入老年代
* 动态对象年龄判断
* 空间分配担保

## 引用

* 强引用
* 软引用
* 弱引用
* 虚引用

## 垃圾收集算法

### 标记-清除 mark-sweep

标记出所有需要回收的对象，统一回收

**缺点**：效率不高，产生不连续碎片浪费空间

### 复制算法

将可用内存分为两块，每次只用一块，满了之后将活着的移到另一块，然后将已经使用过的一次清理 

**缺点**：只有一半内存可用

### 标记-整理  mark-compact

标记，将存活的对象向一段移动，清理掉端边界以外的内存

### 分代收集

根据对象存活周期将堆分为新生代、老年代

* 新生代：只有少量存活，选择复制算法
* 老年代：对象存活率高，采用标记-清理/整理

## 垃圾收集器

### CMS收集器 

Concurrent mark sweep

致力于减小系统停顿时间，常用于B/S结构的服务器端、

流程

1. 初始标记
2. 并发标记
3. 重新标记
4. 并发清除

**缺点**：

* 对CPU资源敏感
* 无法处理浮动垃圾
* 产生大量不连续碎片

### G1收集器

面向服务端的垃圾收集器

特点

* 并发与并行：利用多CPU优势缩短停顿时间
* 分代收集：用不同的方式处理新创建的、存活一段时间的对象
* 空间整合：不会产生大量碎片
* 可预测的停顿：

流程

1. 初始标记
2. 并发标记
3. 最终标记
4. **筛选回收**

# JVM调优

## 参数

Jvm调优典型参数设置;

1. -Xms堆内存的最小值：

   - 默认情况下，当堆中可用内存小于40%时，堆内存会开始增加，一直增加到-Xmx的大小。

2. -Xmx堆内存的最大值：

    默认值是总内存/64（且小于1G）

   - 默认情况下，当堆中可用内存大于70%时，堆内存会开始减少，一直减小到-Xms的大小；

3. -Xmn新生代内存的最大值：

   - 1.包括Eden区和两个Survivor区的总和
   - 2.配置写法如：-Xmn1024k，-Xmn1024m，-Xmn1g

4. -Xss每个线程的栈内存：

   - 默认1M，一般来说是不需要改。线程栈越小意味着可以创建的线程数越多

## 流程

* 第一步：监控分析GC日志

* 第二步：判断JVM问题：

  - 如果各项参数设置合理，系统没有超时日志出现，GC频率不高，GC耗时不高，那么没有必要进行GC优化

  - 如果GC时间超过1-3秒，或者频繁GC，则必须优化。

    

    第三步：确定调优目标

  第四步：调整参数

  - 调优一般是从满足程序的内存使用需求开始，之后是时间延迟要求，最后才是吞吐量要求，要基于这个步骤来不断优化，每一个步骤都是进行下一步的基础，不可逆行之。

  第五步：对比调优前后差距

  第六步：重复： 1 、 2 、 3 、 4 、 5 步骤

  - 找到最佳JVM参数设置

  第七步：应用JVM到应用服务器：

  - 找到最合适的参数，将这些参数应用到所有服务器，并进行后续跟踪。
  - 
  - 
  - 作者：llsydn
    链接：https://juejin.cn/post/7128377003224334373
    来源：稀土掘金
    著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

- 13、类加载机制和双亲委派机制？
- 14、**反射说一下？**
