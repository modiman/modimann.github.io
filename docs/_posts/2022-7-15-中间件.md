# 为什么要使用消息队列

消息中心，有以下几大作用：

- **消息通讯**：可以作为基本的消息通讯，比如聊天室等工具的使用
- **[异步处理](https://www.zhihu.com/search?q=异步处理&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"228208162"})** : 将一些实时性要求不是很强的业务异步处理，起到缓冲的作用，一定程度上也会避免因为有些消费者处理的太慢或者网络问题导致的通讯等待太久，因而导致的单个服务崩溃，甚至产生多个服务间的雪崩效应；
- **应用解耦** : 消息队列将消息生产者和消费者分离开来，可以实现应用解耦
- **流量削峰**: 可以通过在应用前端采用消息队列来接收请求，可以达到削峰的目的：请求超过队列长度直接不处理，重定向至错误页面。类似于网关限流的作用**冗余存储**：消息队列把数据进行持久化，直到它们已经被完全处理，通过这一方式规避了数据丢失风险

## 消息队列对比

|            | Kafka  | RabbitMQ |
| ---------- | ------ | -------- |
| 语言       | scala  | erlang   |
| 延迟队列   | 无     | 有       |
| 死信队列   | 无     | 有       |
| 优先级队列 | 无     | 有       |
| 消息回溯   | 有     | 无       |
| 消息持久化 | 有     | 有       |
| 消息确认   | offset | 单条     |
| 消息TTL    | 无     | 有       |
| 消费模式   | 流模式 | 队列模式 |
| 单机吞吐量 | 605    | 38       |
| 消息延迟   | 5ms    | 微秒级   |
| 费用       | 收费   | 免费     |

* 秒杀用rabbit是因为有延迟队列 死信队列，适合下单之后到付款之间的这段空档期
* kafka的吞吐量比较大，适合位置收集这种多用户多消息场景  秒杀场景一般有限

# 设计消息队列

**核心功能**

接受生产者的消息，broker转储，在合适的时间转发给消费者，消费者回复确认,broker删除消息

，**设计原则**

* 解耦
* 错峰
* 最终一致性

**基本功能实现**

* RPC，服务端提供接收消息和确认消息收到两个基本服务
* 高可用：保证服务端接收消息和确认消息的接口是幂等的
* 承载消息堆积：broker存在的意义包括错峰/流量控制等等，这些都需要暂时保存消息
  * 持久化：磁盘
  * 非持久化：内存
* 消费关系：解析发送接受关系
  * 广播
  * 点对点
* 





# RabbitMQ

## 为什么选择RabbitMQ

* 单机吞吐量 万级  系统并不需要太大的吞吐量
* 由于erlang语言的特性，mq 性能较好，高并发；
* 吞吐量到万级，MQ功能比较完备
* 健壮、稳定、易用、跨平台、支持多种语言、文档齐全；
* 开源提供的管理界面非常棒，用起来很好用
* 社区活跃度高；不过，RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug。
* 如果你的数据量没有那么大，小公司优先选择功能比较完备的RabbitMQ。

**RabbitMQ缺点：**

1. [erlang](https://www.zhihu.com/search?q=erlang&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"60288391"})开发，很难去看懂源码，基本职能依赖于开源社区的快速维护和修复bug，不利于做二次开发和维护。
2. RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。
3. 需要学习比较复杂的接口和协议，学习和维护成本较高。

![ ](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f4ffc0272c864b7bac1384e06a3139ff~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

## 安装



* [RabbitMQ初の体验](https://juejin.cn/post/6854573219253485575#heading-5)



​	如果在安装管理界面时提示erlang为安装，手动设置环境变量

```
C:\Program Files\RabbitMQ Server\rabbitmq_server-3.10.6\sbin>set ERLANG_HOME=C:\Program Files\erl-23.0
```

如果提示拒绝访问

使用管理员打开cmd

### springboot整合

#### 依赖

```xml
   <!-- AMQP依赖 -->
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-amqp</artifactId>
        </dependency>

```

#### 配置

**端口号**：15672是管理界面端口，5672是软件端口

```yaml
rabbitmq:
      #服务器地址
      host: localhost
      #用户名
      username: guest
      #密码
      password: guest
      #虚拟主机
      virtual-host: /
      #端口
      port: 5672
      listener:
        simple:
          #消费者最小数量
          concurrency: 10
          #消费者最大数量
          max-concurrency: 10
          #限制消费者每次只处理一条消息，处理完再继续下一条消息
          prefetch: 1
          #启动时是否默认启动容器，默认true
          auto-startup: true
          #被拒绝时重新进入队列
          default-requeue-rejected: true
      template:
        retry:
          #发布重试，默认false
          enabled: true
          #重试时间 默认1000ms
          initial-interval: 1000
          #重试最大次数，默认3次
          max-attempts: 3
          #重试最大间隔时间，默认10000ms
          max-interval: 10000
          #重试间隔的乘数。比如配2.0 第一次等10s，第二次等20s，第三次等40s
          multiplier: 1.0

```

#### 创建虚拟环境



### 问题来源

* 作者：牛客401890116号
  链接：https://www.nowcoder.com/discuss/628196?type=all&order=recall&pos=&page=0&ncTraceId=&channel=-1&source_id=search_all_nctrack&gio_id=F65021A0BC4E592FC927F934499E15D7-1657876800752
  来源：牛客网

### 参考文章

* [文档](https://www.rabbitmq.com/tutorials/tutorial-one-python.html)
* 

### 1、什么是rabbitmq

rabbit是一个信息中间商（message broker）,以送信打比方，人把信件放进邮箱后，信总会被送达收信人手中。在这个场景下，rabbitmq就是邮箱、邮局和送信人的角色。最大的区别是rabbitmq送的是数据包。

#### **producing**:

生产者，发送消息的一方![img](https://www.rabbitmq.com/img/tutorials/producer.png)

#### **queue**:

尽管信息可以在rabbitmq和用用程序之间流动，但他们只能存放在queue当中。本质上是一个大的数据缓存区，多个生产者可以发送进queue,也可以有多个消费者从queue接收消息。![img](https://www.rabbitmq.com/img/tutorials/producer.png![img](https://www.rabbitmq.com/img/tutorials/queue.png)

#### **customer**:

消费者。主要等待接收消息。

![img](https://www.rabbitmq.com/img/tutorials/consumer.png)

RabbitMQ的核心思想是**生产者并不会直接向任何一个队列发送消息**，实际上他甚至不知道消息是否被发送给了队列。

生产者只会将消息发送给**交换机**

#### Exchanges交换机

交换机从生产者获得消息之后压进队列。它知道该如何处理接收到的消息。

![img](https://www.rabbitmq.com/img/tutorials/exchanges.png)

交换机的类型有	`direct`, `topic`, `headers` and `fanout`,这些类型决定了以下问题

* 交换机是否为一个特殊队列
* 交换机是否为多个队列
* 是否应该摒弃交换机

1. direct

   ![direct 交换器](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2018/1/24/161260568dc498b6~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

   消息中的路由键（routing key）如果和 Binding 中的 binding key 一致， 交换器就将消息发到对应的队列中。路由键与队列名完全匹配，如果一个队列绑定到交换机要求路由键为“dog”，则只转发 routing key 标记为“dog”的消息，不会转发“dog.puppy”，也不会转发“dog.guard”等等。它是完全匹配、单播的模式。

2. fanout

   ![fanout 交换器](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2018/1/24/161260568fe5ce35~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

   每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。fanout 交换器不处理路由键，只是简单的将队列绑定到交换器上，每个发送到交换器的消息都会被转发到与该交换器绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。fanout 类型转发消息是最快的。

3. topic

   ![topic 交换器](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2018/1/24/161260569051565f~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

   topic 交换器通过模式匹配分配消息的路由键属性，将路由键和某个模式进行匹配，此时队列需要绑定到一个模式上。它将路由键和绑定键的字符串切分成单词，这些单词之间用点隔开。它同样也会识别两个通配符：符号“#”和符号“*”。#匹配0个或多个单词，*匹配不多不少一个单词。
   著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

![img](https://www.rabbitmq.com/img/tutorials/python-three-overall.png)

#### routing

之前所使用的fanout会将收到的所有消息发送给消费者，比如日志系统，只需要发送erro日志，那就需要使用`direct`类型的交换机

![img](https://www.rabbitmq.com/img/tutorials/direct-exchange.png)

#### Topic exchange

![img](https://www.rabbitmq.com/img/tutorials/python-five.png)

## 2、为什么要使用rabbitmq

1. 可靠性（Reliability） RabbitMQ 使用一些机制来保证可靠性，如持久化、传输确认、发布确认。
2. 灵活的路由（Flexible Routing） 在消息进入队列之前，通过 Exchange 来路由消息的。对于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对更复杂的路由功能，可以将多个 Exchange 绑定在一起，也通过插件机制实现自己的 Exchange 。
3. 消息集群（Clustering） 多个 RabbitMQ 服务器可以组成一个集群，形成一个逻辑 Broker 。

高可用（Highly Available Queues） 队列可以在集群中的机器上进行镜像，使得在部分节点出问题的情况下队列仍然可用。

多种协议（Multi-protocol） RabbitMQ 支持多种消息队列协议，比如 STOMP、MQTT 等等。

多语言客户端（Many Clients） RabbitMQ 几乎支持所有常用语言，比如 Java、.NET、Ruby 等等。

管理界面（Management UI） RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息 Broker 的许多方面。

跟踪机制（Tracing） 如果消息异常，RabbitMQ 提供了消息跟踪机制，使用者可以找出发生了什么。

插件机制（Plugin System） RabbitMQ 提供了许多插件，来从多方面进行扩展，也可以编写自己的插件。



* 除了Qpid，RabbitMQ是唯一一个实现了AMQP标准的消息服务器；    
*  可靠性，RabbitMQ的持久化支持，保证了消息的稳定性；    
*  高并发，RabbitMQ使用了Erlang开发语言，Erlang是为电话交换机开发的语言，天生自带高并发光环，和高可用特性；    
* 集群部署简单，正是因为Erlang使得RabbitMQ集群部署变得超级简单；    
* 社区活跃度高，根据网上资料来看，RabbitMQ也是首选；
* 

##  3、使用rabbitmq的场景

主要有三个作用：

- **解耦**。如图所示。假设有系统B、C、D都需要系统A的数据，于是系统A调用三个方法发送数据到B、C、D。这时，系统D不需要了，那就需要在系统A把相关的代码删掉。假设这时有个新的系统E需要数据，这时系统A又要增加调用系统E的代码。为了降低这种强耦合，就可以使用MQ，**系统A只需要把数据发送到MQ，其他系统如果需要数据，则从MQ中获取即可**。

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/7/19/173678c7a81cc1c0~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

- 异步。如图所示。一个客户端请求发送进来，系统A会调用系统B、C、D三个系统，同步请求的话，响应时间就是系统A、B、C、D的总和，也就是800ms。**如果使用MQ，系统A发送数据到MQ，然后就可以返回响应给客户端，不需要再等待系统B、C、D的响应，可以大大地提高性能**。对于一些非必要的业务，比如发送短信，发送邮件等等，就可以采用MQ。

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/7/19/17367945a8c4df73~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

- 削峰。如图所示。这其实是MQ一个很重要的应用。假设系统A在某一段时间请求数暴增，有5000个请求发送过来，系统A这时就会发送5000条SQL进入MySQL进行执行，MySQL对于如此庞大的请求当然处理不过来，MySQL就会崩溃，导致系统瘫痪。**如果使用MQ，系统A不再是直接发送SQL到数据库，而是把数据发送到MQ，MQ短时间积压数据是可以接受的，然后由消费者每次拉取2000条进行处理，防止在请求峰值时期大量的请求直接发送到MySQL导致系统崩溃**。

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/7/19/17367a9d902cca4f~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)



##  4、如何确保消息正确地发送至RabbitMQ？ 如何确保消息接收方消费了消息？

**发送方确认模式**

- 将信道设置成 confirm 模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的 ID。
- 一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一 ID）。
- 如果 RabbitMQ 发生内部错误从而导致消息丢失，会发送一条 nack（notacknowledged，未确认）消息。
- 发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。

**接收方确认机制**

- 消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ 才能安全地把消息从队列中删除。
- 这里并没有用到超时机制，RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息。保证数据的最终一致性；

**下面罗列几种特殊情况**

- 如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（可能存在消息重复消费的隐患，需要去重）
- 如果消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。


作者：小杰要吃蛋
链接：https://juejin.cn/post/6844904125935665160
来源：稀土掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

##  5 重复投递或重复消费

### 消息重复

#### 1、出现原因

> 消息重复大体上有两种情况会出现：
>
> 1）、消息消费成功，事务已提交，签收时结果服务器宕机或网络原因导致签收失败，消息状态会由unack转变为ready，重新发送给其他消费方；
>
> 2）、消息消费失败，由于retry重试机制，重新入队又将消息发送出去。

#### 2、解决方案

> 网上大体上能搜罗到的方法有三种：
>
> 1）、消费方业务接口做好幂等；
>
> 2）、消息日志表保存MQ发送时的唯一消息ID，消费方可以根据这个唯一ID进行判断避免消息重复；
>
> 3）、消费方的Message对象有个getRedelivered()方法返回Boolean，为TRUE就表示重复发送过来的。
>
> 我这里只推荐第一种，业务方法幂等这是最直接有效的方式，（2）还要和数据库产生交互，（3）有可能导致第一次消费失败但第二次消费成功的情况被砍掉。



### 消息积压

#### 1、出现原因

> 消息积压出现的场景一般有两种：
>
> 1）、消费方的服务挂掉，导致一直无法消费消息；
>
> 2）、消费方的服务节点太少，导致消费能力不足，从而出现积压，这种情况极可能就是生产方的流量过大导致。

#### 2、解决方案

> 1）、既然消费能力不足，那就扩展更多消费节点，提升消费能力；
>
> 2）、建立专门的队列消费服务，将消息批量取出并持久化，之后再慢慢消费。
>
> (1)就是最直接的方式，也是消息积压最常用的解决方案，但有些企业考虑到服务器成本压力，会选择第（2）种方案进行迂回，先通过一个独立服务把要消费的消息存起来，比如存到数据库，之后再慢慢处理这些消息即可。

1. 先修复consumer消费者的问题，以确保其恢复消费速度，然后将现有consumer 都停掉。
2. 新建一个 topic，partition 是原来的 10 倍，临时建立好原先10倍的queue 数量。
3. 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
4. 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。
5. 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息。





##  6、消息基于什么传输？

- 由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用信道的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。

##  7、消息如何分发？

- 若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。
- 每条消息只会分发给一个订阅的消费者（前提是消费者能够正常处理消息并进行确认）。通过路由可实现多消费的功能

​	

##  8、消息怎么路由？

消息提供方->路由->一至多个队列消息发布到交换器时，消息将拥有一个路由键（routing key），在消息创建时设定。通过队列路由键，可以把队列绑定到交换器上。消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；




作者：小杰要吃蛋
链接：https://juejin.cn/post/6844904125935665160
来源：稀土掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

##  9、如何确保消息不丢失？

* [RabbitMQ：消息丢失；作者：福隆苑居士](https://juejin.cn/post/7117842051286171655)

### 消息丢失

消息丢失的原因无非有三种：

1. 消息发出后，中途网络故障，服务器没收到；
2. 消息发出后，服务器收到了，还没持久化，服务器宕机；
3. 消息发出后，服务器收到了，消费方还未处理业务逻辑，服务却挂掉了，而消息也自动签收，等于啥也没干。

这三种情况，(1) 和 (2)是由于生产方未开启消息确认机制导致，(3)是由于消费方未开启手动签收机制导致。

### 解决方案

1. 生产方发送消息时，要try...catch，在catch中捕获异常，并将MQ发送的关键内容记录到日志表中，日志表中要有消息发送状态，若发送失败，由定时任务定期扫描重发并更新状态；
2. 生产方publisher必须要加入确认回调机制，确认成功发送并签收的消息，如果进入失败回调方法，就修改数据库消息的状态，等待定时任务重发；
3. 消费方要开启手动签收ACK机制，消费成功才将消息移除，失败或因异常情况而尚未处理，就重新入队。

其实这就是前面阐述两个概念时已经讲过的内容，也是接近100%消息投递的企业级方案之一，主要目的就是为了解决消息丢失的问题。


作者：福隆苑居士
链接：https://juejin.cn/post/7117842051286171655
来源：稀土掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



RabbitMQ避免消息丢失的方法主要是利用**消息确认机制**和**手动签收机制**，所以有必要把这两个概念搞清楚 

#### 消息确认机制

主要是生产者使用的机制，用来确认消息是否被成功消费。

#### 消息签收机制

RabbitMQ的消息是自动签收的，你可以理解为快递签收了，那么这个快递的状态就从发送变为已签收，唯一的区别是快递公司会对物流轨迹有记录，而MQ签收后就从队列中删除了。

企业级开发中，RabbitMQ我们基本都开启手动签收方式，这样可以有效避免消息的丢失。

前文中已经在生产者开启了手动签收机制，那么作为消费方，也要设置手动签收。

#### 总结

通过以上方案发现消息丢失后需要让生产者重发

10、使用RabbitMQ有什么好处？
 11、RabbitMQ的集群
 12、mq的缺点

### 消息顺序性

有些消息的消费需要保证有序性，比如秒杀----下单----付款

保证有序的基本思路是将对应的消息发个同一个服务器，前一个消息确认收到并消费了之后再发送下一个消息

### 幂等

对接口的重复查询之后结果是一样的

比如转账操作，第一次转账请求接口后数据库成功执行，但在返回结果时由于网络等问题造成返回失败或没有返回，这时如果客户端再次请求该接口且服务端再次转账，将造成错误。

**解决办法**：给每一条操作生成一个唯一性Id，在查询接口请求之前判断该请求是否已经存在以及是否已经执行成功

### 消息队列满了

1. 增加消费者
2. 批量消费
3. 丢弃不重要的消息
4. 将消息本地化

### 延时队列

**定义**

​	延时[队列](https://so.csdn.net/so/search?q=队列&spm=1001.2101.3001.7020)相比于普通队列最大的区别就体现在其延时的属性上，普通队列的元素是先进先出，按入队顺序进行处理，而延时队列中的元素在入队时会指定一个延迟时间，表示其希望能够在经过该指定时间后处理。从某种意义上来讲，延迟队列的结构并不像一个队列，而更像是一种以时间为权重的有序堆结构。

**场景**

* 下单到支付之间会有半个小时，超时取消订单
* 

​	![img](https://img-blog.csdnimg.cn/img_convert/895fd466f1644577ad0ff7d54defc2c4.png)

1. Time To Live(TTL) ：

一条消息的最大生存时间

**`RabbitMQ 可以从两种维度设置消息过期时间，分别是队列和消息本身。如果同时设置队列和队列中消息的 TTL，则 TTL 值以两者中较小的值为准。`**

1. 队列设置  整个队列的生存时间相同
2. 消息设置  只有单个消息被设置为指定值

#### 死信 dead letter

死信队列实际上是 RabbitMQ 的一种消息处理机制，当 RabbitMQ 在生产和消费消息的时候，消息遇到如下的情况，就会变成“死信”：

1. 消息被消费端拒绝(basic.reject/basic.nack)并且不再重新投递 requeue=false。
2. 消息超时未消费，也就是 TTL 过期了。
3. 消息队列到达最大长度

消息一旦变成一条死信，便会被重新投递到死信交换机(Dead-Letter-Exchange)，然后死信交换机根据绑定规则转发到对应的死信队列上，监听该队列就可以让消息被重新消费。

### 设计消息队列



# Kafka

##  是什么

-  Kafka 是一个分布式流式处理平台，具有高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性。 
-  作用一：消息系统。具备冗余存储、缓冲、异步通信、扩展性、可恢复性等功能。 
-  作用二：存储系统：Kafka有消息持久化和多副本机制。将消息持久化到磁盘，可以把它作为长期的数据存储系统来使用 
-  作用三：流式处理平台。Kafka 可以和流式处理框架进行集成。比如像Spark Streaming和Flink。提供了窗口、连接、变换和聚合等各类操作。 

![img](https://pic1.zhimg.com/v2-4692429e9184ed4a93911fa3a1361d28_b.jpg)

## 组成

* **Broker**：Broker是kafka实例，每个服务器上有一个或多个kafka的实例，我们姑且认为每个broker对应一台服务器。每个kafka集群内的broker都有一个**不重复**的编号，如图中的broker-0、broker-1等……
* **Topic**：消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker上都可以创建多个topic。
* **Partition**：Topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，[partition](https://www.zhihu.com/search?q=partition&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"68052232"})的表现形式就是一个一个的文件夹！
* **Replication**:每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。

**Message**：每一条发送的消息主体。

**Consumer**：消费者，即消息的消费方，是消息的出口。

**Consumer Group**：我们可以将多个消费组组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同一个topic的不同分区的数据，这也是为了提高kafka的吞吐量！

**Zookeeper**：kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。

* A：Kafka将消息以topic为单位进行归纳，A正确。
* B：将向Kafka topic发布消息的程序成为producers。
* C：将预订topics并消费消息的程序成为consumer。
* D：Kafka以集群的方式运行，可以由一个或多个服务组成，每个服务叫做一个broker。
* 本题考查Kafka日志片参数设置，当日志片段大小达到指定的数量的时候(默认为1G)，当前日志片段就会被关闭，一个新的日志片段被打开。
* Kafka单个消息的大小，默认值为1MB。如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会收到 broker 返回的错误消息。
* 由log、index、timeindex三个文件组成一个Segment



## 为什么选择Kafka

1. 吞吐量是最先考虑的，因为用户上报地图信息比较频繁，多用户同时在线时会有大量数据发送给服务端，在众多消息队列中，kafka的吞吐量性能是比较靠前的，同时还能保持不错的延迟
2. 

## 吞吐量&快

  吞吐量高，为什么 

-  零拷贝：避免了传统IO四步操作，采用DMA 技术，用DMA引擎直接将数据从内核模式传递到网卡设备中 
-  页缓存：将磁盘的数据缓存到内存中，将对磁盘的访问变成对内存的访问 
-  顺序追加：消息落到磁盘中，采用顺序追加，不支持随机访问 
-  分区机制：partition ，实现横向扩展 

1. **零拷贝**:基于零拷贝快速移动速度，避免了内核切换
2. **分批发送**:分批发送数据，可以端到端查看数据,
3. **顺序读写**：顺序写入磁盘，避免了随机磁盘寻址的浪费
4. **消息压缩**：批处理能有效压缩数据并减少IO延迟

##  Kafka 零拷贝

，详细过程，传统IO四部操作的过程。零拷贝会经过JVM堆吗？ 

-  将[数据]()直接从磁盘文件复制到网卡设备中，不需要经由应用程序之手。减少了内核和用户模式的上下文切换。底层通过sendfile 方法实现。 
-  传统IO需要四步
  1. 读两步：磁盘到读缓冲区
  2. 读缓冲区到用于程序。
  3. 写两步：应用程序写[数据]()到写缓冲区Socket Buffer，
  4. 写缓冲区写到网卡设备中。 
-  零拷贝技术通过DMA技术将文件内容复制到内核模式的Read Buffer中，和传统IO不同的是，不需要再到用户态走一圈，不再需要额外的Socket Buffer。DMA引擎直接将[数据]()从内核模式中传递到网卡设备中。 
-  应用程序空间，用户态。应用程序存放[数据]()就是在堆咯，所以，不会经过JVM堆 

*网卡是工作在数据链路层的网路组件，是局域网中连接计算机合传输介质的接口，不仅能实现与局域网传输介质之间的物理连接合电信号匹配，还涉及帧的发送与接收、帧的封装与拆封、介质访问控制、数据的编码与解码以及数据缓存的功能等*

## 有序性 

-  一个分区，消费者将消息全部写入一个分区中，一个消费者进行消费。🤣 被字节三面面试官怼死了 
-  自定义分区器Partitioner ，重写partition 方法，将消息顺序追加到K个分区，然后在消费者写K个内存队列，相同分区号的[数据]()都存到一个内存Queue中，N个线程分别消费一个内存队列即可 

## ACK 机制

-  ACK=0 表示生产者在成功写入消息之前不会等待任何来自服务器的响应. 
-  ACK=1 表示只要集群的leader分区副本接收到了消息，就会向生产者发送一个成功响应的ack，此时生产者接收到ack之后就可以认为该消息是写入成功的. 
-  ACK=-1 表示只有所有参与复制的节点(ISR列表的副本)全部收到消息时，生产者才会接收到来自服务器的响应.   

  

## 消费方式

使用**pull**的方式消费

| 优点                                                         | 缺点                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 根据consumer的消费能力**以适当的速率消费消息**               | 会出现一种情况：如果Kafka没有数据，消费者会专门有个线程去等待数据，可能会陷入循环等待中 |
| 消费者可以控制自己的消费方式：可以使用批量消费，也可以选择逐条消费 | 我们可以通过在拉请求中**设置参数**，允许消费者请求在等待数据到达的“长轮询”中进行阻塞 |
| 消费者还可以选择不同的提交方式来实现不同的传输语义，要是使用了push的方式，就没有这些优点了 | （并且可选地等待到给定的[字节数](https://www.zhihu.com/search?q=字节数&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"228208162"})，以确保大的传输大小）来避免这一问题 |

## zookeeper

* Kafka的数据会存储在zookeeper上。包括broker和消费者consumer的信息
* **broker信息**：包含各个broker的服务器信息、Topic信息
* **消费者信息**：主要存储每个消费者消费的topic的[offset](https://www.zhihu.com/search?q=offset&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"228208162"})的值



## message 的格式

 消息由一个固定长度的头部和可变长度的字节数组组成。头部包含了一个版本号和 CRC32校验码。

* 消息长度: 4 bytes (value: 1+4+n)
* 版本号: 1 byte
* CRC 校验码: 4 bytes
* 具体的消息: n bytes

## Kafka 文件目录布局

-  一个主题会有多个分区，那么就会有多个topic-partition 的文件夹。
- 每个分区的日志会切分为多个LogSegment。
- 每个LogSegment 的.log 日志文件都会有两个对应的索引文件。
- 偏移量索引文件（.index 为后缀）
- 时间戳索引文件（以.timeindex为后缀的文件）。 

  \7. Kafka 消费者和分区是如何对应的？如果消费者个数比分区数多会出现什么情况？ 

 

  \9. Kafka 能不能用MySQL 替代？ 

  \10. Kafka 有哪几种选举策略？

## 应用场景

1. 日志收集：
2. **用户轨迹跟踪**：kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等操作，这些活动信息被各个服务器发布到kafka的topic中，然后消费者通过订阅这些topic来做实时的监控分析，当然也可以保存到数据库
3. **运营指标**：kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告
4. **流式处理**：比如spark streaming和storm

