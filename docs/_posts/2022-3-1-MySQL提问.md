# 索引



### 1.MySQL索引，问了20分钟

* [我以为我对Mysql*索引*很了解，直到我遇到了阿里的面试官](https://zhuanlan.zhihu.com/p/73204847)





​       一张表可以建立**任意多个索引，**每个索引可以是**任意多个字段**的组合。索引**可能会提高查询速度**（如果查询时使用了索引），但**一定会减慢写入速度**，因为每次写入时都需要更新索引，所以索引只应该加在经常需要搜索的列上，不要加在写多读少的列上。

#### 单列索引与复合索引

只包含一个字段的索引叫做**单列索引**，包含两个或以上字段的索引叫做**复合索引**（或组合索引）。

建立复合索引时，字段的顺序极其重要。

下面这个SQL语句在 列X，列Y，列Z 上建立了一个复合索引。

```mysql
CREATE INDEX 索引名 ON 表名(列名X, 列名Y, 列名Z);
```

### 索引建立的动机

* 数据库系统基础教程 p223

当关系变得很大时，通过扫描所有元组找到匹配给定查询条件的元组的代价太高

### 索引的声明

```mysql
create index yearindex on Movie(year)
```

这样SQL查询处理器在处理制定年份的查询时，仅仅对年份为指定值的Movies的元组进行测试，从而使获得查询结果的时间大大缩短





## B+树

* 作者：孤独烟
* 链接：https://zhuanlan.zhihu.com/p/107228878
* 来源：知乎
* 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

#### B+树的两个明显特点

1. 数据只出现在叶子节点
2. 所有叶子节点增加了一个链指针

#### 针对上面的B+树和B树的特点，我们做一个总结

**(1)**B树的树内存储数据，因此查询单条数据的时候，B树的查询效率不固定，最好的情况是O(1)。我们可以认为在做单一数据查询的时候，使用B树平均性能更好。但是，由于B树中各节点之间没有指针相邻，因此B树不适合做一些数据遍历操作。

**(2)**B+树的数据只出现在叶子节点上，因此在查询单条数据的时候，查询速度非常稳定。因此，在做单一数据的查询上，其平均性能并不如B树。但是，B+树的叶子节点上有指针进行相连，因此在做数据遍历的时候，只需要对叶子节点进行遍历即可，这个特性使得B+树非常适合做[范围查询](https://www.zhihu.com/search?q=范围查询&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"107228878"})。

​         因此，我们可以做一个推论:没准是Mysql中数据遍历操作比较多，所以用B+树作为索引结构。而Mongodb是做单一查询比较多，数据遍历操作比较少，所以用B树作为索引结构。

***那么为什么Mysql做数据遍历操作多？而Mongodb做数据遍历操作少呢？***

 因为Mysql是关系型数据库，而Mongodb是非关系型数据。









#### B+ Tree索引和Hash索引区别

* [哈希索引](https://www.zhihu.com/search?q=哈希索引&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"73204847"})适合等值查询，但是无法进行范围查询 
* 哈希索引没办法利用索引完成排序

* 哈希索引不支持多列联合索引的最左匹配规则
* 如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题

#### 最左前缀匹配

面试官：那你知道最左前缀匹配吗？

我：（我突然想起来原来面试官是想问这个，怪自己刚刚为什么就没想到这个呢。）哦哦哦。您刚刚问的是这个意思啊，在创建多列索引时，我们根据业务需求，where子句中使用最频繁的一列放在最左边，因为MySQL索引查询会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。所以当我们创建一个联合索引的时候，如(key1,key2,key3)，相当于创建了（key1）、(key1,key2)和(key1,key2,key3)三个索引，这就是最左匹配原则。





我们平时建表的时候都会为表加上主键， 在某些关系数据库中， 如果建表时不指定主键，数据库会拒绝建表的语句执行。 事实上， 一个加了主键的表，并不能被称之为「表」。一个没加主键的表，它的数据无序的放置在磁盘存储器上，一行一行的排列的很整齐， 跟我认知中的「表」很接近。如果给表上了主键，那么表在磁盘上的存储结构就由整齐排列的结构转变成了树状结构，也就是上面说的「平衡树」结构，换句话说，就是整个表就变成了一个索引。没错， 再说一遍， 整个表变成了一个索引，也就是所谓的「聚集索引」。 这就是为什么一个表只能有一个主键， 一个表只能有一个「聚集索引」，因为主键的作用就是把「表」的数据格式转换成「索引（平衡树）」的格式放置。



作者：陈大侠
链接：https://zhuanlan.zhihu.com/p/23624390
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



#### 数据库系统基础教程

* 关系中属性A上的索引是一种数据结构，他能提高在属性A上查找具有某个特定值的元祖的效率
* 

## 索引的选择

* 索引的选择需要做一个开销上的分析
* 索引的选择是数据库设计成败的一个重要因素

### 简单代价模型

​       为了检查元组，需要将包含它的整个磁盘页调入主存，检查一个磁盘页上的所有元组所花费的时间通常和检查一个元组所花费的时间几乎没什么差别。

### 一些有用的索引

通常关系上最有用的索引是其键上的索引，原因有两个”：

1. 在查询中为主键指定值是比较普遍的，因此，键上的索引通常会被频繁的使用
2. 因为键值是唯一的，故与给定键值匹配的元组最多只有一个，因此索引返回的要么是这个元组的位置，要么什么也不返回。也就是说，为了取得这个元组，最多只有一个磁盘页需要被读入到磁盘页



### 计算最佳索引



### 2.主键的优点与缺点

1.自增主键，在mysql中应用最广泛。

**优点：**
    1>需要很小的数据存储空间，仅仅需要4 byte。（bigint类型，是8 byte）

　　　2>insert和update操作时使用INT的性能比UUID好，所以使用int将会提高应用程序的性能。

​    3>index和Join操作，int的性能最好。

​    4>容易记忆。

**缺点：**
    1>如果经常有合并表的操作，就可能会出现主键重复的情况。

​    2>使用int数据范围有限制。如果存在大量的数据，可能会超出int的取值范围。

​    3>很难处理分布式存储的数据表。

2。UUID

**优点：**
    1>能够保证独立性，程序可以在不同的数据库间迁移，效果不受影响。
    2>保证生成的ID不仅是表独立的，而且是库独立的，这点在你想切分数据库的时候尤为重要。
**缺点：**
    1>比较占地方，和INT类型相比，存储一个UUID要花费更多的空间。
    2>使用UUID后，URL显得冗长，不够友好。

​    3>没有内置的函数获取最新产生的UUID主键。

​    4>很难记忆。Join操作性能比int要低。

​    5>UUID做主键将会添加到表上的其他索引中，因此会降低性能。

## 范式

### 参考文献

作者：刘慰
链接：https://zhuanlan.zhihu.com/p/20028672
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

### 第一范式

**符合1NF的关系中的每个属性都不可再分**(所有关系型数据库的最低要求)

反例：![](https://pic3.zhimg.com/89507a1682f28fd2dde066cf94d77b4a_b.jpg)

缺陷：但是仅仅符合1NF的设计，仍然会存在[数据冗余](https://www.zhihu.com/search?q=数据冗余&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"20028672"})过大，插入异常，删除异常，修改异常的问题，例如对于**表3**中的设计：

![](https://pic3.zhimg.com/dfdc86b0e2babe1f8da03d8e2b17ad06_b.jpg)



# 事务

**参考文章**

* [数据库内核杂谈](https://www.infoq.cn/article/teJA7X43BO2alp6rLCWk)

事务的定义是：**一个事务是一组对数据库中数据操作的集合**。无论集合中有多少操作，对于用户来说，只是对数据库状态的一个原子改变。

```
单从概念定义来理解，可能有些晦涩难懂，我们举个例子来讲解：数据库中有两个用户的银行账户 A:100 元; B:200 元。假设事务是 A 转账 50 元到 B，可以理解为这个事务由两个操作组成：1) A-= 50; 2) B+=50。对于用户来说，数据库对于这个事务只有两个状态：执行事务前的初始状态，即 A:100 元; B:200 元，以及执行事务后的转账成功状态：A:50 元;B:250 元，不会有中间状态，比如钱从 A 已经扣除，却还没转到 B 上:A:50 元; B:200 元。
```

## 四大特性

### 原子性(atomicity)

```
一个事务的所有操作要么全部执行，要么一个都不执行。如果在执行事务的过程中，因为任何原因导致事务失败，已经执行的操作都要被回滚(rollback)。这种“all-or-none"的属性就是所谓的事务的原子性(atomicity)。
```

### 一致性(consistency)

```
假定数据库的初始状态是稳定的，或者说对用户来说是一致的。由于事务执行的原子性，即执行失败就回滚到执行前的状态，执行成功就变成一个新的稳定状态。因此，事务的执行会保持数据库状态的一致性(consistency)。
```

### 隔离性(isolation)

```
数据库系统是多用户系统。多个用户可能在同一时间执行不同的事务，称为并发。如果想要做到事务的原子性，那么数据库就必须做到并发的事务互不影响。从事务的角度出发，在执行它本身的过程中，不会感知到其他事务的存在。从数据库的角度出发，即使同一时间有多个事务并发，从微观尺度上看，它们之间也有先来后到，必须等一个事务完成后，另一个事务才开始。这种并发事务之间的不感知就是所谓的事务隔离性(isolation)。
```

### 持久性(durability)

```
当一个事务被认定执行成功后，即代表这个事务的操作被数据库持久化。因此，即使数据库在此时奔溃了，比如进程被杀死了，甚至是服务器断电了，这个事务的操作依然有效，这就是事务的另一个属性，持久性(durability)。
```

## 隔离级别(Isolation Level)

如何实现隔离性？最简单的办法：给数据库加一个全局操作锁，同一时间只允许一个用户操作

**缺点**：限制了并发性。

**解决办法**：根据对隔离性的需求，设置多个隔离级别，越严格的隔离级别越接近全局锁，反之，越宽松则越有利于高并发

为了方便描述，首先定义一个简单的事务模型

| 数据单元 | 数据操作     | 事务操作           |
| -------- | ------------ | ------------------ |
| A        | read(A)      | begin(开启事务)    |
| A        | write(A,val) | commit(提交事务)   |
| A        |              | rollback(回滚事务) |

接下来介绍隔离级别

### 1. read uncommitted（读未提交）

读未提交就是在一个事务中，允许读取其他事务未提交的数据。下图示例很清晰地诠释了读未提交：	

![img](https://static001.infoq.cn/resource/image/fe/04/fe87384762bd9c1ade107aeec3f3f304.png)

在事务 T1 中，读取 A 得到结果是 5，是因为事务 T2 修改了 A 的值，虽然当时 T2 还未提交，甚至最后 T2 回滚了。读未提交导致的问题就是 dirty read(脏读)。

```
脏读的定义就是，一个事务读取了另一个事务还未提交的修改。虽然可能大多数情况下，我们都会认为脏读产生了不正确的结果。但是，抛开业务谈正确性都是耍流氓。或许，某些用户的某些业务，为了支持更大地并发，允许脏读的出现。因为，对于读未提交，完全不需要对操作进行加锁，自然并发性更高。
```

### 2. read committed(读提交)

为了避免脏读，引入第二层隔离级别：读提交。读提交就是指在一个事务中，只能够读取到其他事务已经提交的数据。

![img](https://static001.infoq.cn/resource/image/f9/0a/f971ba38573fc98794403f02162e930a.png)

```
在读提交的隔离级别下，再回看上面的例子，T1 中读取 A 的值就应该还是 10，因为当时 T2 还没有提交。沿着上面的例子，接着往下看，如果最后 T2 提交了事务，而 T1 在之后又读取了一次 A，这时候的值就变为 5 了。
```

**新的问题**

在 T1 事务中，先后读取了两次 A，两次的值不一样了。回顾最早提及的事务的隔离性，两次读取同一数据的值不一样，其实违反了隔离性。因为隔离性定义了一个事务不需要感知其他事务的存在，但显然，由于值不同，说明在这个过程中另一个事务提交了数据。这类问题就被定义为 **nonrepeatable read(不可重复度读)**：在一个事务过程中，可能出现多次读取同一数据但得到的值不同的现象。

### 3. repeatable read(可重复读)

为了避免不可重复读，引入第三层隔离级别：可重复读。

```
可重复读指的是在一个事务中，只能读取已经提交的数据，且可以重复查询这些数据，并且，在重复查询之间，不允许其他事务对这些数据进行写操作。虽然我们还没讲到实现，但不难想象，对读数据加读锁锁就能实现。
```

**新的问题**

```sql
T1:
BEGIN;
SELECT * FROM students WHERE class_id = 1;  // (1)
... 
SELECT * FROM students WHERE class_id = 1;  // (2)
...
COMMIT;

```

```sql
T2:
BEGIN;
INSERT INTO students (1 /* class_id */, ...);
COMMIT; 

```

T2 事务并没有修改现有数据，而是新增了一条新数据，恰巧 class_id = 1。如果这条插入介于(1)和(2)之间，(2)的结果会改变吗？答案是，会的。语句(2)会比(1)多显示一条记录，即 T2 插入的。这个问题被称为 phantom read(幻读)，

```
幻读指的是，在一个事务中，当查询了一组数据后，再次发起相同查询，却发现满足条件的数据被另一个提交的事务改变了。
```

### 4. serializable(可有序化)

如何才能避免幻读呢？数据库系统只能推出最保守的隔离机制，serializable(可有序化)，即所有的事务必须按照一定顺序执行，直接避免了不同事务并发带来的各种问题。

### 总结-四种级别

1. **读未提交：在一个事务中，允许读取其他事务未提交的数据。**
2. **读提交：在一个事务中，只能够读取到其他事务已经提交的数据。**
3. **可重复读：在一个事务中，只能读取已经提交的数据，且可以重复查询这些数据，并且，在重复查询之间，不允许其他事务对这些数据进行写操作。**
4. **可有序化：所有的事务必须按照一定顺序执行。**

依次解决的三个问题

1. **脏读：一个事务读取了另一个事务还未提交的修改**
2. **不可重复度：在一个事务过程中，可能出现多次读取同一数据但得到不同值的现象。**
3. **幻读：在一个事务中，当查询了一组数据后，再次发起相同查询，却发现满足条件的数据被另一个提交的事务改变了。**

下方列出了一张表格，更直观地展现它们之间的关系。

| 隔离级别 |   脏读   | 不可重复度 |   幻读   |
| :------: | :------: | :--------: | :------: |
| 读未提交 | 可能出现 |  可能出现  | 可能出现 |
|  读提交  |   不能   |  可能出现  | 可能出现 |
| 可重复读 |   不能   |    不能    | 可能出现 |
| 可有序化 |   不能   |    不能    |   不能   |

## 隔离实现机制

### 加锁实现机制(Lock-based protocols)

实现隔离性最简单的方法是对全局数据加锁，但这样性能大大降低。

1. 降低锁的粒度

可以想办法把锁的粒度变细，即**仅对要读写的数据加锁**而非全局锁。通过加锁来确保在同一时间，只有获得锁的事务可以对数据进行处理。

2. 定义不同类型的锁

并不是所有的事务对数据都是写操作，如果两个事务同时对某一数据进行读操作，它们之间并不需要互斥。因此，我们可以通过定义不同类型的锁，以及它们之间的兼容程度来获得更细粒度的控制。

**共享锁(share-mode lock; S-lock)**：

(share-mode lock; S-lock)，即当事务获得了某个数据的共享锁，它仅能对该数据进行读操作，但不能写，共享锁有时候也被称为读锁。

**独占锁(exclusive-mode lock; X-lock)**

当事务获得了某个数据的独占锁，它可以对数据进行读和写操作，独占锁也常被叫做写锁。

共享锁和独占锁的兼容模式如下：

|        | S-lock | X-lock |
| :----: | :----: | ------ |
| S-lock |  兼容  | 不兼容 |
| X-lock | 不兼容 | 不兼容 |

仅 S-lock 之间互相兼容，只有当多个事务同时持有共享锁时才能同时对数据进行读操作。

**新的问题**：是么时候加锁？是么时候释放锁？

**案例分析**

| T1:<br/>X-lock(B);<br/>Read(B):<br/>B= B-50;<br/>Write(B);<br/>Unlock(B);<br/>X-lock(A);<br/>Read(A);<br/>A= A + 50;<br/>Write(A);<br/>Unlock(A). | T2:<br/>S-lock(A);<br/>Read(A);<br/>Unlock(A);<br/>S-lock(B);<br/>Read(B);<br/>Unlock(B);<br/>Display(A+B) |
| ------------------------------------------------------------ | ------------------------------------------------------------ |

两个事务对账号 A 和 B 进行操作(假设 A 初始值是 100；B 是 200)，事务 T1 用了 X-lock，因为需要对数据进行修改， 而 T2 仅需要使用 S-lock，因为只是读取数据。乍看之下，好像没有问题。无论是 T1 先执行，还是 T2 先执行，T2 中 display(A+B)都会是 300。但是，如果 T1 和 T2 的执行顺序如下：

| T1:<br/>X-lock(B);<br/>Read(B):<br/>B= B-50;<br/>Write(B);<br/>Unlock(B);<br/> |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
|                                                              | T2:<br/>S-lock(A);<br/>Read(A);<br/>Unlock(A);<br/>S-lock(B);<br/>Read(B);<br/>Unlock(B);<br/>Display(A+B) |
| X-lock(A);<br/>Read(A);<br/>A= A + 50;<br/>Write(A);<br/>Unlock(A). |                                                              |

这时候，T2 中的 display(A+B)的值就是 250，这是错误的数据。问题出在哪呢？T1 中释放对 B 的 X-lock 过早，使得 T2 获得了一个不正确的数值。既然原因是释放过早，那能不能通过延迟释放锁来解决这个问题。我们把 T1 和 T2 分别改写为 T3 和 T4(唯一的区别就是延缓了锁的释放到最后)，如下 表所示

| T1:<br/>X-lock(B);<br/>Read(B):<br/>B= B-50;<br/>Write(B);<br/>X-lock(A);<br/>Read(A);<br/>A= A + 50;<br/>Write(A);<br/>Unlock(B);<br/>Unlock(A). | T2:<br/>S-lock(A);<br/>Read(A);<br/>S-lock(B);<br/>Read(B);<br/>Display(A+B)<br/>Unlock(A);<br/>Unlock(B);<br/> |
| ------------------------------------------------------------ | ------------------------------------------------------------ |

T3 和 T4 分别获取了对 B 和对 A 的锁并且相互请求对 A 和对 B 的锁。相信大家都看出来了，这导致了死锁(dead lock)。这里就不具体介绍死锁的检查和破坏机制了(详情参见操作系统课)，你只需要知道，数据库系统是可以发现死锁的。解决方法也简单，选择其中一个参与的事务，回滚并放弃执行(如果一个不行，就两个)。相对于错误的数据，死锁显然是我们更愿意接受的，所谓两害取其轻

我们引入了第一个加锁实现：**两阶段加锁机制(Two-phase locking protocol)**。它要求事务在加锁的过程中遵循下面两步：



1）获取锁阶段(growing phase)：在这个过程中，事务只能不断地获取新的锁，但不能释放锁。

2）释放锁阶段(shrinking phase)：在这个过程中，事务只能逐渐释放锁，并且无权再获取新的锁。

**重要的事情说三遍：千万不要和两阶段提交(Two-phase commit (2PC))搞混；千万不要和两阶段提交搞混；千万不要和两阶段提交搞混。**两阶段提交是针对分布式事务的概念，我会在以后的文章中详细讲。

为了避免连锁回滚，我们可以引入两阶段提交的升级版：**严格的两阶段加锁(strict two-phase locking protocol)**。**除了需要遵循加锁和释放锁的两阶段外，它还规定，对于独占锁(X-lock)必须等到事务结束时才释放。**这个规定避免了其他事务对未提交的数据进行读写操作，因此也避免了连锁回滚。另一个更严格的升级本叫做**更严格的两阶段加锁(rigorous two-phase locking protocol)，**规定了所有获得的锁都得等到事务结束时才释放。

以上就是关于加锁的实现，如果我们总结一下，主要是介绍了这些内容：

1）引入共享锁(S-lock)和独占锁(X-lock)来获得对数据细粒度的控制；

2）引入两阶段加锁(Two-phase locking protocol)来保证数据的正确性；

3）两阶段加锁不能避免死锁，依然需要数据库系统来检查并破坏死锁，破坏死锁可以通过回滚相关的事务来进行；

4）两阶段加锁的两个升级版本：(更)严格的两阶段加锁(rigorous/strict two-phase locking)通过规定把释放锁等到事务结束来避免连锁回滚(cascading rollback)。



### 时间戳实现机制

使用时间戳记录事务开始的时间，根据时间戳为事务排序确定执行顺序。

为了避免两个时间戳一样可以使用计数的方法表示时间戳。

#### 实现

引入两个概念

1）W-timestamp(A): 记录对于数据 A，最近一次被某个事务修改的时间戳。

2）R-timestamp(A): 记录对于数据 A，最近一次被某个事务读取的时间戳。

一旦有一个更新的事务成功地对数据进行读取，相对应的读写时间戳就会被更新。

**对于事务 Ti 要读取数据 A read(A):**

1. 如果 TS(Ti) < W-timestamp(A)，说明 A 被一个 TS 比 Ti 更大的事务改写过，但 Ti 只能读取比自身 TS 小的数据。因此 Ti 的读取请求会被拒绝，Ti 会被回滚。
2. 如果 TS(Ti) > W-timestamp(A)，说明 A 最近一次被修改小于 TS(Ti)，因此读取成功，并且，R-timestamp(A)被改写为 TS(Ti)。

**对于事务 Ti 要修改数据 A write(A):**

1. 如果 TS(Ti) < R-timestamp(A)，说明 A 已经被一个更大 TS 的事务读取了，Ti 对 A 的修改就没有意义了，因此 Ti 的修改请求会被拒绝，Ti 会被回滚。
2. 如果 TS(Ti) < W-timestamp(A)，说明 A 已经被一个更大 TS 的事务修改了，Ti 对 A 的修改也没有意义了，因此 Ti 的修改请求会被拒绝，Ti 会被回滚。
3. 其他情况下，Ti 的修改会被接受，同时 W-timestamp(A)会被改写为 TS(Ti)。

一旦一个事务因为任何原因被回滚，再次重新执行时，会被系统分配一个新的 TS。



通过上述规则，系统就可以保证对于任意 Ti 和 Tj，如果 TS(Ti)<TS(Tj)，Ti 比 Tj 先运行完。我们通过一个示例来看时间戳是如何运行的。



假定下面两个事务 T1 和 T2，并且 TS(T1) < TS(T2)。

| T1:<br/>Read(B);<br/>Read(A);<br/>Display(A+B).<br/> | T2:<br/>Read(B)<br/>B= B- 50;<br/>Write(B);<br/>Read(A);<br/>A= A + 50;<br/>Write(A);<br/>Display(A+B). |
| ---------------------------------------------------- | ------------------------------------------------------------ |





## 多版本并发控制 (MVCC)

 Multi-Version Concurrency Control

```
为什么多版本并发控制更受欢迎呢？因为锁和时间戳机制都是通过阻塞或者回滚冲突的事务来确保事务的有序性。比如，一个读操作可能被迫回滚，因为它要读取的数据已经被另一个更新的事务修改了。但是，如果我们把每个数据的所有历史版本都记录下来，就可以避免上述这种情况发生。这也正是多版本控制的由来：对于每个数据 Q，每次写操作 write(Q)都会给 Q 建立一个新版本；而对于读操作 read(Q)，会根据事务的先后关系选择一个正确的版本去读取，来保证事务的有序性。多版本控制能够很好地解决这类读写冲突，尤其是长时间的读操作饿死写操作问题。
```

### 多版本时间戳

### 快照隔离(Snapshot Isolation)

```
快照隔离可以看作是对每一个事务，分配了一个独有的数据库快照。事务可以安心地读取这个快照中的数据而不需要去担心其他事务(因此只读事务是不会失败也不会被等待的)。同理，事务对数据的更新也首先暂存在这个独有的快照中，只有当事务提交的时候，这些更新才会试图被写回真正的数据库版本里。当一个事务准备提交时，它依然要确保没有其他事务更新了它所更新过的数据，否则，这个事务会被回滚
```

## 多版本时间戳(Multi-Version Timestamp Ordering)

把时间戳和多版本控制结合就形成了多版本时间戳机制。对于每个事务 Ti，系统都会设置相应的事务时间 TS(Ti)。对于每个数据单元 Q，系统会保存一系列的版本数据 Q1，Q2，Q3，… Qn。其中，每个版本 Qx 保存以下信息：



1. 当前版本的数据值
2. W-TS(Qx): 当 Qx 被某个事务 Ti 创建的时间戳，即 TS(Ti)
3. R-TS(Qx): 由于一个版本的数据可以被多个事务读取，这里存储的是最大的事务时间戳：最近一次被某个事务 Tj 读取成功的时间戳，即 TS(Tj)



当一个事务 Tx 创建了数据 Q 版本 Qk，Qk 会保存 Tx 所写入的数据值，同时，系统会把 W-TS(Qk)和 R-TS(Qk)都初始为 TS(Tx)；当有另一个事务 Ty 并且 TS(Ty) > TS(Tx)读取 Qk，系统会更新 R-TS(Qk)至 TS(Ty)。



现在介绍详细的操作机制：给定当前事务 Ti 对数据 Q 发起了一个读操作 read(Q)或者写操作 write(Q)。并假定，版本 Qk 是 Q 的所有版本中持有最大的但小于或等于 TS(Ti)的 W-TS 的时间戳。则：



1. 如果 Ti 是读操作，则读取成功，返回 Qk 中的值给 Ti。
2. 如果 Ti 是写操作，则需要判断，如果 TS(Ti) < R-TS(Qx)，即说明有一个更新的事务已经读取了数据，因此系统判定更新失败，回滚 Ti。如果 TS(Ti) = W-TS(Qx)，系统可以直接将 Ti 的值覆盖 Qk 的原值；如果 TS(Ti) > R-TS(Qx)，则创建一个新的版本 Q。



规则一很容易理解，一个事务可以读取到在它看来最新的数据。规则二则保证了一个事务被需要被撤销，如果已经有更新的事务读取了某个版本。



多版本时间戳机制的一大好处在于，一个读取数据的事务永远不会失败也不需要等待。在一个读多写少的场景下，相比于先前介绍的两种机制，会有很好的性能提升。



当然，它也是有缺点的。首先，就是在读取操作的事务中，也需要更新相应的 R-TS(Qk)，并且读取数据，这就导致可能产生两次磁盘操作，而非只读一次。另外，当写操作发生冲突时，它会要求回滚失败的事务，相比起等待，回滚操作可能更昂贵一些。下面介绍的另一种的实现可以解决这个问题。



## 多版本两阶段加锁(Multi-Version Two-Phase Locking)

多版本两阶段加锁机制，相比于上文介绍的多版本时间戳机制，是要集多版本控制和两阶段加锁之所长。它会区分对待只读操作的事务和有更新操作的事务。



有更新数据的事务会遵守两阶段加锁的规则，即事务需要持有所有的锁直至事务结束。这样，这些事务就能够保证有序性(在介绍 [两阶段加锁](https://www.infoq.cn/article/KyZjpzySYHUYDJa2e1fS)的时候已经讲解过)。这样做的好处在于不同的写事务可以等待并且按照顺序依次完成而不需要回滚后重试。对于只读操作，和上文介绍的多版本时间戳机制一样。不同的是，在多版本两阶段加锁中，事务的时间不再是时间戳，而是表现相对时序的事务计数 TS-Counter。这个 TS-Counter 在每次事务提交时被更新。



对于只读操作的事务 Ti，数据库系统会把 TS(Ti)赋于当前 TS-Counter 的值，这样 Ti 读取数据就和上面介绍的多版本时间戳一样，会读取到最大的但小于或等于 TS(Ti)的 Q 版本的值。对于有更新操作的事务，如果要读取一个数据，首先，它会获取这个数据的共享锁，并且读取最新版本的数据。当事务需要写数据时，首先要获取数据的独占锁并且创建一个新的版本，并把版本的时间戳设置为无穷大，当这个事务要被提交时，把它锁创建的所有数据的新版本的时间戳设置为 TS-Counter+1，并且同时更新系统的 TS-Ccounter，也变为 TS-Counter+1。



## 多版本并发控制的缺陷

天下没有免费的午餐，我们来讨论它有什么缺陷。



1. 额外的存储和计算资源支出：首先，需要额外存储历史版本数据，并且在执行时，每个事务要快速定位到正确的版本，并且对于更新的事务，通常情况会复制一份或者创建一个新的版本来暂存数据，这些都是需要消耗存储和计算资源的。当然，数据库系统可以定期对老的数据版本进行清理来释放存储空间。
2. 多线程竞争时间戳分配：由于需要保证不同事务的有序性，因此需要有一个共享的时间戳实现来分配(无论是用时间，还是相对的 counter)，免不了不同的事务线程需要去竞争时间戳。
3. 有些情况下，会导致频繁的事务回滚：特别当事务之间存在大量竞争的时候，会造成频繁的事务回滚。



总结一下，我们介绍了两种具体的多版本并发控制的实现，多版本时间戳机制和多版本两阶段加锁，两者都保证了对于只读操作的事务，不会失败也不会被等待。区别在于写操作的事务，多版本时间戳机制会回滚“迟到”的写事务，而多版本两阶段加锁通过共享和独占锁来对多个写操作事务排序。同时，我们也讨论了一些多版本并发控制的缺陷。但是，瑕不掩瑜，它依然是最常见的并发控制实现。



回忆一下在[第十期](https://www.infoq.cn/article/teJA7X43BO2alp6rLCWk)介绍的隔离级别：读未提交；读提交；可重复读和可有序化。那用多版本并发控制实现了哪个隔离级别呢？读者可能会觉得，应该是可有序化。但其实不然，它实现了一个新的隔离级别叫做 Snapshot Isolation(快照隔离)。



## 快照隔离(Snapshot Isolation)

快照隔离可以看作是对每一个事务，分配了一个独有的数据库快照。事务可以安心地读取这个快照中的数据而不需要去担心其他事务(因此只读事务是不会失败也不会被等待的)。同理，事务对数据的更新也首先暂存在这个独有的快照中，只有当事务提交的时候，这些更新才会试图被写回真正的数据库版本里。当一个事务准备提交时，它依然要确保没有其他事务更新了它所更新过的数据，否则，这个事务会被回滚。



那为什么说快照隔离是一个单独的隔离级别而不是可有序化呢？问题就在于，它提供了“太多”的隔离性(英语中用 too much！貌似更形象一些)。我想借用 CMU 数据库教授 Andy Pavlo 课里举过的一个非常贴切的例子，我们现在假设数据就是围棋的棋子，一部分是黑子，一部分是白子。现在同时有两个更新事务：T1: 把所有的白子变成黑子(写成 SQL 语句可以看作是这样的： **UPDATE color = ‘black’ FROM marbles WHERE color = ‘white’** )。T2:把所有的黑子变成白子。执行这两个操作会怎么样呢？由于快照隔离(多版本并发控制)机制，这两个事务更新的数据不一样，因此都会视为成功。这就导致了最终，白子和黑子的颜色互换。见下图示例。



![img](https://static001.infoq.cn/resource/image/79/ce/79ae28d92c24970f2ee1eeb8ff6590ce.png)



(Credit to https://15721.courses.cs.cmu.edu/spring2020/slides/03-mvcc1.pdf)



但是，根据可有序化的定义，要确保不同的事务最终是可以沿着时间线排成一溜执行，因此无论是 T1 先执行还是 T2 先执行，最终的颜色应该全是黑色或是白色，如下图所示。



![img](https://static001.infoq.cn/resource/image/42/58/42e7b461db5c7d01327374643f309b58.png)



(Credit to https://15721.courses.cs.cmu.edu/spring2020/slides/03-mvcc1.pdf)



上述的示例被称为 Write Skew Anomaly。因此，快照隔离是一个区别于可有序化的隔离级别，如果把它安插在我们介绍过的隔离级别，应该如下图所示。



![img](https://static001.infoq.cn/resource/image/06/4e/0637yy401860a95bf8c2d70e2092544e.png)



(Credit to https://15721.courses.cs.cmu.edu/spring2020/slides/03-mvcc1.pdf)



大部分的数据库都支持快照隔离。Orcale 和 PostgreSQL 数据库其实是使用快照隔离机制来实现可有序化机制。因此，在极端小概率情况下，数据库的状态是有可能“非有序化”的。



## 总结

至此，事务、隔离和并发就全部介绍完毕。我们分别介绍了事务的 ACID 属性以及不同的隔离级别，再依次介绍了不同的并发控制实现，两阶段加锁，时间戳机制，和多版本并发控制。



对于单机的数据库系统就介绍得差不多了。下一篇文章，我们聊一个非常有意思的话题：假设给你一个单机的数据库系统实现，要求在这个基础上把它扩建成分布式数据库系统，你会怎么做？这个问题还有个小故事。很久很久以前，在原来公司参与系统设计面试的时候，候选人和我说，我原本准备的面试题另一个面试官已经问过了(当时我的内心是崩溃的…)。这是我临时想出来的面试题，留给大家做思考
