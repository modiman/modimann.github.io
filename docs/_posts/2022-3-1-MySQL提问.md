# 索引



### 1.MySQL索引，问了20分钟

* [我以为我对Mysql*索引*很了解，直到我遇到了阿里的面试官](https://zhuanlan.zhihu.com/p/73204847)





​       一张表可以建立**任意多个索引，**每个索引可以是**任意多个字段**的组合。索引**可能会提高查询速度**（如果查询时使用了索引），但**一定会减慢写入速度**，因为每次写入时都需要更新索引，所以索引只应该加在经常需要搜索的列上，不要加在写多读少的列上。

#### 单列索引与复合索引

只包含一个字段的索引叫做**单列索引**，包含两个或以上字段的索引叫做**复合索引**（或组合索引）。

建立复合索引时，字段的顺序极其重要。

下面这个SQL语句在 列X，列Y，列Z 上建立了一个复合索引。

```mysql
CREATE INDEX 索引名 ON 表名(列名X, 列名Y, 列名Z);
```

### 索引建立的动机

* 数据库系统基础教程 p223

当关系变得很大时，通过扫描所有元组找到匹配给定查询条件的元组的代价太高

### 索引的声明

```mysql
create index yearindex on Movie(year)
```

这样SQL查询处理器在处理制定年份的查询时，仅仅对年份为指定值的Movies的元组进行测试，从而使获得查询结果的时间大大缩短





## B+树

* 作者：孤独烟
* 链接：https://zhuanlan.zhihu.com/p/107228878
* 来源：知乎
* 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

#### B+树的两个明显特点

1. 数据只出现在叶子节点
2. 所有叶子节点增加了一个链指针

#### 针对上面的B+树和B树的特点，我们做一个总结

**(1)**B树的树内存储数据，因此查询单条数据的时候，B树的查询效率不固定，最好的情况是O(1)。我们可以认为在做单一数据查询的时候，使用B树平均性能更好。但是，由于B树中各节点之间没有指针相邻，因此B树不适合做一些数据遍历操作。

**(2)**B+树的数据只出现在叶子节点上，因此在查询单条数据的时候，查询速度非常稳定。因此，在做单一数据的查询上，其平均性能并不如B树。但是，B+树的叶子节点上有指针进行相连，因此在做数据遍历的时候，只需要对叶子节点进行遍历即可，这个特性使得B+树非常适合做[范围查询](https://www.zhihu.com/search?q=范围查询&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"107228878"})。

​         因此，我们可以做一个推论:没准是Mysql中数据遍历操作比较多，所以用B+树作为索引结构。而Mongodb是做单一查询比较多，数据遍历操作比较少，所以用B树作为索引结构。

***那么为什么Mysql做数据遍历操作多？而Mongodb做数据遍历操作少呢？***

 因为Mysql是关系型数据库，而Mongodb是非关系型数据。









#### B+ Tree索引和Hash索引区别

* [哈希索引](https://www.zhihu.com/search?q=哈希索引&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"73204847"})适合等值查询，但是无法进行范围查询 
* 哈希索引没办法利用索引完成排序

* 哈希索引不支持多列联合索引的最左匹配规则
* 如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题

#### 最左前缀匹配

面试官：那你知道最左前缀匹配吗？

我：（我突然想起来原来面试官是想问这个，怪自己刚刚为什么就没想到这个呢。）哦哦哦。您刚刚问的是这个意思啊，在创建多列索引时，我们根据业务需求，where子句中使用最频繁的一列放在最左边，因为MySQL索引查询会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。所以当我们创建一个联合索引的时候，如(key1,key2,key3)，相当于创建了（key1）、(key1,key2)和(key1,key2,key3)三个索引，这就是最左匹配原则。





我们平时建表的时候都会为表加上主键， 在某些关系数据库中， 如果建表时不指定主键，数据库会拒绝建表的语句执行。 事实上， 一个加了主键的表，并不能被称之为「表」。一个没加主键的表，它的数据无序的放置在磁盘存储器上，一行一行的排列的很整齐， 跟我认知中的「表」很接近。如果给表上了主键，那么表在磁盘上的存储结构就由整齐排列的结构转变成了树状结构，也就是上面说的「平衡树」结构，换句话说，就是整个表就变成了一个索引。没错， 再说一遍， 整个表变成了一个索引，也就是所谓的「聚集索引」。 这就是为什么一个表只能有一个主键， 一个表只能有一个「聚集索引」，因为主键的作用就是把「表」的数据格式转换成「索引（平衡树）」的格式放置。



作者：陈大侠
链接：https://zhuanlan.zhihu.com/p/23624390
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



#### 数据库系统基础教程

* 关系中属性A上的索引是一种数据结构，他能提高在属性A上查找具有某个特定值的元祖的效率
* 

## 索引的选择

* 索引的选择需要做一个开销上的分析
* 索引的选择是数据库设计成败的一个重要因素

### 简单代价模型

​       为了检查元组，需要将包含它的整个磁盘页调入主存，检查一个磁盘页上的所有元组所花费的时间通常和检查一个元组所花费的时间几乎没什么差别。

### 一些有用的索引

通常关系上最有用的索引是其键上的索引，原因有两个”：

1. 在查询中为主键指定值是比较普遍的，因此，键上的索引通常会被频繁的使用
2. 因为键值是唯一的，故与给定键值匹配的元组最多只有一个，因此索引返回的要么是这个元组的位置，要么什么也不返回。也就是说，为了取得这个元组，最多只有一个磁盘页需要被读入到磁盘页



### 计算最佳索引



### 2.主键的优点与缺点

1.自增主键，在mysql中应用最广泛。

**优点：**
    1>需要很小的数据存储空间，仅仅需要4 byte。（bigint类型，是8 byte）

　　　2>insert和update操作时使用INT的性能比UUID好，所以使用int将会提高应用程序的性能。

​    3>index和Join操作，int的性能最好。

​    4>容易记忆。

**缺点：**
    1>如果经常有合并表的操作，就可能会出现主键重复的情况。

​    2>使用int数据范围有限制。如果存在大量的数据，可能会超出int的取值范围。

​    3>很难处理分布式存储的数据表。

2。UUID

**优点：**
    1>能够保证独立性，程序可以在不同的数据库间迁移，效果不受影响。
    2>保证生成的ID不仅是表独立的，而且是库独立的，这点在你想切分数据库的时候尤为重要。
**缺点：**
    1>比较占地方，和INT类型相比，存储一个UUID要花费更多的空间。
    2>使用UUID后，URL显得冗长，不够友好。

​    3>没有内置的函数获取最新产生的UUID主键。

​    4>很难记忆。Join操作性能比int要低。

​    5>UUID做主键将会添加到表上的其他索引中，因此会降低性能。

## 范式

### 参考文献

作者：刘慰
链接：https://zhuanlan.zhihu.com/p/20028672
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

### 第一范式

**符合1NF的关系中的每个属性都不可再分**(所有关系型数据库的最低要求)

反例：![](https://pic3.zhimg.com/89507a1682f28fd2dde066cf94d77b4a_b.jpg)

缺陷：但是仅仅符合1NF的设计，仍然会存在[数据冗余](https://www.zhihu.com/search?q=数据冗余&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"20028672"})过大，插入异常，删除异常，修改异常的问题，例如对于**表3**中的设计：

![](https://pic3.zhimg.com/dfdc86b0e2babe1f8da03d8e2b17ad06_b.jpg)



# 事务

**参考文章**

* [数据库内核杂谈](https://www.infoq.cn/article/teJA7X43BO2alp6rLCWk)

事务的定义是：**一个事务是一组对数据库中数据操作的集合**。无论集合中有多少操作，对于用户来说，只是对数据库状态的一个原子改变。

```
单从概念定义来理解，可能有些晦涩难懂，我们举个例子来讲解：数据库中有两个用户的银行账户 A:100 元; B:200 元。假设事务是 A 转账 50 元到 B，可以理解为这个事务由两个操作组成：1) A-= 50; 2) B+=50。对于用户来说，数据库对于这个事务只有两个状态：执行事务前的初始状态，即 A:100 元; B:200 元，以及执行事务后的转账成功状态：A:50 元;B:250 元，不会有中间状态，比如钱从 A 已经扣除，却还没转到 B 上:A:50 元; B:200 元。
```

## 四大特性

### 原子性(atomicity)

```
一个事务的所有操作要么全部执行，要么一个都不执行。如果在执行事务的过程中，因为任何原因导致事务失败，已经执行的操作都要被回滚(rollback)。这种“all-or-none"的属性就是所谓的事务的原子性(atomicity)。
```

### 一致性(consistency)

```
假定数据库的初始状态是稳定的，或者说对用户来说是一致的。由于事务执行的原子性，即执行失败就回滚到执行前的状态，执行成功就变成一个新的稳定状态。因此，事务的执行会保持数据库状态的一致性(consistency)。
```

### 隔离性(isolation)

```
数据库系统是多用户系统。多个用户可能在同一时间执行不同的事务，称为并发。如果想要做到事务的原子性，那么数据库就必须做到并发的事务互不影响。从事务的角度出发，在执行它本身的过程中，不会感知到其他事务的存在。从数据库的角度出发，即使同一时间有多个事务并发，从微观尺度上看，它们之间也有先来后到，必须等一个事务完成后，另一个事务才开始。这种并发事务之间的不感知就是所谓的事务隔离性(isolation)。
```

### 持久性(durability)

```
当一个事务被认定执行成功后，即代表这个事务的操作被数据库持久化。因此，即使数据库在此时奔溃了，比如进程被杀死了，甚至是服务器断电了，这个事务的操作依然有效，这就是事务的另一个属性，持久性(durability)。
```

## 隔离级别(Isolation Level)

如何实现隔离性？最简单的办法：给数据库加一个全局操作锁，同一时间只允许一个用户操作

**缺点**：限制了并发性。

**解决办法**：根据对隔离性的需求，设置多个隔离级别，越严格的隔离级别越接近全局锁，反之，越宽松则越有利于高并发

为了方便描述，首先定义一个简单的事务模型

| 数据单元 | 数据操作     | 事务操作           |
| -------- | ------------ | ------------------ |
| A        | read(A)      | begin(开启事务)    |
| A        | write(A,val) | commit(提交事务)   |
| A        |              | rollback(回滚事务) |

接下来介绍隔离级别

### 1. read uncommitted（读未提交）

读未提交就是在一个事务中，允许读取其他事务未提交的数据。下图示例很清晰地诠释了读未提交：	

![img](https://static001.infoq.cn/resource/image/fe/04/fe87384762bd9c1ade107aeec3f3f304.png)

在事务 T1 中，读取 A 得到结果是 5，是因为事务 T2 修改了 A 的值，虽然当时 T2 还未提交，甚至最后 T2 回滚了。读未提交导致的问题就是 dirty read(脏读)。

```
脏读的定义就是，一个事务读取了另一个事务还未提交的修改。虽然可能大多数情况下，我们都会认为脏读产生了不正确的结果。但是，抛开业务谈正确性都是耍流氓。或许，某些用户的某些业务，为了支持更大地并发，允许脏读的出现。因为，对于读未提交，完全不需要对操作进行加锁，自然并发性更高。
```

### 2. read committed(读提交)

为了避免脏读，引入第二层隔离级别：读提交。读提交就是指在一个事务中，只能够读取到其他事务已经提交的数据。

![img](https://static001.infoq.cn/resource/image/f9/0a/f971ba38573fc98794403f02162e930a.png)

```
在读提交的隔离级别下，再回看上面的例子，T1 中读取 A 的值就应该还是 10，因为当时 T2 还没有提交。沿着上面的例子，接着往下看，如果最后 T2 提交了事务，而 T1 在之后又读取了一次 A，这时候的值就变为 5 了。
```

**新的问题**

在 T1 事务中，先后读取了两次 A，两次的值不一样了。回顾最早提及的事务的隔离性，两次读取同一数据的值不一样，其实违反了隔离性。因为隔离性定义了一个事务不需要感知其他事务的存在，但显然，由于值不同，说明在这个过程中另一个事务提交了数据。这类问题就被定义为 **nonrepeatable read(不可重复度读)**：在一个事务过程中，可能出现多次读取同一数据但得到的值不同的现象。

### 3. repeatable read(可重复读)

为了避免不可重复读，引入第三层隔离级别：可重复读。

```
可重复读指的是在一个事务中，只能读取已经提交的数据，且可以重复查询这些数据，并且，在重复查询之间，不允许其他事务对这些数据进行写操作。虽然我们还没讲到实现，但不难想象，对读数据加读锁锁就能实现。
```

**新的问题**

```sql
T1:
BEGIN;
SELECT * FROM students WHERE class_id = 1;  // (1)
... 
SELECT * FROM students WHERE class_id = 1;  // (2)
...
COMMIT;

```

```sql
T2:
BEGIN;
INSERT INTO students (1 /* class_id */, ...);
COMMIT; 

```

T2 事务并没有修改现有数据，而是新增了一条新数据，恰巧 class_id = 1。如果这条插入介于(1)和(2)之间，(2)的结果会改变吗？答案是，会的。语句(2)会比(1)多显示一条记录，即 T2 插入的。这个问题被称为 phantom read(幻读)，

```
幻读指的是，在一个事务中，当查询了一组数据后，再次发起相同查询，却发现满足条件的数据被另一个提交的事务改变了。
```

### 4. serializable(可有序化)

如何才能避免幻读呢？数据库系统只能推出最保守的隔离机制，serializable(可有序化)，即所有的事务必须按照一定顺序执行，直接避免了不同事务并发带来的各种问题。

### 总结-四种级别

1. **读未提交：在一个事务中，允许读取其他事务未提交的数据。**
2. **读提交：在一个事务中，只能够读取到其他事务已经提交的数据。**
3. **可重复读：在一个事务中，只能读取已经提交的数据，且可以重复查询这些数据，并且，在重复查询之间，不允许其他事务对这些数据进行写操作。**
4. **可有序化：所有的事务必须按照一定顺序执行。**

依次解决的三个问题

1. **脏读：一个事务读取了另一个事务还未提交的修改**
2. **不可重复度：在一个事务过程中，可能出现多次读取同一数据但得到不同值的现象。**
3. **幻读：在一个事务中，当查询了一组数据后，再次发起相同查询，却发现满足条件的数据被另一个提交的事务改变了。**

下方列出了一张表格，更直观地展现它们之间的关系。

| 隔离级别 |   脏读   | 不可重复度 |   幻读   |
| :------: | :------: | :--------: | :------: |
| 读未提交 | 可能出现 |  可能出现  | 可能出现 |
|  读提交  |   不能   |  可能出现  | 可能出现 |
| 可重复读 |   不能   |    不能    | 可能出现 |
| 可有序化 |   不能   |    不能    |   不能   |

## 隔离实现机制

### 加锁实现机制(Lock-based protocols)

实现隔离性最简单的方法是对全局数据加锁，但这样性能大大降低。

1. 降低锁的粒度

可以想办法把锁的粒度变细，即**仅对要读写的数据加锁**而非全局锁。通过加锁来确保在同一时间，只有获得锁的事务可以对数据进行处理。

2. 定义不同类型的锁

并不是所有的事务对数据都是写操作，如果两个事务同时对某一数据进行读操作，它们之间并不需要互斥。因此，我们可以通过定义不同类型的锁，以及它们之间的兼容程度来获得更细粒度的控制。

**共享锁(share-mode lock; S-lock)**：

(share-mode lock; S-lock)，即当事务获得了某个数据的共享锁，它仅能对该数据进行读操作，但不能写，共享锁有时候也被称为读锁。

**独占锁(exclusive-mode lock; X-lock)**

当事务获得了某个数据的独占锁，它可以对数据进行读和写操作，独占锁也常被叫做写锁。

共享锁和独占锁的兼容模式如下：

|        | S-lock | X-lock |
| :----: | :----: | ------ |
| S-lock |  兼容  | 不兼容 |
| X-lock | 不兼容 | 不兼容 |

仅 S-lock 之间互相兼容，只有当多个事务同时持有共享锁时才能同时对数据进行读操作。

**新的问题**：是么时候加锁？是么时候释放锁？

### 时间戳实现机制

使用时间戳记录事务开始的时间，根据时间戳为事务排序确定执行顺序。

为了避免两个时间戳一样可以使用计数的方法表示时间戳。

#### 实现

引入两个概念

1）W-timestamp(A): 记录对于数据 A，最近一次被某个事务修改的时间戳。

2）R-timestamp(A): 记录对于数据 A，最近一次被某个事务读取的时间戳。

一旦有一个更新的事务成功地对数据进行读取，相对应的读写时间戳就会被更新。

**对于事务 Ti 要读取数据 A read(A):**

1. 如果 TS(Ti) < W-timestamp(A)，说明 A 被一个 TS 比 Ti 更大的事务改写过，但 Ti 只能读取比自身 TS 小的数据。因此 Ti 的读取请求会被拒绝，Ti 会被回滚。
2. 如果 TS(Ti) > W-timestamp(A)，说明 A 最近一次被修改小于 TS(Ti)，因此读取成功，并且，R-timestamp(A)被改写为 TS(Ti)。

**对于事务 Ti 要修改数据 A write(A):**

1. 如果 TS(Ti) < R-timestamp(A)，说明 A 已经被一个更大 TS 的事务读取了，Ti 对 A 的修改就没有意义了，因此 Ti 的修改请求会被拒绝，Ti 会被回滚。
2. 如果 TS(Ti) < W-timestamp(A)，说明 A 已经被一个更大 TS 的事务修改了，Ti 对 A 的修改也没有意义了，因此 Ti 的修改请求会被拒绝，Ti 会被回滚。
3. 其他情况下，Ti 的修改会被接受，同时 W-timestamp(A)会被改写为 TS(Ti)。
4. 

## 多版本并发控制 (MVCC)

 Multi-Version Concurrency Control

```
为什么多版本并发控制更受欢迎呢？因为锁和时间戳机制都是通过阻塞或者回滚冲突的事务来确保事务的有序性。比如，一个读操作可能被迫回滚，因为它要读取的数据已经被另一个更新的事务修改了。但是，如果我们把每个数据的所有历史版本都记录下来，就可以避免上述这种情况发生。这也正是多版本控制的由来：对于每个数据 Q，每次写操作 write(Q)都会给 Q 建立一个新版本；而对于读操作 read(Q)，会根据事务的先后关系选择一个正确的版本去读取，来保证事务的有序性。多版本控制能够很好地解决这类读写冲突，尤其是长时间的读操作饿死写操作问题。
```

### 多版本时间戳

### 快照隔离(Snapshot Isolation)

```
快照隔离可以看作是对每一个事务，分配了一个独有的数据库快照。事务可以安心地读取这个快照中的数据而不需要去担心其他事务(因此只读事务是不会失败也不会被等待的)。同理，事务对数据的更新也首先暂存在这个独有的快照中，只有当事务提交的时候，这些更新才会试图被写回真正的数据库版本里。当一个事务准备提交时，它依然要确保没有其他事务更新了它所更新过的数据，否则，这个事务会被回滚
```

