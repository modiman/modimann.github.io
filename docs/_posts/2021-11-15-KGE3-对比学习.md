## 背景



在知识图谱补全任务中，训练数据只包含正例三元组。对于给定的正三元组，负采样需要采集一个或多个负三元组来训练判别模型，即**负采样**,得到negative pair。

与之对应的是positive pair

得到positive pair和negative pair之后，如何更好的利用两者学习更好的模型表示？答案是**对比学习**

大多数现存的方法随机替换h或t然后过滤掉出现在训练集中的错误的负样本。不同三元组的负样本并非是共享的，因此他们彼此独立。基于嵌入的方法的经典负采样数目为64。



## 负采样

作者：AI Box专栏
链接：https://zhuanlan.zhihu.com/p/387378387
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

以推荐系统为例直观了解一下负采样

### **研究方向：**

在推荐系统负采样中，主要有三方面的研究方向：采样质量，采样偏差和采样效率。

**1、采样质量：**

 一般来说，在负采样过程中，采样的质量主要是指采到的负例所包含的信息量。 相比于低信息量的负例，采到信息量更高的负例将显著提升模型训练的效率，加速[模型收敛](https://www.zhihu.com/search?q=模型收敛&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"387378387"})。从近几年推荐系统负采样领域的论文数量来看，提升采样质量是目前该领域的主要研究方向。 

**2、采样偏差：**

在推荐系统负采样中，我们的基本假设是用户交互过的商品都是该用户的正例，未交互过的都是负例。但容易发现，这个假设还是比较强的，与真实场景存在一定偏差，例如用户未购买过的商品并不一定是不喜欢的，也有可能是用户在未来想要发生交互的商品，这一偏差可以被称为[伪负例](https://www.zhihu.com/search?q=伪负例&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"387378387"})（False Negative）问题。这些采样中的偏差会对模型训练造成影响，因此缓解或消除采样中的偏差是该领域一个重要的研究方向。

**3、采样效率：**

在推荐场景中，用户的历史交互数据是比较稀疏的，一般来说，用户平均交互的商品数量不会超过整个商品集大小的10%。因此，对于负采样而言，需要在一个较大的采样池中进行采样，一旦采样过于复杂，会导致模型训练的开销增大，这也与实际工业场景下的要求不符。因此，[采样算法](https://www.zhihu.com/search?q=采样算法&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"387378387"})的设计需要控制好复杂度，提升采样效率也是该领域一个有重要研究意义的方向。

### 主流负采样算法

#### 启发式算法

1. 随机负采样，平等对待采样池中的样本
2. 基于流行度：如果一个商品流行度很高，但用户没有与之交互，说明用户不喜欢，正是可以有效学习到用户的喜好，缺点在于采样分布是提前计算好的

#### 基于模型的负采样算法

1. 动态采样，对于每一轮学习，那些会被模型打高分的样本应该被挑出来让模型进行学习
2. 基于GAN，



## 对比学习

**对比学习**[SimKGC]：对比学习通过比较正例和负例学习有用的表示。正例与负例的定义与具体的任务有关。

在自监督视觉表示学习中，正例对是同一图像的两个增强表示。负例对则是两个不同图像的增强表示



## SimKGC

### 模型架构：双编码器架构

### 负采样方法



**本文提出的负采样方法**

### In-batch Negatives (IB)



[^SimKGC]: SimKGC: Simple Contrastive Knowledge Graph Completion with Pre-trained Language Models
[^]: 

