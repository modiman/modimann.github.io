# 多线程并发

## 参考文献

* [面试官：说说多线程并发问题](https://juejin.cn/post/6844903941830869006)

## 一、多线程为什么会有并发问题

为什么多线程同时访问（读写）同个变量，会有并发问题？

> 1. Java 内存模型规定了所有的变量都存储在主内存中，每条线程有自己的工作内存。
> 2. 线程的工作内存中保存了该线程中用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。
> 3. 线程访问一个变量，首先将变量从主内存拷贝到工作内存，对变量的写操作，不会马上同步到主内存。
> 4. 不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。

## 二、Java 内存模型（JMM）

Java 内存模型(JMM) 作用于工作内存（本地内存）和主存之间数据同步过程，它规定了如何做数据同步以及什么时候做数据同步，如下图。



![JMM](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/9/15/16d32c69d2b91f19~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)



## 三、并发三要素

**原子性**：在一个操作中，CPU 不可以在中途暂停然后再调度，即不被中断操作，要么执行完成，要么就不执行。

**可见性**：多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

**有序性**：程序执行的顺序按照代码的先后顺序执行。

## 四、怎么做，才能解决并发问题？（重点）

下面结合不同场景分析解决并发问题的处理方式。

### 一、volatile

#### 1.1 volatile 特性

**保证可见性，不保证原子性**

> 1. 当写一个volatile变量时，JVM会把本地内存的变量强制刷新到主内存中
> 2. 这个写操作导致其他线程中的缓存无效，其他线程读，会从主内存读。volatile的写操作对其它线程实时可见。

**禁止指令重排序** 指令重排序是指编译器和处理器为了优化程序性能对指令进行排序的一种手段，需要遵守一定规则：

> 1. 不会对存在依赖关系的指令重排序，例如 a = 1;b = a;  a 和b存在依赖关系，不会被重排序
> 2. 不能影响单线程下的执行结果。比如：a=1;b=2;c=a+b这三个操作,前两个操作可以重排序，但是c=a+b不会被重排序，因为要保证结果是3

#### 1.2 使用场景

对于一个变量，只有一个线程执行写操作，其它线程都是读操作，这时候可以用 volatile 修饰这个变量。

#### 1.3 单例双重锁为什么要用到volatile？

```java
public class TestInstance {

private static volatile TestInstance mInstance;

public static TestInstance getInstance(){       //1
    if (mInstance == null){                     //2
        synchronized (TestInstance.class){      //3
            if (mInstance == null){             //4
                mInstance = new TestInstance(); //5
            }
        }
    }
    return mInstance;
	}
}
```



假如没有用volatile，并发情况下会出现问题，线程A执行到注释5 `new TestInstance()` 的时候，分为如下几个几步操作：

1. 分配内存
2. 初始化对象
3. mInstance 指向内存

这时候如果发生指令重排，执行顺序是132，执行到第3的时候，线程B刚好进来了，并且执行到注释2，这时候判断mInstance 不为空，直接使用一个未初始化的对象。所以使用volatile关键字来禁止指令重排序。

#### 1.4 volatile 原理

在JVM底层volatile是采用**内存屏障**来实现的，内存屏障会提供3个功能：

> 1. 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
> 2. 它会强制将缓存的修改操作立即写到主内存
> 3. 写操作会导致其它CPU中的缓存行失效，写之后，其它线程的读操作会从主内存读。

#### 1.5 volatile 的局限性

**volatile 只能保证可见性，不能保证原子性**写操作对其它线程可见，但是不能解决多个线程同时写的问题。

### 二、Synchronized

#### 2.1 Synchronized 使用场景

多个线程同时写一个变量。

例如售票，余票是100张，窗口A和窗口B同时各卖出一张票， 假如余票变量用 volatile 修饰，是有问题的。
 A窗口获取余票是100，B窗口获取余票也是100，A卖出一张变成99，刷新回主内存，同时B卖出一张变成99，也刷新回主内存，会导致最终主内存余票是99而不是98。

前面说到 volatile 的局限性，就是多个线程同时写的情况，这种情况一般可以使用**Synchronized**。

**Synchronized 可以保证同一时刻，只有一个线程可执行某个方法或某个代码块。**

#### 2.2 Synchronized 原理

```java
public class SynchronizedTest {

public static void main(String[] args) {
    synchronized (SynchronizedTest.class) {
        System.out.println("123");
    }
    method();
}

private static void method() {
}
}
```

将这段代码先用`javac`命令编译，再`java p -v SynchronizedTest.class`命令查看字节码，部分字节码如下

```java
public static void main(java.lang.String[]);
descriptor: ([Ljava/lang/String;)V
flags: ACC_PUBLIC, ACC_STATIC
Code:
  stack=2, locals=3, args_size=1
     0: ldc           #2                  // class com/lanshifu/opengldemo/test/SynchronizedTest
     2: dup
     3: astore_1
     4: monitorenter
     5: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;
     8: ldc           #4                  // String 123
    10: invokevirtual #5                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
    13: aload_1
    14: monitorexit
    15: goto          23
    18: astore_2
    19: aload_1
    20: monitorexit
    21: aload_2
    22: athrow
    23: invokestatic  #6                  // Method method:()V
    26: return
```

可以看到 `4: monitorenter` 和 `14: monitorexit`，中间是打印的语句。

执行同步代码块，首先会执行`monitorenter`指令，然后执行同步代码块中的代码，退出同步代码块的时候会执行`monitorexit`指令 。

> 使用Synchronized进行同步，其关键就是必须要对对象的监视器monitor进行获取，当线程获取monitor后才能继续往下执行，否则就进入同步队列，线程状态变成BLOCK，同一时刻只有一个线程能够获取到monitor，当监听到monitorexit被调用，队列里就有一个线程出队，获取monitor。详情参考：[www.jianshu.com/p/d53bf830f…](https://link.juejin.cn?target=https%3A%2F%2Fwww.jianshu.com%2Fp%2Fd53bf830fa09)

每个对象拥有一个计数器，当线程获取该对象锁后，计数器就会加一，释放锁后就会将计数器减一，所以只要这个锁的计数器大于0，其它线程访问就只能等待。

#### 2.3 Synchronized 锁的升级

大家对Synchronized的理解可能就是重量级锁，但是Java1.6对 Synchronized 进行了各种优化之后，有些情况下它就并不那么重，Java1.6 中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁。

**偏向锁：** 大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。

> 当一个线程A访问加了同步锁的代码块时，会在对象头中存 储当前线程的id，后续这个线程进入和退出这段加了同步锁的代码块时，不需要再次加锁和释放锁。

**轻量级锁：** 在偏向锁情况下，如果线程B也访问了同步代码块，比较对象头的线程id不一样，会升级为轻量级锁，并且通过自旋的方式来获取轻量级锁。

**重量级锁：** 如果线程A和线程B同时访问同步代码块，则轻量级锁会升级为重量级锁，线程A获取到重量级锁的情况下，线程B只能入队等待，进入BLOCK状态。

#### 2.4  Synchronized 缺点

1. 不能设置锁超时时间
2. 不能通过代码释放锁
3. 容易造成死锁

### 三、ReentrantLock

上面说到`Synchronized`的缺点，不能设置锁超时时间和不能通过代码释放锁，`ReentranLock`就可以解决这个问题。

**在多个条件变量和高度竞争锁的地方，用ReentrantLock更合适**，ReentrantLock还提供了`Condition`，对线程的等待和唤醒等操作更加灵活，一个ReentrantLock可以有多个Condition实例，所以更有扩展性。

#### 3.1 ReentrantLock 的使用

**lock 和 unlock**

```
        ReentrantLock reentrantLock = new ReentrantLock();
        System.out.println("reentrantLock->lock");
        reentrantLock.lock();
        try {
            
            System.out.println("睡眠2秒...");
            Thread.sleep(2000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }finally {
            reentrantLock.unlock();
            System.out.println("reentrantLock->unlock");
        }
```

**实现可定时的锁请求：tryLock**

```
    public static void main(String[] args) {
        ReentrantLock reentrantLock = new ReentrantLock();
        Thread thread1 = new Thread_tryLock(reentrantLock);
        thread1.setName("thread1");
        thread1.start();
        Thread thread2 = new Thread_tryLock(reentrantLock);
        thread2.setName("thread2");
        thread2.start();
}


    static class Thread_tryLock extends Thread {
        ReentrantLock reentrantLock;

        public Thread_tryLock(ReentrantLock reentrantLock) {
            this.reentrantLock = reentrantLock;
        }

        @Override
        public void run() {
            try {
                System.out.println("try lock:" + Thread.currentThread().getName());
                boolean tryLock = reentrantLock.tryLock(3, TimeUnit.SECONDS);
                if (tryLock) {
                    System.out.println("try lock success :" + Thread.currentThread().getName());
                    System.out.println("睡眠一下：" + Thread.currentThread().getName());
                    Thread.sleep(5000);
                    System.out.println("醒了：" + Thread.currentThread().getName());
                } else {
                    System.out.println("try lock 超时 :" + Thread.currentThread().getName());
                }

            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                System.out.println("unlock:" + Thread.currentThread().getName());
                reentrantLock.unlock();
            }
        }
    }
```

打印的日志：

```
try lock:thread1
try lock:thread2
try lock success :thread2
睡眠一下：thread2
try lock 超时 :thread1
unlock:thread1
Exception in thread "thread1" java.lang.IllegalMonitorStateException
	at java.util.concurrent.locks.ReentrantLock$Sync.tryRelease(ReentrantLock.java:151)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.release(AbstractQueuedSynchronizer.java:1261)
	at java.util.concurrent.locks.ReentrantLock.unlock(ReentrantLock.java:457)
	at com.lanshifu.demo_module.test.lock.ReentranLockTest$Thread_tryLock.run(ReentranLockTest.java:60)
醒了：thread2
unlock:thread2
```

上面演示了`trtLock`的使用，`trtLock`设置获取锁的等待时间，超过3秒直接返回失败，可以从日志中看到结果。 有异常是因为thread1获取锁失败，不应该调用unlock。

#### 3.2 Condition 条件

```java
public static void main(String[] args) {

        Thread_Condition thread_condition = new Thread_Condition();
        thread_condition.setName("测试Condition的线程");
        thread_condition.start();
        try {
            Thread.sleep(2000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        thread_condition.singal();

    }


static class Thread_Condition extends Thread {

        @Override
        public void run() {
            await();
        }

        private ReentrantLock lock = new ReentrantLock();
        public Condition condition = lock.newCondition();

        public void await() {
            try {
                System.out.println("lock");
                lock.lock();
                System.out.println(Thread.currentThread().getName() + ":我在等待通知的到来...");
                condition.await();//await 和 signal 对应
                //condition.await(2, TimeUnit.SECONDS); //设置等待超时时间
                System.out.println(Thread.currentThread().getName() + ":等到通知了，我继续执行>>>");
            } catch (Exception e) {
                e.printStackTrace();
            } finally {
                System.out.println("unlock");
                lock.unlock();
            }
        }

        public void singal() {
            try {
                System.out.println("lock");
                lock.lock();
                System.out.println("我要通知在等待的线程，condition.signal()");
                condition.signal();//await 和 signal 对应
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                System.out.println("unlock");
                lock.unlock();
            }
        }
    }
```

运行打印日志

```
lock
测试Condition的线程:我在等待通知的到来...
lock
我要通知在等待的线程，condition.signal()
unlock
测试Condition的线程:等到通知了，我继续执行>>>
unlock
```

上面演示了`Condition的 await 和 signal` 使用，前提要先lock。

#### 3.3 公平锁与非公平锁

ReentrantLock 构造函数传true表示公平锁。

公平锁表示线程获取锁的顺序是按照线程加锁的顺序来分配的，即先来先得的顺序。而非公平锁就是一种锁的抢占机制，是随机获得锁的，可能会导致某些线程一致拿不到锁，所以是不公平的。

#### 3.4 ReentrantLock  注意点

1. ReentrantLock使用lock和unlock来获得锁和释放锁
2. unlock要放在finally中，这样正常运行或者异常都会释放锁
3. 使用condition的await和signal方法之前，必须调用lock方法获得对象监视器

### 四、并发包

通过上面分析，并发严重的情况下，使用锁显然效率低下，因为同一时刻只能有一个线程可以获得锁，其它线程只能乖乖等待。

Java提供了并发包解决这个问题，接下来介绍并发包里一些常用的数据结构。

#### 4.1 ConcurrentHashMap

**我们都知道HashMap是线程不安全的数据结构，HashTable则在HashMap基础上，get方法和put方法加上Synchronized修饰变成线程安全，不过在高并发情况下效率底下，最终被`ConcurrentHashMap`替代。**

ConcurrentHashMap 采用分段锁，内部默认有16个桶，get和put操作，首先将key计算hashcode，然后跟16取余，落到16个桶中的一个，然后每个桶中都加了锁（ReentrantLock），桶中是HashMap结构（数组加链表，链表过长转红黑树）。

所以理论上最多支持16个线程同时访问。

#### 4.2 LinkBlockingQueue

链表结构的阻塞队列，内部使用多个ReentrantLock

```java
    /** Lock held by take, poll, etc */
    private final ReentrantLock takeLock = new ReentrantLock();

    /** Wait queue for waiting takes */
    private final Condition notEmpty = takeLock.newCondition();

    /** Lock held by put, offer, etc */
    private final ReentrantLock putLock = new ReentrantLock();

    /** Wait queue for waiting puts */
    private final Condition notFull = putLock.newCondition();

private void signalNotEmpty() {
        final ReentrantLock takeLock = this.takeLock;
        takeLock.lock();
        try {
            notEmpty.signal();
        } finally {
            takeLock.unlock();
        }
    }

    /**
     * Signals a waiting put. Called only from take/poll.
     */
    private void signalNotFull() {
        final ReentrantLock putLock = this.putLock;
        putLock.lock();
        try {
            notFull.signal();
        } finally {
            putLock.unlock();
        }
    }
```

源码不贴太多，简单说一下`LinkBlockingQueue` 的逻辑：

> 1. 从队列获取数据，如果队列中没有数据，会调用`notEmpty.await();`进入等待。
> 2. 在放数据进去队列的时候会调用`notEmpty.signal();`，通知消费者，1中的等待结束，唤醒继续执行。
> 3. 从队列里取到数据的时候会调用`notFull.signal();`，通知生产者继续生产。
> 4. 在put数据进入队列的时候，如果判断队列中的数据达到最大值，那么会调用`notFull.await();`，等待消费者消费掉，也就是等待3去取数据并且发出`notFull.signal();`，这时候生产者才能继续生产。

`LinkBlockingQueue` 是典型的生产者消费者模式，源码细节就不多说。

#### 4.3  原子操作类：AtomicInteger

内部采用CAS（compare and swap）保证原子性

举一个int自增的例子

```
        AtomicInteger atomicInteger = new AtomicInteger(0);
        atomicInteger.incrementAndGet();//自增
```

源码看一下

```
   /**
     * Atomically increments by one the current value.
     *
     * @return the updated value
     */
    public final int incrementAndGet() {
        return U.getAndAddInt(this, VALUE, 1) + 1;
    }
```

U 是 Unsafe，看下 `Unsafe#getAndAddInt`

```
    public final int getAndAddInt(Object var1, long var2, int var4) {
        int var5;
        do {
            var5 = this.getIntVolatile(var1, var2);
        } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));

        return var5;
    }
```

通过`compareAndSwapInt`保证原子性。

## 五、总结

面试中问到多线程并发问题，可以这么答：

> 1. 当只有一个线程写，其它线程都是读的时候，可以用`volatile`修饰变量
> 2. 当多个线程写，那么一般情况下并发不严重的话可以用`Synchronized`，Synchronized并不是一开始就是重量级锁，在并发不严重的时候，比如只有一个线程访问的时候，是偏向锁；当多个线程访问，但不是同时访问，这时候锁升级为轻量级锁；当多个线程同时访问，这时候升级为重量级锁。所以在并发不是很严重的情况下，使用Synchronized是可以的。不过Synchronized有局限性，比如不能设置锁超时，不能通过代码释放锁。
> 3. `ReentranLock` 可以通过代码释放锁，可以设置锁超时。
> 4. 高并发下，Synchronized、ReentranLock 效率低，因为同一时刻只有一个线程能进入同步代码块，如果同时有很多线程访问，那么其它线程就都在等待锁。这个时候可以使用并发包下的数据结构，例如`ConcurrentHashMap`，`LinkBlockingQueue`，以及原子性的数据结构如：`AtomicInteger`。

面试的时候按照上面总结的这个思路回答基本就ok了。既然说到并发包，那么除了`ConcurrentHashMap`，其它一些常用的数据结构的原理也需要去了解下，例如`HashMap、HashTable、TreeMap`原理，`ArrayList、LinkedList`对比，这些都是老生常谈的，自己去看源码或者一些博客。

关于多线程并发就先总结到这里，如果是应付面试的话按照这篇文章的思路来准备应该是没太大问题的。


作者：蓝师傅
链接：https://juejin.cn/post/6844903941830869006
来源：稀土掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



## [一文搞懂六大*进程通信*机制原理(全网最详细)](https://zhuanlan.zhihu.com/p/465574868)

[![玩转Linux内核](https://pic1.zhimg.com/50/v2-52b5b5f22089a2f57aeffb52f2590a2e_s.jpg?source=4e949a73)](https://www.zhihu.com/people/gang-hao-xin-dong-23)

[玩转Linux内核](https://www.zhihu.com/people/gang-hao-xin-dong-23)



目录

初学操作系统的时候，我就一直懵逼，为啥进程同步与互斥机制里有信号量机制，进程通信里又有信号量机制，然后你再看网络上的各种面试题汇总或者博客，你会发现很多都是千篇一律的进程通信机制有哪些？进程同步与互斥机制鲜有人问津。看多了我都想把 CSDN 屏了.....，最后知道真相的我只想说为啥不能一篇博客把东西写清楚，没头没尾真的浪费时间。希望这篇文章能够拯救某段时间和我一样被绕晕的小伙伴。上篇文章我已经讲过进程间的同步与互斥机制，各位小伙伴看完这个再来看进程通信比较好。**全文脉络思维导图如下：**![img](https://pic2.zhimg.com/v2-05357079c73568813ec18658a5e803c1_b.jpg)一. 什么是进程通信顾名思义，进程通信（ InterProcess Communication，IPC）就是指**进程之间的信息交换**。实际上，**进程的同步与互斥本质上也是一种进程通信**（这也就是待会我们会在进程通信机制中看见信号量和 PV 操作的原因了），只不过它传输的仅仅是[信号量](https://www.zhihu.com/search?q=信号量&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})，通过修改信号量，使得进程之间建立联系，相互协调和协同工作，但是它**缺乏传递数据的能力**。虽然存在某些情况，进程之间交换的信息量很少，比如仅仅交换某个状态信息，这样进程的同步与互斥机制完全可以胜任这项工作。但是大多数情况下，**进程之间需要交换大批数据**，比如传送一批信息或整个文件，这就需要通过一种新的通信机制来完成，也就是所谓的进程通信。再来从操作系统层面直观的看一些进程通信：我们知道，为了保证安全，每个进程的用户地址空间都是独立的，一般而言一个进程不能直接访问另一个进程的地址空间，不过内核空间是每个进程都共享的，所以**进程之间想要进行信息交换就必须通过内核**。![img](https://pic2.zhimg.com/v2-1c0a8bc38f13325491ab6a8b0f781be1_b.jpg)
下面就来我们来列举一下 Linux 内核提供的常见的进程通信机制：管道（也称作共享文件）消息队列（也称作消息传递）共享内存（也称作共享存储）信号量和 PV 操作信号套接字（Socket）**【文章福利**】小编推荐自己的Linux内核技术交流群:【**[865977150](https://link.zhihu.com/?target=https%3A//jq.qq.com/%3F_wv%3D1027%26k%3DMIwvxPCw)**】整理了一些个人觉得比较好的学习书籍、视频资料共享在群文件里面，有需要的可以自行添加哦！！！前100名进群领取，额外赠送一份价值**699的内核资料包**（含视频教程、电子书、实战项目及代码)![img](https://pic1.zhimg.com/v2-b8374d9d3ede89608ee38a95136b6c1c_b.jpg)**学习直通车：**[Linux内核源码/内存调优/文件系统/进程管理/设备驱动/网络协议栈-学习视频教程-腾讯课堂​ke.qq.com/course/4032547?flowToken=1040236​ke.qq.com/course/4032547?flowToken=1040236​ke.qq.com/course/4032547?flowToken=1040236](https://link.zhihu.com/?target=https%3A//ke.qq.com/course/4032547%3FflowToken%3D1040236)**内核资料直通车：**[Linux内核源码技术学习路线+视频教程代码资料​docs.qq.com/doc/DTkZRWXRFcWx1bWVx​docs.qq.com/doc/DTkZRWXRFcWx1bWVx​docs.qq.com/doc/DTkZRWXRFcWx1bWVx![img](https://pic4.zhimg.com/v2-f54ced07633ae35c82eb2e6841fb62af_180x120.jpg)](https://link.zhihu.com/?target=https%3A//docs.qq.com/doc/DTkZRWXRFcWx1bWVx)二. 管道**匿名管道**各位如果学过 Linux 命令，那对管道肯定不陌生，Linux 管道使用竖线 | 连接多个命令，这被称为管道符。`$ command1 | command2`以上这行代码就组成了一个管道，它的功能是将前一个命令（command1）的输出，作为后一个命令（command2）的输入，从这个功能描述中，我们可以看出**管道中的数据只能单向流动**，也就是半双工通信，如果想实现相互通信（全双工通信），我们需要创建两个管道才行。另外，通过管道符 | 创建的管道是匿名管道，用完了就会被自动销毁。并且，匿名管道只能在具有亲缘关系（父子进程）的进程间使用，。也就是说，**匿名管道只能用于父子进程之间的通信**。在 Linux 的实际编码中，是通过 pipe 函数来创建匿名管道的，若创建成功则返回 0，创建失败就返回 -1：`int pipe (int fd[2]);`**该函数拥有一个存储空间为 2 的[文件描述符](https://www.zhihu.com/search?q=文件描述符&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})数组：**fd[0] 指向管道的读端，fd[1] 指向管道的写端fd[1] 的输出是 fd[0] 的输入**粗略的解释一下通过匿名管道实现进程间通信的步骤：**1）父进程创建两个匿名管道，管道 1（fd1[0]和 fd1[1]）和管道 2（fd2[0] 和 fd2[1]）；因为管道的数据是单向流动的，所以要想实现数据双向通信，就需要两个管道，每个方向一个。2）[父进程](https://www.zhihu.com/search?q=父进程&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"}) fork 出子进程，于是对于这两个匿名管道，子进程也分别有两个文件描述符指向匿名管道的读写两端；3）父进程关闭管道 1 的读端 fd1[0] 和 管道 2 的写端 fd2[1]，子进程关闭管道 1 的写端 fd1[1] 和 管道 2 的读端 fd2[0]，这样，管道 1 只能用于父进程写、子进程读；管道 2 只能用于父进程读、子进程写。管道是用**[环形队列](https://www.zhihu.com/search?q=环形队列&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})**实现的，数据从写端流入从读端流出，这就实现了父子进程之间的双向通信。![img](https://pic3.zhimg.com/v2-9a3131e0e838332fecaab3476eda26fa_b.jpg)看完上面这些讲述，我们来理解下管道的本质是什么：对于管道两端的进程而言，管道就是一个文件（这也就是为啥管道也被称为共享文件机制的原因了），但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在于内存中。简单来说，**管道的本质就是内核在内存中开辟了一个缓冲区，这个缓冲区与管道文件相关联，对管道文件的操作，被内核转换成对这块缓冲区的操作**。**有名管道**匿名管道由于没有名字，只能用于父子进程间的通信。为了克服这个缺点，提出了有名管道，也称做 FIFO，因为数据是先进先出的传输方式。所谓有名管道也就是提供一个路径名与之关联，这样，即使与创建有名管道的进程不存在亲缘关系的进程，只要可以访问该路径，就能够通过这个有名管道进行相互通信。**使用 Linux 命令 mkfifo 来创建有名管道：**`$ mkfifo myPipe`**myPipe 就是这个管道的名称，接下来，我们往 myPipe 这个有名管道中写入数据：**`$ echo "hello" > myPipe`执行这行命令后，你会发现它就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。于是，我们执行另外一个命令来读取这个有名管道里的数据：`$ cat < myPipe hello`三. 消息队列可以看出，**管道这种进程通信方式虽然使用简单，但是效率比较低，不适合进程间频繁地交换数据，并且管道只能传输无格式的[字节流](https://www.zhihu.com/search?q=字节流&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})**。为此，消息传递机制（Linux 中称消息队列）应用而生。比如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程在需要的时候自行去消息队列中读取数据就可以了。同样的，B 进程要给 A 进程发送消息也是如此。![img](https://pic1.zhimg.com/v2-a2caf6e76f9407a1752a220080b10134_b.jpg)**消息队列的本质就是存放在内存中的消息的链表，而消息本质上是用户自定义的[数据结构](https://www.zhihu.com/search?q=数据结构&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})**。如果进程从消息队列中读取了某个消息，这个消息就会被从消息队列中删除。对比一下管道机制：消息队列允许一个或多个进程向它写入或读取消息。消息队列可以实现消息的**随机查询**，不一定非要以先进先出的次序读取消息，也可以按消息的类型读取。比有名管道的先进先出原则更有优势。对于消息队列来说，在某个进程往一个队列写入消息之前，并不需要另一个进程在该消息队列上等待消息的到达。而对于管道来说，除非读进程已存在，否则先有写进程进行写入操作是没有意义的。消息队列的生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列就会一直存在。而匿名管道随进程的创建而建立，随进程的结束而销毁。需要注意的是，消息队列对于交换较少数量的数据很有用，因为无需避免冲突。但是，由于用户进程写入数据到内存中的消息队列时，会发生从用户态**拷贝**数据到内核态的过程；同样的，另一个用户进程读取内存中的消息数据时，会发生从内核态拷贝数据到[用户态](https://www.zhihu.com/search?q=用户态&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})的过程。因此，**如果数据量较大，使用消息队列就会造成频繁的系统调用，也就是需要消耗更多的时间以便内核介入**。四. 共享内存为了避免像消息队列那样频繁的拷贝消息、进行系统调用，共享内存机制出现了。顾名思义，共享内存就是允许不相干的进程将同一段物理内存连接到它们各自的地址空间中，使得这些进程可以访问同一个物理内存，这个物理内存就成为共享内存。如果某个进程向共享内存写入数据，所做的改动将**立即**影响到可以访问同一段共享内存的任何其他进程。集合内存管理的内容，我们来深入理解下共享内存的原理。首先，每个进程都有属于自己的进程控制块（PCB）和逻辑地址空间（Addr Space），并且都有一个与之对应的页表，负责将进程的逻辑地址（虚拟地址）与物理地址进行映射，通过内存管理单元（MMU）进行管理。**两个不同进程的逻辑地址通过页表映射到物理空间的同一区域，它们所共同指向的这块区域就是共享内存**。![img](https://pic4.zhimg.com/v2-30fd4ee32afadbc97fc602a8461ac74b_b.jpg)不同于消息队列频繁的系统调用，对于共享内存机制来说，仅在建立共享内存区域时需要系统调用，一旦建立共享内存，所有的访问都可作为常规内存访问，无需借助内核。这样，数据就不需要在进程之间来回拷贝，所以这是最快的一种进程通信方式。![img](https://pic2.zhimg.com/v2-b2f88341dfb4ed26e5e11a7408e8766d_b.jpg)五. 信号量和 PV 操作实际上，对具有多 CPU 系统的最新研究表明，在这类系统上，消息传递的性能其实是要优于共享内存的，因为**消息队列无需避免冲突，而共享内存机制可能会发生冲突**。也就是说如果多个进程同时修改同一个共享内存，先来的那个进程写的内容就会被后来的覆盖。并且，在多道批处理系统中，多个进程是可以并发执行的，但由于系统的资源有限，进程的执行不是一贯到底的， 而是走走停停，以不可预知的速度向前推进（异步性）。但有时候我们又希望多个进程能密切合作，按照某个特定的顺序依次执行，以实现一个共同的任务。举个例子，如果有 A、B 两个进程分别负责读和写数据的操作，这两个线程是相互合作、相互依赖的。那么写数据应该发生在读数据之前。而实际上，由于异步性的存在，可能会发生先读后写的情况，而此时由于缓冲区还没有被写入数据，读进程 A 没有数据可读，因此读进程 A 被阻塞。![img](https://pic2.zhimg.com/v2-44d3a2d42d9c6c0be7e636d192cdd749_b.jpg)因此，为了解决上述这两个问题，保证共享内存在任何时刻只有一个进程在访问（互斥），并且使得进程们能够按照某个特定顺序访问共享内存（同步），我们就可以使用进程的同步与互斥机制，常见的比如信号量与 PV 操作。**进程的同步与互斥其实是一种对进程通信的保护机制，并不是用来传输进程之间真正通信的内容的，但是由于它们会传输信号量，所以也被纳入进程通信的范畴，称为低级通信**。下面的内容和上篇文章【看完了进程同步与互斥机制，我终于彻底理解了 PV 操作】中所讲的差不多，看过的小伙伴可直接跳到下一标题。信号量其实就是一个变量 ，我们可以用一个信号量来表示系统中某种资源的数量，比如：系统中只有一台打印机，就可以设置一个初值为 1 的信号量。用户进程可以通过使用操作系统提供的一对原语来对信号量进行操作，从而很方便的实现进程互斥或同步。这一对原语就是 PV 操作：1）**P 操作**：将信号量值减 1，表示**申请占用一个资源**。如果结果小于 0，表示已经没有可用资源，则执行 P 操作的进程被阻塞。如果结果大于等于 0，表示现有的资源足够你使用，则执行 P 操作的进程继续执行。可以这么理解，当信号量的值为 2 的时候，表示有 2 个资源可以使用，当信号量的值为 -2 的时候，表示有两个进程正在等待使用这个资源。不看这句话真的无法理解 V 操作，看完顿时如梦初醒。2）**V 操作**：将信号量值加 1，表示**释放一个资源**，即使用完资源后归还资源。若加完后信号量的值小于等于 0，表示有某些进程正在等待该资源，由于我们已经释放出一个资源了，因此需要唤醒一个等待使用该资源（[就绪态](https://www.zhihu.com/search?q=就绪态&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})）的进程，使之运行下去。我觉得已经讲的足够通俗了，不过对于 V 操作大家可能仍然有困惑，下面再来看两个关于 V 操作的问答：问：**信号量的值 大于 0 表示有共享资源可供使用，这个时候为什么不需要唤醒进程**？答：所谓唤醒进程是从就绪队列（[阻塞队列](https://www.zhihu.com/search?q=阻塞队列&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})）中唤醒进程，而信号量的值大于 0 表示有共享资源可供使用，也就是说这个时候没有进程被阻塞在这个资源上，所以不需要唤醒，正常运行即可。问：**信号量的值 等于 0 的时候表示没有共享资源可供使用，为什么还要唤醒进程**？答：V 操作是先执行信号量值加 1 的，也就是说，把信号量的值加 1 后才变成了 0，在此之前，信号量的值是 -1，即有一个进程正在等待这个共享资源，我们需要唤醒它。**信号量和 PV 操作具体的定义如下：**![img](https://pic4.zhimg.com/v2-7b74c0f4c727c73429e033d31686d257_b.jpg)**互斥访问共享内存****两步走即可实现不同进程对共享内存的互斥访问：**定义一个互斥信号量，并初始化为 1把对共享内存的访问置于 P 操作和 V 操作之间![img](https://pic1.zhimg.com/v2-b9985c3b39adfc1318846b92b06f4a84_b.jpg)**P 操作和 V 操作必须成对出现**。缺少 P 操作就不能保证对共享内存的互斥访问，缺少 V 操作就会导致共享内存永远得不到释放、处于等待态的进程永远得不到唤醒。![img](https://pic2.zhimg.com/v2-bacaff7e77dc273c7bd9b7c206b7edf9_b.jpg)**实现进程同步**回顾一下进程同步，就是要各并发进程按要求有序地运行。举个例子，以下两个进程 P1、P2 并发执行，由于存在异步性，因此二者交替推进的次序是不确定的。假设 P2 的 “代码4” 要基于 P1 的 “代码1” 和 “代码2” 的运行结果才能执行，那么我们就必须保证 “代码4” 一定是在 “代码2” 之后才会执行。![img](https://pic3.zhimg.com/v2-d235165c06aa584e182af579baeefa06_b.jpg)如果 P2 的 “代码4” 要基于 P1 的 “代码1” 和 “代码2” 的运行结果才能执行，那么我们就必须保证 “代码4” 一定是在 “代码2” 之后才会执行。**使用信号量和 PV 操作实现进程的同步也非常方便，三步走：**定义一个同步信号量，并初始化为当前可用资源的数量在优先级较**高**的操作的**后**面执行 V 操作，释放资源在优先级较**低**的操作的**前**面执行 P 操作，申请占用资源![img](https://pic1.zhimg.com/v2-b96f4d81a066a07c78881580ed5d6a10_b.jpg)**配合下面这张图直观理解下：**![img](https://pic1.zhimg.com/v2-5298a00e4d5f74ec0e6e7667761e695c_b.jpg)六. 信号注意！**信号和信号量是完全不同的两个概念**！信号是进程通信机制中唯一的**异步**通信机制，它可以在任何时候发送信号给某个进程。**通过发送指定信号来通知进程某个[异步事件](https://www.zhihu.com/search?q=异步事件&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})的发送，以迫使进程执行信号处理程序。信号处理完毕后，被中断进程将恢复执行**。用户、内核和进程都能生成和发送信号。信号事件的来源主要有硬件来源和软件来源。所谓硬件来源就是说我们可以通过键盘输入某些[组合键](https://www.zhihu.com/search?q=组合键&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})给进程发送信号，比如常见的组合键 Ctrl+C 产生 SIGINT 信号，表示终止该进程；而软件来源就是通过 [kill](https://www.zhihu.com/search?q=kill&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"}) 系列的命令给进程发送信号，比如 kill -9 1111 ，表示给 PID 为 1111 的进程发送 SIGKILL 信号，让其立即结束。**我们来查看一下 Linux 中有哪些信号：**![img](https://pic3.zhimg.com/v2-09f8b9dcfea6a49418793954047a8f62_b.jpg)七. Socket至此，上面介绍的 5 种方法都是用于同一台主机上的进程之间进行通信的，如果想要**跨网络与不同主机上的进程进行通信**，那该怎么做呢？这就是 Socket 通信做的事情了（**当然，Socket 也能完成同主机上的进程通信**）。![img](https://pic1.zhimg.com/v2-053f491fd42d5e7ba86295393e275310_b.jpg)
Socket 起源于 Unix，原意是**插座**，在计算机通信领域，Socket 被翻译为**套接字**，它是计算机之间进行通信的一种约定或一种方式。通过 Socket 这种约定，一台计算机可以接收其他计算机的数据，也可以向其他计算机发送数据。从计算机网络层面来说，**Socket 套接字是网络通信的基石**，是支持 TCP/IP 协议的网络通信的基本操作单元。它是网络通信过程中端点的抽象表示，包含进行网络通信必须的五种信息：连接使用的协议，本地主机的 IP 地址，本地进程的协议端口，远地主机的 IP 地址，远地进程的协议端口。Socket 的本质其实是一个编程接口（API），是应用层与 TCP/IP 协议族通信的中间软件抽象层，它对 TCP/IP 进行了封装。它**把复杂的 TCP/IP [协议族](https://www.zhihu.com/search?q=协议族&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"465574868"})隐藏在 Socket 接口后面**。对用户来说，只要通过一组简单的 API 就可以实现网络的连接。八. 总结简单总结一下上面六种 Linux 内核提供的进程通信机制：1）首先，最简单的方式就是**管道**，管道的本质是存放在内存中的特殊的文件。也就是说，内核在内存中开辟了一个缓冲区，这个缓冲区与管道文件相关联，对管道文件的操作，被内核转换成对这块缓冲区的操作。管道分为匿名管道和有名管道，匿名管道只能在父子进程之间进行通信，而有名管道没有限制。2）虽然管道使用简单，但是效率比较低，不适合进程间频繁地交换数据，并且管道只能传输无格式的字节流。为此**消息队列**应用而生。消息队列的本质就是存放在内存中的消息的链表，而消息本质上是用户自定义的数据结构。如果进程从消息队列中读取了某个消息，这个消息就会被从消息队列中删除。3）消息队列的速度比较慢，因为每次数据的写入和读取都需要经过用户态与内核态之间数据的拷贝过程，**共享内存**可以解决这个问题。所谓共享内存就是：两个不同进程的逻辑地址通过页表映射到物理空间的同一区域，它们所共同指向的这块区域就是共享内存。如果某个进程向共享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程。对于共享内存机制来说，仅在建立共享内存区域时需要系统调用，一旦建立共享内存，所有的访问都可作为常规内存访问，无需借助内核。这样，数据就不需要在进程之间来回拷贝，所以这是最快的一种进程通信方式。4）共享内存速度虽然非常快，但是存在冲突问题，为此，我们可以使用信号量和 PV 操作来实现对共享内存的互斥访问，并且还可以实现进程同步。5）**信号**和信号量是完全不同的两个概念！信号是进程通信机制中唯一的异步通信机制，它可以在任何时候发送信号给某个进程。通过发送指定信号来通知进程某个异步事件的发送，以迫使进程执行信号处理程序。信号处理完毕后，被中断进程将恢复执行。用户、内核和进程都能生成和发送信号。6）上面介绍的 5 种方法都是用于同一台主机上的进程之间进行通信的，如果想要跨网络与不同主机上的进程进行通信，就需要使用 **Socket** 通信。另外，Socket 也能完成同主机上的进程通信。[2022年嵌入式开发想进互联网大厂，你技术过硬吗？](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzg4NDQ0OTI4Ng%3D%3D%26mid%3D2247484055%26idx%3D1%26sn%3D4853a8cb88c81d0a6f1d1fde3ad3a116%26chksm%3Dcfb94bfef8cec2e828aea867492b04a443c8017961c1c802495ee4204aa24819738a59d478e3%23rd)[从事十年嵌入式转内核开发(23K到45K),给兄弟们的一些建议](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzg4NDQ0OTI4Ng%3D%3D%26mid%3D2247484315%26idx%3D1%26sn%3D32a69de03504aa9e70a6844846b04d7e%26chksm%3Dcfb94af2f8cec3e4a887d2b9f283bc4a09e44d6bbf4dc652c4b153de2cf6a97ef734edecafab%23rd)[腾讯T6-9首发“Linux内核源码嵌入式开发进阶笔记”，差距不止一点点哦](https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzg4NDQ0OTI4Ng%3D%3D%26mid%3D2247483870%26idx%3D1%26sn%3D371c575a3d7df9e25f302e5c49e50bf6%26chksm%3Dcfb948b7f8cec1a1bf6207bc0a0e11dd3706b1a86eb38775f68c915d2e06d5769e48498df9c3%23rd)![img](https://pic4.zhimg.com/v2-b4727cbe1e4dba48982fdcbbe9b78f3b_b.jpg)

[编辑于 2022-02-13 16:52](https://zhuanlan.zhihu.com/p/465574868)3.反射是什么







### 4.synchronize锁升级

### 5.计算机网络七层，各层功能，协议





### 6.线程与进程

### 7.Linux查日志的方法

### 算法：反转链表

 