# Representation Learning of Knowledge Graphs with Entity  Descriptions

# 摘要

针对问题：事实上，在大多数知识图中，通常存在对实体的简明描述，这是现有方法无法很好地利用的。在本文中，我们提出了一种新的基于实体描述的知识图RL方法。

* 提出两种编码器：连续词袋和CNN用来编码实体描述
* 在知识补全和实体分类两个任务上评估模型
* 可以处理零样本问题，即可以根据实体描述表示知识图谱中没有出现过的实体

# 介绍

写一些问题背景，即随着知识图谱规模的不断增大，由于计算效率和数据稀疏的限制，以往的知识图谱应用方法不再可行，因此提出了知识图谱表示学习。

# 相关工作

* 基于翻译的模型
* 考虑文本信息的模型-----NTN，

# 问题公式化

## 定义一：基于结构的表示

使用TransE模型得到hs和ts

## 定义二：基于描述的表示

根据头实体和尾实体的描述得到hd和td

# 方法

为了利用事实三元组和实体描述，并能够处理零样本场景，提出两种实体表示

基于结构的表示捕获三元组信息，基于描述的的表示捕获实体描述的信息。

将两种表示学习到同一连续向量空间，能量函数定义为

E=E<sub>S</sub>+E<sub>D</sub> （2）

其中

 E<sub>D</sub>= E<sub>DD</sub>+E<sub>DS</sub>+E<sub>SD</sub>  （3）

E<sub>DD</sub>=|hd+r-td|

E<sub>DS</sub>=|hd+r-ts|

E<sub>SD</sub>=|hd+r-td|

能量函数将两种类型的实体表示投射到同一个向量空间中，四种能量函数共享关系表示，从而使两种类型的表示相互促进。

本文提出了两种编码器构建基于描述的表示

## 连续词袋模型

​       从每个简短的描述中，我们可以生成一组关键字，这些关键字通常能够捕捉实体的主要思想。我们假设相似的实体应该有相似的描述，相应的有相似的关键字。那些不能通过结构信息直接检测到的关系，可以在关键词的内部联系中找到

​    首先利用TF—IDF等方法给实体描述中的词语排序，选取前n个词语作为编码器输入

**ed = x1+x2+......+xk,**（4）

![image-20220211155713070](https://github.com/modiman/modiman.github.io/blob/gh-pages/docs/_posts/imgs/image-20220211155713070.png?raw=true)

## CNN编码器

### 总体框架

![image-20220211160038645](https://github.com/modiman/modiman.github.io/blob/gh-pages/docs/_posts/imgs/image-20220211160038645.png?raw=true)

### 预处理和词表示

使用Word2Vec作为卷积层的输入

### 训练

参数集设置为θ=（X，W1，W2，E，R）

X，E，R分别是词向量，实体、关系嵌入

W1,W2是不同层的卷积核

### 初始化

W1，W2随机初始化

### 优化

随机梯度下降

# 实验

## 数据集

* FB15K，
* 针对零样本，自建立FB20K